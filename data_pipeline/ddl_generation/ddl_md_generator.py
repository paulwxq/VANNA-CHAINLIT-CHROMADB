"""
DDLå’ŒMDæ–‡æ¡£ç”Ÿæˆå™¨å‘½ä»¤è¡Œå…¥å£
ç”¨äºä»PostgreSQLæ•°æ®åº“ç”ŸæˆDDLå’ŒMDè®­ç»ƒæ•°æ®
"""
import argparse
import asyncio
import sys
import os
import logging
from pathlib import Path

def setup_argument_parser():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='DDL/MDæ–‡æ¡£ç”Ÿæˆå™¨ - ä»PostgreSQLæ•°æ®åº“ç”Ÿæˆè®­ç»ƒæ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬ä½¿ç”¨
  python -m data_pipeline.ddl_md_generator --db-connection "postgresql://user:pass@host:5432/db" --table-list tables.txt --business-context "ç”µå•†ç³»ç»Ÿ"
  
  # æŒ‡å®šè¾“å‡ºç›®å½•
  python -m data_pipeline.ddl_md_generator --db-connection "..." --table-list tables.txt --business-context "ç”µå•†ç³»ç»Ÿ" --output-dir ./data_pipeline/training_data/
  
  # ä»…ç”ŸæˆDDLæ–‡ä»¶
  python -m data_pipeline.ddl_md_generator --db-connection "..." --table-list tables.txt --business-context "ç”µå•†ç³»ç»Ÿ" --pipeline ddl_only
  
  # æƒé™æ£€æŸ¥æ¨¡å¼
  python -m data_pipeline.ddl_md_generator --db-connection "..." --check-permissions-only
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        '--db-connection',
        required=True,
        help='æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸² (ä¾‹å¦‚: postgresql://user:pass@localhost:5432/dbname)'
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        '--table-list',
        help='è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--business-context',
        help='ä¸šåŠ¡ä¸Šä¸‹æ–‡æè¿°'
    )
    
    parser.add_argument(
        '--business-context-file',
        help='ä¸šåŠ¡ä¸Šä¸‹æ–‡æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--output-dir',
        help='è¾“å‡ºç›®å½•è·¯å¾„'
    )
    
    parser.add_argument(
        '--pipeline',
        choices=['full', 'ddl_only', 'analysis_only'],
        help='å¤„ç†é“¾ç±»å‹'
    )
    
    parser.add_argument(
        '--max-concurrent',
        type=int,
        help='æœ€å¤§å¹¶å‘è¡¨æ•°é‡'
    )
    
    # åŠŸèƒ½å¼€å…³
    parser.add_argument(
        '--no-filter-system-tables',
        action='store_true',
        help='ç¦ç”¨ç³»ç»Ÿè¡¨è¿‡æ»¤'
    )
    
    parser.add_argument(
        '--check-permissions-only',
        action='store_true',
        help='ä»…æ£€æŸ¥æ•°æ®åº“æƒé™ï¼Œä¸å¤„ç†è¡¨'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º'
    )
    
    parser.add_argument(
        '--log-file',
        help='æ—¥å¿—æ–‡ä»¶è·¯å¾„'
    )
    
    return parser

def load_config_with_overrides(args):
    """åŠ è½½é…ç½®å¹¶åº”ç”¨å‘½ä»¤è¡Œè¦†ç›–"""
    from data_pipeline.config import SCHEMA_TOOLS_CONFIG
    
    config = SCHEMA_TOOLS_CONFIG.copy()
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.output_dir:
        config["output_directory"] = args.output_dir
    
    if args.pipeline:
        config["default_pipeline"] = args.pipeline
    
    if args.max_concurrent:
        config["max_concurrent_tables"] = args.max_concurrent
    
    if args.no_filter_system_tables:
        config["filter_system_tables"] = False
    
    if args.log_file:
        config["log_file"] = args.log_file
    
    return config

def load_business_context(args):
    """åŠ è½½ä¸šåŠ¡ä¸Šä¸‹æ–‡"""
    if args.business_context_file:
        try:
            with open(args.business_context_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–ä¸šåŠ¡ä¸Šä¸‹æ–‡æ–‡ä»¶ {args.business_context_file}: {e}")
    
    if args.business_context:
        return args.business_context
    
    from data_pipeline.config import SCHEMA_TOOLS_CONFIG
    return SCHEMA_TOOLS_CONFIG.get("default_business_context", "æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ")

async def check_permissions_only(db_connection: str):
    """ä»…æ£€æŸ¥æ•°æ®åº“æƒé™"""
    from .training_data_agent import SchemaTrainingDataAgent
    
    print("ğŸ” æ£€æŸ¥æ•°æ®åº“æƒé™...")
    
    try:
        agent = SchemaTrainingDataAgent(
            db_connection=db_connection,
            table_list_file="",  # ä¸éœ€è¦è¡¨æ¸…å•
            business_context=""   # ä¸éœ€è¦ä¸šåŠ¡ä¸Šä¸‹æ–‡
        )
        
        # åˆå§‹åŒ–Agentä»¥å»ºç«‹æ•°æ®åº“è¿æ¥
        await agent._initialize()
        
        # æ£€æŸ¥æƒé™
        permissions = await agent.check_database_permissions()
        
        print("\nğŸ“‹ æƒé™æ£€æŸ¥ç»“æœ:")
        print(f"  âœ… æ•°æ®åº“è¿æ¥: {'å¯ç”¨' if permissions['connect'] else 'ä¸å¯ç”¨'}")
        print(f"  âœ… å…ƒæ•°æ®æŸ¥è¯¢: {'å¯ç”¨' if permissions['select_metadata'] else 'ä¸å¯ç”¨'}")
        print(f"  âœ… æ•°æ®æŸ¥è¯¢: {'å¯ç”¨' if permissions['select_data'] else 'ä¸å¯ç”¨'}")
        print(f"  â„¹ï¸  æ•°æ®åº“ç±»å‹: {'åªè¯»' if permissions['is_readonly'] else 'è¯»å†™'}")
        
        # ä¿®å¤åˆ¤æ–­é€»è¾‘ï¼šis_readonly=Falseè¡¨ç¤ºå¯è¯»å†™ï¼Œæ˜¯å¥½äº‹
        required_permissions = ['connect', 'select_metadata', 'select_data']
        has_required_permissions = all(permissions.get(perm, False) for perm in required_permissions)
        
        if has_required_permissions:
            print("\nâœ… æ•°æ®åº“æƒé™æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹å¤„ç†")
            return True
        else:
            print("\nâŒ æ•°æ®åº“æƒé™ä¸è¶³ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return False
            
    except Exception as e:
        print(f"\nâŒ æƒé™æ£€æŸ¥å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    from data_pipeline.utils.logger import setup_logging
    setup_logging(
        verbose=args.verbose,
        log_file=args.log_file
    )
    
    # ä»…æƒé™æ£€æŸ¥æ¨¡å¼
    if args.check_permissions_only:
        success = await check_permissions_only(args.db_connection)
        sys.exit(0 if success else 1)
    
    # éªŒè¯å¿…éœ€å‚æ•°
    if not args.table_list:
        print("é”™è¯¯: éœ€è¦æŒ‡å®š --table-list å‚æ•°")
        parser.print_help()
        sys.exit(1)
    
    if not os.path.exists(args.table_list):
        print(f"é”™è¯¯: è¡¨æ¸…å•æ–‡ä»¶ä¸å­˜åœ¨: {args.table_list}")
        sys.exit(1)
    
    try:
        # åŠ è½½é…ç½®å’Œä¸šåŠ¡ä¸Šä¸‹æ–‡
        config = load_config_with_overrides(args)
        business_context = load_business_context(args)
        
        # åˆ›å»ºAgent
        from .training_data_agent import SchemaTrainingDataAgent
        
        agent = SchemaTrainingDataAgent(
            db_connection=args.db_connection,
            table_list_file=args.table_list,
            business_context=business_context,
            output_dir=config["output_directory"],
            pipeline=config["default_pipeline"]
        )
        
        # æ‰§è¡Œç”Ÿæˆ
        print("ğŸš€ å¼€å§‹ç”ŸæˆDDLå’ŒMDæ–‡æ¡£...")
        report = await agent.generate_training_data()
        
        # è¾“å‡ºç»“æœ
        if report['summary']['failed'] == 0:
            print("\nğŸ‰ æ‰€æœ‰è¡¨å¤„ç†æˆåŠŸ!")
        else:
            print(f"\nâš ï¸  å¤„ç†å®Œæˆï¼Œä½†æœ‰ {report['summary']['failed']} ä¸ªè¡¨å¤±è´¥")
        
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {config['output_directory']}")
        
        # å¦‚æœæœ‰å¤±è´¥çš„è¡¨ï¼Œè¿”å›éé›¶é€€å‡ºç 
        sys.exit(1 if report['summary']['failed'] > 0 else 0)
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())