import asyncio
import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from data_pipeline.config import SCHEMA_TOOLS_CONFIG
from data_pipeline.validators import FileCountValidator
from data_pipeline.analyzers import MDFileAnalyzer, ThemeExtractor
from data_pipeline.utils.logger import setup_logging
from core.vanna_llm_factory import create_vanna_instance


class QuestionSQLGenerationAgent:
    """Question-SQLç”ŸæˆAgent"""
    
    def __init__(self, 
                 output_dir: str,
                 table_list_file: str,
                 business_context: str,
                 db_name: str = None):
        """
        åˆå§‹åŒ–Agent
        
        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼ˆåŒ…å«DDLå’ŒMDæ–‡ä»¶ï¼‰
            table_list_file: è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„
            business_context: ä¸šåŠ¡ä¸Šä¸‹æ–‡
            db_name: æ•°æ®åº“åç§°ï¼ˆç”¨äºè¾“å‡ºæ–‡ä»¶å‘½åï¼‰
        """
        self.output_dir = Path(output_dir)
        self.table_list_file = table_list_file
        self.business_context = business_context
        self.db_name = db_name or "db"
        
        self.config = SCHEMA_TOOLS_CONFIG
        self.logger = logging.getLogger("schema_tools.QSAgent")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.validator = FileCountValidator()
        self.md_analyzer = MDFileAnalyzer(output_dir)
        
        # vannaå®ä¾‹å’Œä¸»é¢˜æå–å™¨å°†åœ¨éœ€è¦æ—¶åˆå§‹åŒ–
        self.vn = None
        self.theme_extractor = None
        
        # ä¸­é—´ç»“æœå­˜å‚¨
        self.intermediate_results = []
        self.intermediate_file = None
        
    async def generate(self) -> Dict[str, Any]:
        """
        ç”ŸæˆQuestion-SQLå¯¹
        
        Returns:
            ç”Ÿæˆç»“æœæŠ¥å‘Š
        """
        start_time = time.time()
        
        try:
            self.logger.info("ğŸš€ å¼€å§‹ç”ŸæˆQuestion-SQLè®­ç»ƒæ•°æ®")
            
            # 1. éªŒè¯æ–‡ä»¶æ•°é‡
            self.logger.info("ğŸ“‹ éªŒè¯æ–‡ä»¶æ•°é‡...")
            validation_result = self.validator.validate(self.table_list_file, str(self.output_dir))
            
            if not validation_result.is_valid:
                self.logger.error(f"âŒ æ–‡ä»¶éªŒè¯å¤±è´¥: {validation_result.error}")
                if validation_result.missing_ddl:
                    self.logger.error(f"ç¼ºå¤±DDLæ–‡ä»¶: {validation_result.missing_ddl}")
                if validation_result.missing_md:
                    self.logger.error(f"ç¼ºå¤±MDæ–‡ä»¶: {validation_result.missing_md}")
                raise ValueError(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {validation_result.error}")
            
            self.logger.info(f"âœ… æ–‡ä»¶éªŒè¯é€šè¿‡: {validation_result.table_count}ä¸ªè¡¨")
            
            # 2. è¯»å–æ‰€æœ‰MDæ–‡ä»¶å†…å®¹
            self.logger.info("ğŸ“– è¯»å–MDæ–‡ä»¶...")
            md_contents = await self.md_analyzer.read_all_md_files()
            
            # 3. åˆå§‹åŒ–LLMç›¸å…³ç»„ä»¶
            self._initialize_llm_components()
            
            # 4. æå–åˆ†æä¸»é¢˜
            self.logger.info("ğŸ¯ æå–åˆ†æä¸»é¢˜...")
            themes = await self.theme_extractor.extract_themes(md_contents)
            self.logger.info(f"âœ… æˆåŠŸæå– {len(themes)} ä¸ªåˆ†æä¸»é¢˜")
            
            for i, theme in enumerate(themes):
                topic_name = theme.get('topic_name', theme.get('name', ''))
                description = theme.get('description', '')
                self.logger.info(f"  {i+1}. {topic_name}: {description}")
            
            # 5. åˆå§‹åŒ–ä¸­é—´ç»“æœæ–‡ä»¶
            self._init_intermediate_file()
            
            # 6. å¤„ç†æ¯ä¸ªä¸»é¢˜
            all_qs_pairs = []
            failed_themes = []
            
            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¹¶è¡Œè¿˜æ˜¯ä¸²è¡Œå¤„ç†
            max_concurrent = self.config['qs_generation'].get('max_concurrent_themes', 1)
            if max_concurrent > 1:
                results = await self._process_themes_parallel(themes, md_contents, max_concurrent)
            else:
                results = await self._process_themes_serial(themes, md_contents)
            
            # 7. æ•´ç†ç»“æœ
            for result in results:
                if result['success']:
                    all_qs_pairs.extend(result['qs_pairs'])
                else:
                    failed_themes.append(result['theme_name'])
            
            # 8. ä¿å­˜æœ€ç»ˆç»“æœ
            output_file = await self._save_final_results(all_qs_pairs)
            
            # 8.5 ç”Ÿæˆmetadata.txtæ–‡ä»¶
            await self._generate_metadata_file(themes)
            
            # 8.6 ç”Ÿæˆmetadata_detail.mdæ–‡ä»¶
            await self._generate_metadata_md_file(themes)
            
            # 8.7 ç”Ÿæˆdb_query_decision_prompt.txtæ–‡ä»¶
            await self._generate_decision_prompt_file(themes)
            
            # 9. æ¸…ç†ä¸­é—´æ–‡ä»¶
            if not failed_themes:  # åªæœ‰å…¨éƒ¨æˆåŠŸæ‰æ¸…ç†
                self._cleanup_intermediate_file()
            
            # 10. ç”ŸæˆæŠ¥å‘Š
            end_time = time.time()
            report = {
                'success': True,
                'total_themes': len(themes),
                'successful_themes': len(themes) - len(failed_themes),
                'failed_themes': failed_themes,
                'total_questions': len(all_qs_pairs),
                'output_file': str(output_file),
                'execution_time': end_time - start_time
            }
            
            self._print_summary(report)
            
            return report
            
        except Exception as e:
            self.logger.exception("âŒ Question-SQLç”Ÿæˆå¤±è´¥")
            
            # ä¿å­˜å½“å‰å·²ç”Ÿæˆçš„ç»“æœ
            if self.intermediate_results:
                recovery_file = self._save_intermediate_results()
                self.logger.warning(f"âš ï¸  ä¸­é—´ç»“æœå·²ä¿å­˜åˆ°: {recovery_file}")
            
            raise
    
    def _initialize_llm_components(self):
        """åˆå§‹åŒ–LLMç›¸å…³ç»„ä»¶"""
        if not self.vn:
            self.logger.info("åˆå§‹åŒ–LLMç»„ä»¶...")
            self.vn = create_vanna_instance()
            self.theme_extractor = ThemeExtractor(self.vn, self.business_context)
    
    async def _process_themes_serial(self, themes: List[Dict], md_contents: str) -> List[Dict]:
        """ä¸²è¡Œå¤„ç†ä¸»é¢˜"""
        results = []
        
        for i, theme in enumerate(themes):
            self.logger.info(f"å¤„ç†ä¸»é¢˜ {i+1}/{len(themes)}: {theme.get('topic_name', theme.get('name', ''))}")
            result = await self._process_single_theme(theme, md_contents)
            results.append(result)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­
            if not result['success'] and not self.config['qs_generation']['continue_on_theme_error']:
                self.logger.error(f"ä¸»é¢˜å¤„ç†å¤±è´¥ï¼Œåœæ­¢å¤„ç†")
                break
        
        return results
    
    async def _process_themes_parallel(self, themes: List[Dict], md_contents: str, max_concurrent: int) -> List[Dict]:
        """å¹¶è¡Œå¤„ç†ä¸»é¢˜"""
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_with_semaphore(theme):
            async with semaphore:
                return await self._process_single_theme(theme, md_contents)
        
        tasks = [process_with_semaphore(theme) for theme in themes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                theme_name = themes[i].get('topic_name', themes[i].get('name', ''))
                self.logger.error(f"ä¸»é¢˜ '{theme_name}' å¤„ç†å¼‚å¸¸: {result}")
                processed_results.append({
                    'success': False,
                    'theme_name': theme_name,
                    'error': str(result)
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _process_single_theme(self, theme: Dict, md_contents: str) -> Dict:
        """å¤„ç†å•ä¸ªä¸»é¢˜"""
        theme_name = theme.get('topic_name', theme.get('name', ''))
        
        try:
            self.logger.info(f"ğŸ” å¼€å§‹å¤„ç†ä¸»é¢˜: {theme_name}")
            
            # æ„å»ºprompt
            prompt = self._build_qs_generation_prompt(theme, md_contents)
            
            # è°ƒç”¨LLMç”Ÿæˆ
            response = await self._call_llm(prompt)
            
            # è§£æå“åº”
            qs_pairs = self._parse_qs_response(response)
            
            # éªŒè¯å’Œæ¸…ç†
            validated_pairs = self._validate_qs_pairs(qs_pairs, theme_name)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            await self._save_theme_results(theme_name, validated_pairs)
            
            self.logger.info(f"âœ… ä¸»é¢˜ '{theme_name}' å¤„ç†æˆåŠŸï¼Œç”Ÿæˆ {len(validated_pairs)} ä¸ªé—®é¢˜")
            
            return {
                'success': True,
                'theme_name': theme_name,
                'qs_pairs': validated_pairs
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†ä¸»é¢˜ '{theme_name}' å¤±è´¥: {e}")
            return {
                'success': False,
                'theme_name': theme_name,
                'error': str(e),
                'qs_pairs': []
            }
    
    def _build_qs_generation_prompt(self, theme: Dict, md_contents: str) -> str:
        """æ„å»ºQuestion-SQLç”Ÿæˆçš„prompt"""
        questions_count = self.config['qs_generation']['questions_per_theme']
        
        # è·å–ä¸»é¢˜ä¿¡æ¯
        topic_name = theme.get('topic_name', theme.get('name', ''))
        description = theme.get('description', '')
        biz_entities = theme.get('biz_entities', [])
        biz_metrics = theme.get('biz_metrics', [])
        related_tables = theme.get('related_tables', [])
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸šåŠ¡æ•°æ®åˆ†æå¸ˆï¼Œæ­£åœ¨ä¸º{self.business_context}è®¾è®¡æ•°æ®æŸ¥è¯¢ã€‚

å½“å‰åˆ†æä¸»é¢˜ï¼š{topic_name}
ä¸»é¢˜æè¿°ï¼š{description}
ä¸šåŠ¡å®ä½“ï¼š{', '.join(biz_entities)}
ä¸šåŠ¡æŒ‡æ ‡ï¼š{', '.join(biz_metrics)}
ç›¸å…³è¡¨ï¼š{', '.join(related_tables)}

æ•°æ®åº“è¡¨ç»“æ„ä¿¡æ¯ï¼š
{md_contents}

è¯·ä¸ºè¿™ä¸ªä¸»é¢˜ç”Ÿæˆ {questions_count} ä¸ªä¸šåŠ¡é—®é¢˜å’Œå¯¹åº”çš„SQLæŸ¥è¯¢ã€‚

è¦æ±‚ï¼š
1. é—®é¢˜åº”è¯¥ä»ä¸šåŠ¡è§’åº¦å‡ºå‘ï¼Œè´´åˆä¸»é¢˜è¦æ±‚ï¼Œå…·æœ‰å®é™…åˆ†æä»·å€¼
2. SQLå¿…é¡»ä½¿ç”¨PostgreSQLè¯­æ³•
3. è€ƒè™‘å®é™…ä¸šåŠ¡é€»è¾‘ï¼ˆå¦‚è½¯åˆ é™¤ä½¿ç”¨ delete_ts IS NULL æ¡ä»¶ï¼‰
4. ä½¿ç”¨ä¸­æ–‡åˆ«åæé«˜å¯è¯»æ€§ï¼ˆä½¿ç”¨ AS æŒ‡å®šåˆ—åˆ«åï¼‰
5. é—®é¢˜åº”è¯¥å¤šæ ·åŒ–ï¼Œè¦†ç›–ä¸åŒçš„åˆ†æè§’åº¦
6. åŒ…å«æ—¶é—´ç­›é€‰ã€åˆ†ç»„ç»Ÿè®¡ã€æ’åºã€é™åˆ¶ç­‰ä¸åŒç±»å‹çš„æŸ¥è¯¢
7. SQLè¯­å¥æœ«å°¾å¿…é¡»ä»¥åˆ†å·ç»“æŸ
8. **é‡è¦ï¼šé—®é¢˜å’ŒSQLéƒ½å¿…é¡»æ˜¯å•è¡Œæ–‡æœ¬ï¼Œä¸èƒ½åŒ…å«æ¢è¡Œç¬¦**

è¾“å‡ºJSONæ ¼å¼ï¼ˆæ³¨æ„SQLä¸­çš„åŒå¼•å·éœ€è¦è½¬ä¹‰ï¼‰ï¼š
```json
[
  {{
    "question": "å…·ä½“çš„ä¸šåŠ¡é—®é¢˜ï¼Ÿ",
    "sql": "SELECT column AS ä¸­æ–‡å FROM table WHERE condition;"
  }}
]
```

ç”Ÿæˆçš„é—®é¢˜åº”è¯¥åŒ…æ‹¬ä½†ä¸é™äºï¼š
- è¶‹åŠ¿åˆ†æï¼ˆæŒ‰æ—¶é—´ç»´åº¦ï¼‰
- å¯¹æ¯”åˆ†æï¼ˆä¸åŒç»´åº¦å¯¹æ¯”ï¼‰
- æ’åç»Ÿè®¡ï¼ˆTOP Nï¼‰
- æ±‡æ€»ç»Ÿè®¡ï¼ˆæ€»é‡ã€å¹³å‡å€¼ç­‰ï¼‰
- æ˜ç»†æŸ¥è¯¢ï¼ˆç‰¹å®šæ¡ä»¶çš„è¯¦ç»†æ•°æ®ï¼‰"""
        
        return prompt
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLM"""
        try:
            response = await asyncio.to_thread(
                self.vn.chat_with_llm,
                question=prompt,
                system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œç²¾é€šPostgreSQLè¯­æ³•ï¼Œæ“…é•¿è®¾è®¡æœ‰ä¸šåŠ¡ä»·å€¼çš„æ•°æ®æŸ¥è¯¢ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºã€‚ç‰¹åˆ«æ³¨æ„ï¼šç”Ÿæˆçš„é—®é¢˜å’ŒSQLéƒ½å¿…é¡»æ˜¯å•è¡Œæ–‡æœ¬ï¼Œä¸èƒ½åŒ…å«æ¢è¡Œç¬¦ã€‚"
            )
            
            if not response or not response.strip():
                raise ValueError("LLMè¿”å›ç©ºå“åº”")
            
            return response.strip()
            
        except Exception as e:
            self.logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _parse_qs_response(self, response: str) -> List[Dict[str, str]]:
        """è§£æQuestion-SQLå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = response
            
            # è§£æJSON
            qs_pairs = json.loads(json_str)
            
            if not isinstance(qs_pairs, list):
                raise ValueError("å“åº”ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
            
            return qs_pairs
            
        except json.JSONDecodeError as e:
            self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
            self.logger.debug(f"åŸå§‹å“åº”: {response}")
            raise ValueError(f"æ— æ³•è§£æLLMå“åº”ä¸ºJSONæ ¼å¼: {e}")
    
    def _validate_qs_pairs(self, qs_pairs: List[Dict], theme_name: str) -> List[Dict[str, str]]:
        """éªŒè¯å’Œæ¸…ç†Question-SQLå¯¹"""
        validated = []
        
        for i, pair in enumerate(qs_pairs):
            if not isinstance(pair, dict):
                self.logger.warning(f"è·³è¿‡æ— æ•ˆæ ¼å¼çš„é¡¹ {i+1}")
                continue
            
            question = pair.get('question', '').strip()
            sql = pair.get('sql', '').strip()
            
            if not question or not sql:
                self.logger.warning(f"è·³è¿‡ç©ºé—®é¢˜æˆ–SQLçš„é¡¹ {i+1}")
                continue
            
            # æ¸…ç†questionä¸­çš„æ¢è¡Œç¬¦ï¼Œæ›¿æ¢ä¸ºç©ºæ ¼
            question = ' '.join(question.split())
            
            # æ¸…ç†SQLä¸­çš„æ¢è¡Œç¬¦å’Œå¤šä½™ç©ºæ ¼ï¼Œå‹ç¼©ä¸ºå•è¡Œ
            sql = ' '.join(sql.split())
            
            # ç¡®ä¿SQLä»¥åˆ†å·ç»“æŸ
            if not sql.endswith(';'):
                sql += ';'
            
            validated.append({
                'question': question,
                'sql': sql
            })
        
        self.logger.info(f"ä¸»é¢˜ '{theme_name}': éªŒè¯é€šè¿‡ {len(validated)}/{len(qs_pairs)} ä¸ªé—®é¢˜")
        
        return validated
    
    def _init_intermediate_file(self):
        """åˆå§‹åŒ–ä¸­é—´ç»“æœæ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.intermediate_file = self.output_dir / f"qs_intermediate_{timestamp}.json"
        self.intermediate_results = []
        self.logger.info(f"ä¸­é—´ç»“æœæ–‡ä»¶: {self.intermediate_file}")
    
    async def _save_theme_results(self, theme_name: str, qs_pairs: List[Dict]):
        """ä¿å­˜å•ä¸ªä¸»é¢˜çš„ç»“æœ"""
        theme_result = {
            "theme": theme_name,
            "timestamp": datetime.now().isoformat(),
            "questions_count": len(qs_pairs),
            "questions": qs_pairs
        }
        
        self.intermediate_results.append(theme_result)
        
        # ç«‹å³ä¿å­˜åˆ°ä¸­é—´æ–‡ä»¶
        if self.config['qs_generation']['save_intermediate']:
            try:
                with open(self.intermediate_file, 'w', encoding='utf-8') as f:
                    json.dump(self.intermediate_results, f, ensure_ascii=False, indent=2)
                self.logger.debug(f"ä¸­é—´ç»“æœå·²æ›´æ–°: {self.intermediate_file}")
            except Exception as e:
                self.logger.warning(f"ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {e}")
    
    def _save_intermediate_results(self) -> Path:
        """å¼‚å¸¸æ—¶ä¿å­˜ä¸­é—´ç»“æœ"""
        if not self.intermediate_results:
            return None
        
        recovery_file = self.output_dir / f"qs_recovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(recovery_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "status": "interrupted",
                    "timestamp": datetime.now().isoformat(),
                    "completed_themes": len(self.intermediate_results),
                    "results": self.intermediate_results
                }, f, ensure_ascii=False, indent=2)
            
            return recovery_file
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ¢å¤æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    async def _save_final_results(self, all_qs_pairs: List[Dict]) -> Path:
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = self.output_dir / f"{self.config['qs_generation']['output_file_prefix']}_{self.db_name}_{timestamp}_pair.json"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(all_qs_pairs, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"âœ… æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            return output_file
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æœ€ç»ˆç»“æœå¤±è´¥: {e}")
            raise
    
    def _cleanup_intermediate_file(self):
        """æ¸…ç†ä¸­é—´æ–‡ä»¶"""
        if self.intermediate_file and self.intermediate_file.exists():
            try:
                self.intermediate_file.unlink()
                self.logger.info("å·²æ¸…ç†ä¸­é—´æ–‡ä»¶")
            except Exception as e:
                self.logger.warning(f"æ¸…ç†ä¸­é—´æ–‡ä»¶å¤±è´¥: {e}")
    
    def _print_summary(self, report: Dict):
        """æ‰“å°æ€»ç»“ä¿¡æ¯"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š ç”Ÿæˆæ€»ç»“")
        self.logger.info(f"  âœ… æ€»ä¸»é¢˜æ•°: {report['total_themes']}")
        self.logger.info(f"  âœ… æˆåŠŸä¸»é¢˜: {report['successful_themes']}")
        
        if report['failed_themes']:
            self.logger.info(f"  âŒ å¤±è´¥ä¸»é¢˜: {len(report['failed_themes'])}")
            for theme in report['failed_themes']:
                self.logger.info(f"     - {theme}")
        
        self.logger.info(f"  ğŸ“ æ€»é—®é¢˜æ•°: {report['total_questions']}")
        self.logger.info(f"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {report['output_file']}")
        self.logger.info(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {report['execution_time']:.2f}ç§’")
        self.logger.info("=" * 60)

    async def _generate_metadata_file(self, themes: List[Dict]):
        """ç”Ÿæˆmetadata.txtæ–‡ä»¶ï¼ŒåŒ…å«INSERTè¯­å¥"""
        metadata_file = self.output_dir / "metadata.txt"
        
        try:
            with open(metadata_file, 'w', encoding='utf-8') as f:
                f.write("-- Schema Toolsç”Ÿæˆçš„ä¸»é¢˜å…ƒæ•°æ®\n")
                f.write(f"-- ä¸šåŠ¡èƒŒæ™¯: {self.business_context}\n")
                f.write(f"-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"-- æ•°æ®åº“: {self.db_name}\n\n")
                
                f.write("-- åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n")
                f.write("CREATE TABLE IF NOT EXISTS metadata (\n")
                f.write("    id SERIAL PRIMARY KEY,    -- ä¸»é”®\n")
                f.write("    topic_name VARCHAR(100) NOT NULL,  -- ä¸šåŠ¡ä¸»é¢˜åç§°\n")
                f.write("    description TEXT,                  -- ä¸šåŠ¡ä¸»ä½“è¯´æ˜\n")
                f.write("    related_tables TEXT[],\t\t\t  -- ç›¸å…³è¡¨å\n")
                f.write("    biz_entities TEXT[],               -- ä¸»è¦ä¸šåŠ¡å®ä½“åç§°\n")
                f.write("    biz_metrics TEXT[],                -- ä¸»è¦ä¸šåŠ¡æŒ‡æ ‡åç§°\n")
                f.write("    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP    -- æ’å…¥æ—¶é—´\n")
                f.write(");\n\n")
                
                f.write("-- æ’å…¥ä¸»é¢˜æ•°æ®\n")
                for theme in themes:
                    # è·å–å­—æ®µå€¼ï¼Œä½¿ç”¨æ–°æ ¼å¼
                    topic_name = theme.get('topic_name', theme.get('name', ''))
                    description = theme.get('description', '')
                    
                    # å¤„ç†related_tables
                    related_tables = theme.get('related_tables', [])
                    if isinstance(related_tables, list):
                        tables_str = ','.join(related_tables)
                    else:
                        tables_str = ''
                    
                    # å¤„ç†biz_entities
                    biz_entities = theme.get('biz_entities', [])
                    if isinstance(biz_entities, list):
                        entities_str = ','.join(biz_entities)
                    else:
                        entities_str = ''
                    
                    # å¤„ç†biz_metrics
                    biz_metrics = theme.get('biz_metrics', [])
                    if isinstance(biz_metrics, list):
                        metrics_str = ','.join(biz_metrics)
                    else:
                        metrics_str = ''
                    
                    # ç”ŸæˆINSERTè¯­å¥
                    f.write("INSERT INTO metadata(topic_name, description, related_tables, biz_entities, biz_metrics) VALUES\n")
                    f.write("(\n")
                    f.write(f"  '{self._escape_sql_string(topic_name)}',\n")
                    f.write(f"  '{self._escape_sql_string(description)}',\n")
                    f.write(f"  '{tables_str}',\n")
                    f.write(f"  '{entities_str}',\n")
                    f.write(f"  '{metrics_str}'\n")
                    f.write(");\n\n")
            
            self.logger.info(f"âœ… metadata.txtæ–‡ä»¶å·²ç”Ÿæˆ: {metadata_file}")
            return metadata_file
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆmetadata.txtæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    async def _generate_metadata_md_file(self, themes: List[Dict]):
        """ç”Ÿæˆmetadata_detail.mdæ–‡ä»¶"""
        metadata_md_file = self.output_dir / "metadata_detail.md"
        
        try:
            # ä»themesä¸­æ”¶é›†ç¤ºä¾‹æ•°æ®
            sample_tables = set()
            sample_entities = set()
            sample_metrics = set()
            
            for theme in themes:
                related_tables = theme.get('related_tables', [])
                if isinstance(related_tables, list):
                    sample_tables.update(related_tables[:2])  # å–å‰2ä¸ªè¡¨ä½œä¸ºç¤ºä¾‹
                
                biz_entities = theme.get('biz_entities', [])
                if isinstance(biz_entities, list):
                    sample_entities.update(biz_entities[:3])  # å–å‰3ä¸ªå®ä½“ä½œä¸ºç¤ºä¾‹
                
                biz_metrics = theme.get('biz_metrics', [])
                if isinstance(biz_metrics, list):
                    sample_metrics.update(biz_metrics[:3])  # å–å‰3ä¸ªæŒ‡æ ‡ä½œä¸ºç¤ºä¾‹
            
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œé¿å…ç¡¬ç¼–ç ç‰¹å®šè¡Œä¸šå†…å®¹
            tables_example = ', '.join(list(sample_tables)[:2]) if sample_tables else 'æ•°æ®è¡¨1, æ•°æ®è¡¨2'
            entities_example = ', '.join(list(sample_entities)[:3]) if sample_entities else 'ä¸šåŠ¡å®ä½“1, ä¸šåŠ¡å®ä½“2, ä¸šåŠ¡å®ä½“3'
            metrics_example = ', '.join(list(sample_metrics)[:3]) if sample_metrics else 'ä¸šåŠ¡æŒ‡æ ‡1, ä¸šåŠ¡æŒ‡æ ‡2, ä¸šåŠ¡æŒ‡æ ‡3'
            
            with open(metadata_md_file, 'w', encoding='utf-8') as f:
                f.write("## metadataï¼ˆå­˜å‚¨åˆ†æä¸»é¢˜å…ƒæ•°æ®ï¼‰\n\n")
                f.write("`metadata` ä¸»è¦æè¿°äº†å½“å‰æ•°æ®åº“åŒ…å«äº†å“ªäº›æ•°æ®å†…å®¹ï¼Œå“ªäº›åˆ†æä¸»é¢˜ï¼Œå“ªäº›æŒ‡æ ‡ç­‰ç­‰ã€‚\n\n")
                f.write("å­—æ®µåˆ—è¡¨ï¼š\n\n")
                f.write("- `id` (serial) - ä¸»é”®ID [ä¸»é”®, éç©º]\n")
                f.write("- `topic_name` (varchar(100)) - ä¸šåŠ¡ä¸»é¢˜åç§° [éç©º]\n")
                f.write("- `description` (text) - ä¸šåŠ¡ä¸»é¢˜è¯´æ˜\n")
                f.write(f"- `related_tables` (text[]) - æ¶‰åŠçš„æ•°æ®è¡¨ [ç¤ºä¾‹: {tables_example}]\n")
                f.write(f"- `biz_entities` (text[]) - ä¸»è¦ä¸šåŠ¡å®ä½“åç§° [ç¤ºä¾‹: {entities_example}]\n")
                f.write(f"- `biz_metrics` (text[]) - ä¸»è¦ä¸šåŠ¡æŒ‡æ ‡åç§° [ç¤ºä¾‹: {metrics_example}]\n")
                f.write("- `created_at` (timestamp) - æ’å…¥æ—¶é—´ [é»˜è®¤å€¼: `CURRENT_TIMESTAMP`]\n\n")
                f.write("å­—æ®µè¡¥å……è¯´æ˜ï¼š\n\n")
                f.write("- `id` ä¸ºä¸»é”®ï¼Œè‡ªå¢ï¼›\n")
                f.write("- `related_tables` ç”¨äºå»ºç«‹ä¸»é¢˜ä¸å…·ä½“æ˜ç»†è¡¨çš„ä¾èµ–å…³ç³»ï¼›\n")
                f.write("- `biz_entities` è¡¨ç¤ºä¸»é¢˜å…³æ³¨çš„æ ¸å¿ƒå¯¹è±¡ï¼Œä¾‹å¦‚æœåŠ¡åŒºã€è½¦è¾†ã€å…¬å¸ï¼›\n")
                f.write("- `biz_metrics` è¡¨ç¤ºè¯¥ä¸»é¢˜å…³æ³¨çš„ä¸šåŠ¡åˆ†ææŒ‡æ ‡ï¼Œä¾‹å¦‚è¥æ”¶å¯¹æ¯”ã€è¶‹åŠ¿å˜åŒ–ã€å æ¯”ç»“æ„ç­‰ã€‚\n")
            
            self.logger.info(f"âœ… metadata_detail.mdæ–‡ä»¶å·²ç”Ÿæˆ: {metadata_md_file}")
            return metadata_md_file
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆmetadata_detail.mdæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    async def _generate_decision_prompt_with_llm(self, themes: List[Dict], md_contents: str) -> str:
        """ä½¿ç”¨LLMåŠ¨æ€ç”Ÿæˆdb_query_decision_prompt.txtçš„å®Œæ•´å†…å®¹ï¼ˆåŸºäºçº¯è¡¨ç»“æ„åˆ†æï¼‰"""
        try:
            # æ„å»ºLLMæç¤ºè¯ - è®©LLMå®Œå…¨ç‹¬ç«‹åˆ†æè¡¨ç»“æ„
            prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ•°æ®åˆ†æå¸ˆï¼Œè¯·ç›´æ¥åˆ†æä»¥ä¸‹æ•°æ®åº“çš„è¡¨ç»“æ„ï¼Œç‹¬ç«‹åˆ¤æ–­ä¸šåŠ¡èŒƒå›´å’Œæ•°æ®èŒƒå›´ã€‚

ä¸šåŠ¡èƒŒæ™¯ï¼š{self.business_context}

æ•°æ®åº“è¡¨ç»“æ„è¯¦ç»†ä¿¡æ¯ï¼š
{md_contents}

åˆ†æä»»åŠ¡ï¼š
è¯·ä½ ç›´æ¥ä»è¡¨ç»“æ„ã€å­—æ®µåç§°ã€å­—æ®µç±»å‹ã€ç¤ºä¾‹æ•°æ®ä¸­æ¨æ–­ä¸šåŠ¡é€»è¾‘ï¼Œä¸è¦å‚è€ƒä»»ä½•é¢„è®¾çš„ä¸šåŠ¡ä¸»é¢˜ã€‚

åˆ†æè¦æ±‚ï¼š
1. **ä¸šåŠ¡èŒƒå›´**ï¼šæ ¹æ®è¡¨åå’Œæ ¸å¿ƒä¸šåŠ¡å­—æ®µï¼Œç”¨ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªæ•°æ®åº“æ”¯æ’‘çš„ä¸šåŠ¡é¢†åŸŸ
2. **æ•°æ®èŒƒå›´**ï¼šæ ¹æ®å…·ä½“çš„æ•°æ®å­—æ®µï¼ˆå¦‚é‡‘é¢ã€æ•°é‡ã€ç±»å‹ç­‰ï¼‰ï¼Œç”¨ä¸€å¥è¯æ¦‚æ‹¬æ¶‰åŠçš„æ•°æ®ç±»å‹å’ŒèŒƒå›´  
3. **æ ¸å¿ƒä¸šåŠ¡å®ä½“**ï¼šä»éæŠ€æœ¯å­—æ®µä¸­è¯†åˆ«ä¸»è¦çš„ä¸šåŠ¡å¯¹è±¡ï¼ˆå¦‚è¡¨ä¸­çš„ç»´åº¦å­—æ®µï¼‰
4. **å…³é”®ä¸šåŠ¡æŒ‡æ ‡**ï¼šä»æ•°å€¼å‹å­—æ®µå’Œæšä¸¾å­—æ®µä¸­è¯†åˆ«å¯ä»¥è¿›è¡Œåˆ†æçš„æŒ‡æ ‡

æŠ€æœ¯å­—æ®µè¿‡æ»¤è§„åˆ™ï¼ˆè¯·å¿½ç•¥ä»¥ä¸‹å­—æ®µï¼‰ï¼š
- ä¸»é”®å­—æ®µï¼šidã€ä¸»é”®IDç­‰
- æ—¶é—´æˆ³å­—æ®µï¼šcreate_tsã€update_tsã€delete_tsã€created_atã€updated_atç­‰  
- ç‰ˆæœ¬å­—æ®µï¼šversionã€ç‰ˆæœ¬å·ç­‰
- æ“ä½œäººå­—æ®µï¼šcreated_byã€updated_byã€deleted_byç­‰

è¯·ç›´æ¥ç”Ÿæˆä»¥ä¸‹æ ¼å¼çš„ä¸šåŠ¡åˆ†ææŠ¥å‘Šï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œä¸è¦æ·»åŠ é¢å¤–å†…å®¹ï¼‰ï¼š

=== æ•°æ®åº“ä¸šåŠ¡èŒƒå›´ ===
å½“å‰æ•°æ®åº“å­˜å‚¨çš„æ˜¯[ä¸šåŠ¡æè¿°]çš„ç›¸å…³æ•°æ®ï¼Œä¸»è¦æ¶‰åŠ[æ•°æ®èŒƒå›´]ï¼ŒåŒ…å«ä»¥ä¸‹ä¸šåŠ¡æ•°æ®ï¼š
æ ¸å¿ƒä¸šåŠ¡å®ä½“ï¼š
- å®ä½“ç±»å‹1ï¼šè¯¦ç»†æè¿°ï¼ˆåŸºäºå®é™…å­—æ®µå’Œä¸šåŠ¡åœºæ™¯ï¼‰ï¼Œä¸»è¦å­—æ®µï¼šå­—æ®µ1ã€å­—æ®µ2ã€å­—æ®µ3
- å®ä½“ç±»å‹2ï¼šè¯¦ç»†æè¿°ï¼Œä¸»è¦å­—æ®µï¼šå­—æ®µ1ã€å­—æ®µ2ã€å­—æ®µ3
å…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼š
- æŒ‡æ ‡ç±»å‹1ï¼šè¯¦ç»†æè¿°ï¼ˆåŸºäºå®é™…æ•°å€¼å­—æ®µå’Œåˆ†æéœ€æ±‚ï¼‰
- æŒ‡æ ‡ç±»å‹2ï¼šè¯¦ç»†æè¿°

è¦æ±‚ï¼š
1. è¯·å®Œå…¨åŸºäºè¡¨ç»“æ„è¿›è¡Œç‹¬ç«‹åˆ†æï¼Œä»å­—æ®µçš„ä¸šåŠ¡å«ä¹‰å‡ºå‘ï¼Œå‡†ç¡®åæ˜ æ•°æ®åº“çš„å®é™…ä¸šåŠ¡èŒƒå›´
2. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ åˆ†æä¾æ®ã€æ€»ç»“æˆ–å…¶ä»–é¢å¤–å†…å®¹
3. è¾“å‡ºå†…å®¹åˆ°"æŒ‡æ ‡ç±»å‹2ï¼šè¯¦ç»†æè¿°"ç»“æŸå³å¯"""
            
            # è°ƒç”¨LLMç”Ÿæˆå†…å®¹
            response = await self._call_llm(prompt)
            return response.strip()
            
        except Exception as e:
            self.logger.error(f"LLMç”Ÿæˆå†³ç­–æç¤ºå†…å®¹å¤±è´¥: {e}")
            # å›é€€æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€å†…å®¹
            return self._generate_fallback_decision_content(themes)
    
    async def _generate_fallback_decision_content(self, themes: List[Dict]) -> str:
        """ç”Ÿæˆå›é€€çš„å†³ç­–æç¤ºå†…å®¹ï¼ˆå°è¯•ç”¨ç®€åŒ–LLMè°ƒç”¨ï¼‰"""
        content = f"=== æ•°æ®åº“ä¸šåŠ¡èŒƒå›´ ===\n"
        
        # å°è¯•ç”¨ç®€åŒ–çš„LLMè°ƒç”¨è·å–æ•°æ®èŒƒå›´
        try:
            # æ„å»ºç®€åŒ–çš„æç¤ºè¯
            entities_sample = []
            metrics_sample = []
            
            for theme in themes[:3]:  # åªå–å‰3ä¸ªä¸»é¢˜ä½œä¸ºç¤ºä¾‹
                biz_entities = theme.get('biz_entities', [])
                if isinstance(biz_entities, list):
                    entities_sample.extend(biz_entities[:2])
                    
                biz_metrics = theme.get('biz_metrics', [])  
                if isinstance(biz_metrics, list):
                    metrics_sample.extend(biz_metrics[:2])
            
            # ç®€åŒ–çš„æç¤ºè¯
            simple_prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”¨ä¸€å¥è¯æ¦‚æ‹¬{self.business_context}æ¶‰åŠçš„æ•°æ®èŒƒå›´ï¼š
ä¸šåŠ¡å®ä½“ç¤ºä¾‹ï¼š{', '.join(entities_sample[:5])}
ä¸šåŠ¡æŒ‡æ ‡ç¤ºä¾‹ï¼š{', '.join(metrics_sample[:5])}

è¯·åªå›ç­”æ•°æ®èŒƒå›´ï¼Œæ ¼å¼å¦‚ï¼šæŸæŸæ•°æ®ã€æŸæŸä¿¡æ¯ã€æŸæŸç»Ÿè®¡ç­‰"""

            data_range = await self._call_llm(simple_prompt)
            data_range = data_range.strip()
            
            # å¦‚æœLLMè¿”å›å†…å®¹åˆç†ï¼Œåˆ™ä½¿ç”¨
            if data_range and len(data_range) < 100:
                content += f"å½“å‰æ•°æ®åº“å­˜å‚¨çš„æ˜¯{self.business_context}çš„ç›¸å…³æ•°æ®ï¼Œä¸»è¦æ¶‰åŠ{data_range}ï¼ŒåŒ…å«ä»¥ä¸‹ä¸šåŠ¡æ•°æ®ï¼š\n"
            else:
                raise Exception("LLMè¿”å›å†…å®¹ä¸åˆç†")
                
        except Exception as e:
            self.logger.warning(f"ç®€åŒ–LLMè°ƒç”¨ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨å®Œå…¨å…œåº•æ–¹æ¡ˆ: {e}")
            # çœŸæ­£çš„æœ€åå…œåº•
            content += f"å½“å‰æ•°æ®åº“å­˜å‚¨çš„æ˜¯{self.business_context}çš„ç›¸å…³æ•°æ®ï¼Œä¸»è¦æ¶‰åŠç›¸å…³ä¸šåŠ¡æ•°æ®ï¼ŒåŒ…å«ä»¥ä¸‹ä¸šåŠ¡æ•°æ®ï¼š\n"
        
        content += "æ ¸å¿ƒä¸šåŠ¡å®ä½“ï¼š\n"
        
        # æ”¶é›†æ‰€æœ‰å®ä½“
        all_entities = set()
        for theme in themes:
            biz_entities = theme.get('biz_entities', [])
            if isinstance(biz_entities, list):
                all_entities.update(biz_entities)
        
        for entity in list(all_entities)[:8]:
            content += f"- {entity}ï¼š{entity}ç›¸å…³çš„ä¸šåŠ¡ä¿¡æ¯\n"
        
        content += "å…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼š\n"
        
        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
        all_metrics = set()
        for theme in themes:
            biz_metrics = theme.get('biz_metrics', [])
            if isinstance(biz_metrics, list):
                all_metrics.update(biz_metrics)
        
        for metric in list(all_metrics)[:8]:
            content += f"- {metric}ï¼š{metric}ç›¸å…³çš„åˆ†ææŒ‡æ ‡\n"
        
        return content

    async def _generate_decision_prompt_file(self, themes: List[Dict]):
        """ç”Ÿæˆdb_query_decision_prompt.txtæ–‡ä»¶"""
        decision_prompt_file = self.output_dir / "db_query_decision_prompt.txt"
        
        try:
            # è¯»å–MDå†…å®¹ä½œä¸ºLLMè¾“å…¥
            md_contents = await self.md_analyzer.read_all_md_files()
            
            # ä½¿ç”¨LLMåŠ¨æ€ç”Ÿæˆå†³ç­–æç¤ºå†…å®¹
            decision_content = await self._generate_decision_prompt_with_llm(themes, md_contents)
            
            # å†™å…¥æ–‡ä»¶
            with open(decision_prompt_file, 'w', encoding='utf-8') as f:
                f.write(decision_content)
            
            self.logger.info(f"âœ… db_query_decision_prompt.txtæ–‡ä»¶å·²ç”Ÿæˆ: {decision_prompt_file}")
            return decision_prompt_file
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆdb_query_decision_prompt.txtæ–‡ä»¶å¤±è´¥: {e}")
            # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ
            try:
                fallback_content = await self._generate_fallback_decision_content(themes)
                with open(decision_prompt_file, 'w', encoding='utf-8') as f:
                    f.write(fallback_content)
                self.logger.warning(f"âš ï¸ ä½¿ç”¨å›é€€æ–¹æ¡ˆç”Ÿæˆäº† {decision_prompt_file}")
                return decision_prompt_file
            except Exception as fallback_error:
                self.logger.error(f"å›é€€æ–¹æ¡ˆä¹Ÿå¤±è´¥: {fallback_error}")
                return None
    
    def _escape_sql_string(self, value: str) -> str:
        """è½¬ä¹‰SQLå­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        if not value:
            return ""
        # è½¬ä¹‰å•å¼•å·
        return value.replace("'", "''") 