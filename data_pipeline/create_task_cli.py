"""
Data Pipeline å‘½ä»¤è¡Œä»»åŠ¡åˆ›å»ºå·¥å…·

ä¸“é—¨ç”¨äºæ‰‹åŠ¨åˆ›å»ºä»»åŠ¡ï¼Œç”Ÿæˆmanual_å‰ç¼€çš„task_id
ä»…åˆ›å»ºä»»åŠ¡ç›®å½•ï¼Œä¸æ¶‰åŠæ•°æ®åº“æˆ–é…ç½®æ–‡ä»¶
"""

import argparse
import os
import sys
from datetime import datetime
from pathlib import Path


def generate_manual_task_id() -> str:
    """ç”Ÿæˆæ‰‹åŠ¨ä»»åŠ¡IDï¼Œæ ¼å¼: manual_YYYYMMDD_HHMMSS"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"manual_{timestamp}"


def resolve_base_directory():
    """è§£æåŸºç¡€è¾“å‡ºç›®å½•"""
    try:
        from data_pipeline.config import SCHEMA_TOOLS_CONFIG
        base_dir = SCHEMA_TOOLS_CONFIG.get("output_directory", "./data_pipeline/training_data/")
    except ImportError:
        # å¦‚æœæ— æ³•å¯¼å…¥é…ç½®ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
        base_dir = "./data_pipeline/training_data/"
    
    # å¤„ç†ç›¸å¯¹è·¯å¾„
    if not Path(base_dir).is_absolute():
        # ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•è§£æ
        project_root = Path(__file__).parent.parent
        base_dir = project_root / base_dir
    
    return Path(base_dir)


def create_task_directory(task_id: str, logger) -> Path:
    """åˆ›å»ºä»»åŠ¡ç›®å½•"""
    base_dir = resolve_base_directory()
    task_dir = base_dir / task_id
    
    try:
        task_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"ä»»åŠ¡ç›®å½•å·²åˆ›å»º: {task_dir}")
        return task_dir
    except Exception as e:
        logger.error(f"åˆ›å»ºä»»åŠ¡ç›®å½•å¤±è´¥: {e}")
        raise


def extract_db_name_from_connection(connection_string: str) -> str:
    """ä»æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²ä¸­æå–æ•°æ®åº“åç§°"""
    try:
        if '/' in connection_string:
            db_name = connection_string.split('/')[-1]
            if '?' in db_name:
                db_name = db_name.split('?')[0]
            return db_name if db_name else "database"
        else:
            return "database"
    except Exception:
        return "database"


def setup_argument_parser():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='Data Pipeline ä»»åŠ¡åˆ›å»ºå·¥å…· - åˆ›å»ºæ‰‹åŠ¨æ‰§è¡Œçš„è®­ç»ƒä»»åŠ¡',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬åˆ›å»º
  python -m data_pipeline.create_task_cli --business-context "ç”µå•†ç³»ç»Ÿ" --db-connection "postgresql://user:pass@localhost:5432/ecommerce_db"
  
  # æŒ‡å®šè¡¨æ¸…å•æ–‡ä»¶
  python -m data_pipeline.create_task_cli --table-list tables.txt --business-context "é«˜é€Ÿå…¬è·¯ç®¡ç†ç³»ç»Ÿ" --db-connection "postgresql://user:pass@localhost:5432/highway_db"
  
  # æŒ‡å®šä»»åŠ¡åç§°
  python -m data_pipeline.create_task_cli --task-name "ç”µå•†æ•°æ®è®­ç»ƒ" --business-context "ç”µå•†ç³»ç»Ÿ" --db-connection "postgresql://user:pass@localhost:5432/ecommerce_db"

åˆ›å»ºæˆåŠŸåï¼Œå¯ä»¥ä½¿ç”¨è¿”å›çš„task_idè¿›è¡Œåˆ†æ­¥æ‰§è¡Œï¼š
  python -m data_pipeline.ddl_generation.ddl_md_generator --task-id <task_id> --db-connection "..." --table-list tables.txt --business-context "..."
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        '--business-context',
        required=True,
        help='ä¸šåŠ¡ä¸Šä¸‹æ–‡æè¿°'
    )
    
    parser.add_argument(
        '--db-connection',
        required=True,
        help='æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸² (postgresql://user:pass@host:port/dbname)'
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        '--table-list',
        help='è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--task-name',
        help='ä»»åŠ¡åç§°'
    )
    
    parser.add_argument(
        '--db-name',
        help='æ•°æ®åº“åç§°ï¼ˆå¦‚æœä¸æä¾›ï¼Œå°†ä»è¿æ¥å­—ç¬¦ä¸²ä¸­æå–ï¼‰'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='å¯ç”¨è¯¦ç»†è¾“å‡ºå’Œæ—¥å¿—'
    )
    
    return parser


def print_usage_instructions(task_id: str, task_dir: Path, logger, **params):
    """è¾“å‡ºä½¿ç”¨è¯´æ˜"""
    # æ€»æ˜¯å‘æ§åˆ¶å°è¾“å‡ºç»“æœï¼ŒåŒæ—¶è®°å½•åˆ°æ—¥å¿—
    output_lines = [
        "",
        "=" * 60,
        "ğŸ‰ ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼",
        "=" * 60,
        f"ğŸ“‹ ä»»åŠ¡ID: {task_id}",
        f"ğŸ“ ä»»åŠ¡ç›®å½•: {task_dir}"
    ]
    
    if params.get('task_name'):
        output_lines.append(f"ğŸ¯ ä»»åŠ¡åç§°: {params['task_name']}")
    
    if params.get('db_name'):
        output_lines.append(f"ğŸ—„ï¸  æ•°æ®åº“: {params['db_name']}")
    
    output_lines.append(f"ğŸ¢ ä¸šåŠ¡èƒŒæ™¯: {params['business_context']}")
    
    if params.get('table_list'):
        output_lines.append(f"ğŸ“‹ è¡¨æ¸…å•æ–‡ä»¶: {params['table_list']}")
    
    output_lines.extend([
        "",
        "ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ‰§è¡Œåˆ†æ­¥æ“ä½œï¼š",
        "=" * 60
    ])
    
    # æ„å»ºç¤ºä¾‹å‘½ä»¤
    db_conn = params['db_connection']
    business_context = params['business_context']
    table_list = params.get('table_list', 'tables.txt')
    
    command_lines = [
        "# æ­¥éª¤1: ç”ŸæˆDDLå’ŒMDæ–‡ä»¶",
        f'python -m data_pipeline.ddl_generation.ddl_md_generator \\',
        f'  --task-id {task_id} \\',
        f'  --db-connection "{db_conn}" \\',
        f'  --table-list {table_list} \\',
        f'  --business-context "{business_context}"',
        "",
        "# æ­¥éª¤2: ç”ŸæˆQuestion-SQLå¯¹",
        f'python -m data_pipeline.qa_generation.qs_generator \\',
        f'  --task-id {task_id} \\',
        f'  --table-list {table_list} \\',
        f'  --business-context "{business_context}"',
        "",
        "# æ­¥éª¤3: éªŒè¯å’Œä¿®æ­£SQL",
        f'python -m data_pipeline.validators.sql_validate_cli \\',
        f'  --task-id {task_id} \\',
        f'  --db-connection "{db_conn}"',
        "",
        "# æ­¥éª¤4: è®­ç»ƒæ•°æ®åŠ è½½",
        f'python -m data_pipeline.trainer.run_training \\',
        f'  --task-id {task_id}',
        "",
        "=" * 60
    ]
    
    # è¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆæ€»æ˜¯æ˜¾ç¤ºï¼‰
    for line in output_lines + command_lines:
        print(line)
    
    # è®°å½•åˆ°æ—¥å¿—
    logger.info("ä»»åŠ¡åˆ›å»ºæˆåŠŸæ€»ç»“:")
    for line in output_lines[2:]:  # è·³è¿‡è£…é¥°çº¿
        if line and not line.startswith("="):
            logger.info(f"  {line}")
    
    logger.info("åˆ†æ­¥æ‰§è¡Œå‘½ä»¤:")
    for line in command_lines:
        if line and not line.startswith("#") and line.strip():
            logger.info(f"  {line}")


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    # ç”Ÿæˆä»»åŠ¡ID
    task_id = generate_manual_task_id()
    
    # åˆå§‹åŒ–ç»Ÿä¸€æ—¥å¿—æœåŠ¡
    try:
        from data_pipeline.dp_logging import get_logger
        logger = get_logger("CreateTaskCLI", task_id)
        logger.info(f"å¼€å§‹åˆ›å»ºæ‰‹åŠ¨ä»»åŠ¡: {task_id}")
    except ImportError:
        # å¦‚æœæ— æ³•å¯¼å…¥ç»Ÿä¸€æ—¥å¿—æœåŠ¡ï¼Œåˆ›å»ºç®€å•çš„logger
        import logging
        logger = logging.getLogger("CreateTaskCLI")
        logger.setLevel(logging.INFO)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s: %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        logger.warning("æ— æ³•å¯¼å…¥ç»Ÿä¸€æ—¥å¿—æœåŠ¡ï¼Œä½¿ç”¨ç®€å•æ—¥å¿—")
    
    try:
        logger.info(f"ç”Ÿæˆä»»åŠ¡ID: {task_id}")
        
        # æå–æ•°æ®åº“åç§°
        db_name = args.db_name or extract_db_name_from_connection(args.db_connection)
        logger.info(f"æ•°æ®åº“åç§°: {db_name}")
        
        # éªŒè¯è¡¨æ¸…å•æ–‡ä»¶ï¼ˆå¦‚æœæä¾›ï¼‰
        if args.table_list:
            if not os.path.exists(args.table_list):
                error_msg = f"è¡¨æ¸…å•æ–‡ä»¶ä¸å­˜åœ¨: {args.table_list}"
                logger.error(error_msg)
                sys.exit(1)
            else:
                logger.info(f"è¡¨æ¸…å•æ–‡ä»¶éªŒè¯é€šè¿‡: {args.table_list}")
        
        # åˆ›å»ºä»»åŠ¡ç›®å½•
        task_dir = create_task_directory(task_id, logger)
        
        logger.info(f"ä»»åŠ¡åˆ›å»ºå®Œæˆ: {task_id}")
        logger.info(f"å‚æ•°ä¿¡æ¯: ä¸šåŠ¡èƒŒæ™¯='{args.business_context}', æ•°æ®åº“='{db_name}', è¡¨æ¸…å•='{args.table_list}'")
        
        # è¾“å‡ºä½¿ç”¨è¯´æ˜
        print_usage_instructions(
            task_id=task_id,
            task_dir=task_dir,
            logger=logger,
            task_name=args.task_name,
            db_name=db_name,
            business_context=args.business_context,
            table_list=args.table_list,
            db_connection=args.db_connection
        )
        
        logger.info("ä»»åŠ¡åˆ›å»ºå·¥å…·æ‰§è¡Œå®Œæˆ")
        sys.exit(0)
        
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        sys.exit(130)
    except Exception as e:
        logger.error(f"ä»»åŠ¡åˆ›å»ºå¤±è´¥: {e}", exc_info=args.verbose)
        sys.exit(1)


if __name__ == "__main__":
    main() 