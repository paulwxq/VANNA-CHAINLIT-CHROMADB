{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Vanna Agent Test - åŸºäº create_react_agent çš„å®ç°\n",
        "\n",
        "## ç›®æ ‡\n",
        "ä½¿ç”¨ LangGraph çš„ `create_react_agent()` åˆ›å»ºä¸€ä¸ªåŒ…å«å››ä¸ªå·¥å…·çš„æ™ºèƒ½Agentï¼š\n",
        "1. generate_sql - ç”ŸæˆSQL\n",
        "2. valid_sql - éªŒè¯SQL\n",
        "3. run_sql - æ‰§è¡ŒSQL\n",
        "4. generate_summary - ç”Ÿæˆæ‘˜è¦\n",
        "\n",
        "## æ¶æ„\n",
        "- ä¸‰èŠ‚ç‚¹ç»“æ„ï¼šAgentèŠ‚ç‚¹ â†’ ToolsèŠ‚ç‚¹ â†’ ENDèŠ‚ç‚¹\n",
        "- Agentè‡ªä¸»å†³ç­–æ˜¯å¦éœ€è¦æŸ¥è¯¢æ•°æ®åº“\n",
        "- å¯¹äºå¸¸è¯†é—®é¢˜ç›´æ¥ç”¨LLMå›ç­”"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. ç¯å¢ƒå‡†å¤‡å’Œå¯¼å…¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "é¡¹ç›®æ ¹ç›®å½•: c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\n",
            "commonç›®å½•å­˜åœ¨: True\n",
            "Pythonè·¯å¾„å·²æ›´æ–°: True\n",
            "âœ… å¯¼å…¥å®Œæˆ\n"
          ]
        }
      ],
      "source": [
        "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# æ–¹æ³•1: åŸºäºå½“å‰notebookæ–‡ä»¶ä½ç½®è®¡ç®—é¡¹ç›®æ ¹ç›®å½•\n",
        "current_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
        "project_root = os.path.dirname(current_dir)  # test/ çš„ä¸Šä¸€çº§å°±æ˜¯é¡¹ç›®æ ¹ç›®å½•\n",
        "\n",
        "# æ–¹æ³•2: å¤‡ç”¨æ–¹æ¡ˆï¼Œå¦‚æœæ–¹æ³•1å¤±è´¥\n",
        "if not os.path.exists(os.path.join(project_root, 'common')):\n",
        "    # å°è¯•å½“å‰å·¥ä½œç›®å½•çš„ä¸Šä¸€çº§\n",
        "    project_root = os.path.dirname(os.getcwd())\n",
        "\n",
        "# æ·»åŠ åˆ°Pythonè·¯å¾„\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "print(f\"é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
        "print(f\"commonç›®å½•å­˜åœ¨: {os.path.exists(os.path.join(project_root, 'common'))}\")\n",
        "print(f\"Pythonè·¯å¾„å·²æ›´æ–°: {project_root in sys.path}\")\n",
        "\n",
        "# åŸºç¡€å¯¼å…¥\n",
        "from typing import Dict, Any, List, Optional\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain/LangGraph å¯¼å…¥\n",
        "from langchain.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# é¡¹ç›®å¯¼å…¥\n",
        "from common.vanna_instance import get_vanna_instance\n",
        "from common.utils import get_current_llm_config\n",
        "\n",
        "print(\"âœ… å¯¼å…¥å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… é…ç½®å‚æ•°å·²è®¾ç½®\n",
            "æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°: 10\n",
            "æœ€å¤§è¿”å›è¡Œæ•°: 200\n"
          ]
        }
      ],
      "source": [
        "# ========== å¯é…ç½®å‚æ•° ==========\n",
        "\n",
        "# æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰\n",
        "MAX_TOOL_CALLS = 10\n",
        "\n",
        "# æœ€å¤§è¿”å›è¡Œæ•°\n",
        "MAX_RETURN_ROWS = 200\n",
        "\n",
        "# æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—\n",
        "VERBOSE = True\n",
        "\n",
        "# æ•°æ®åº“ä¸šåŠ¡èŒƒå›´æè¿°ï¼ˆè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰\n",
        "DATABASE_SCOPE = \"\"\"\n",
        "=== æ•°æ®åº“ä¸šåŠ¡èŒƒå›´ ===\n",
        "æœ¬ç³»ç»Ÿæ˜¯é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºå•†ä¸šç®¡ç†ç³»ç»Ÿï¼ŒåŒ…å«ä»¥ä¸‹ä¸šåŠ¡æ•°æ®ï¼š\n",
        "\n",
        "æ ¸å¿ƒä¸šåŠ¡å®ä½“ï¼š\n",
        "- æœåŠ¡åŒº(bss_service_area)ï¼šæœåŠ¡åŒºåŸºç¡€ä¿¡æ¯ã€ä½ç½®ã€çŠ¶æ€\n",
        "- æ¡£å£/å•†é“º(bss_business_day_data)ï¼šæ¡£å£ä¿¡æ¯ã€å“ç±»ã€è¥ä¸šæ•°æ®\n",
        "- è½¦æµé‡(bss_car_day_count)ï¼šæŒ‰è½¦å‹ç»Ÿè®¡çš„æ—¥æµé‡æ•°æ®\n",
        "- å…¬å¸ä¿¡æ¯(bss_company)ï¼šæœåŠ¡åŒºç®¡ç†å…¬å¸\n",
        "\n",
        "å…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼š\n",
        "- æ”¯ä»˜æ–¹å¼ï¼šå¾®ä¿¡æ”¯ä»˜ã€æ”¯ä»˜å®æ”¯ä»˜ã€ç°é‡‘æ”¯ä»˜ç­‰\n",
        "- è¥ä¸šæ•°æ®ï¼šæ”¯ä»˜é‡‘é¢ã€è®¢å•æ•°é‡ã€è¥ä¸šé¢ã€æ”¶å…¥ç»Ÿè®¡\n",
        "- è½¦æµç»Ÿè®¡ï¼šæŒ‰è½¦å‹çš„æµé‡åˆ†æ\n",
        "- ç»è¥åˆ†æï¼šé¤é¥®ã€å°åƒã€ä¾¿åˆ©åº—ç­‰å“ç±»æ”¶å…¥\n",
        "\n",
        "æ—¶é—´èŒƒå›´ï¼š\n",
        "- æ•°æ®æ›´æ–°åˆ°æœ€è¿‘çš„è¥ä¸šæ—¥\n",
        "- å†å²æ•°æ®å¯è¿½æº¯åˆ°ç³»ç»Ÿä¸Šçº¿æ—¶é—´\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… é…ç½®å‚æ•°å·²è®¾ç½®\")\n",
        "print(f\"æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°: {MAX_TOOL_CALLS}\")\n",
        "print(f\"æœ€å¤§è¿”å›è¡Œæ•°: {MAX_RETURN_ROWS}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. è·å–LLMå®ä¾‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: qwen-plus\n",
            "ğŸ”§ ä¸ºæ¨¡å‹ qwen-plus è®¾ç½® enable_thinking=False\n",
            "âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\n"
          ]
        }
      ],
      "source": [
        "def get_llm():\n",
        "    \"\"\"è·å–å…¼å®¹çš„LLMå®ä¾‹\"\"\"\n",
        "    try:\n",
        "        # å°è¯•ä½¿ç”¨OpenAIå…¼å®¹çš„API\n",
        "        from langchain_openai import ChatOpenAI\n",
        "        from common.utils import get_current_llm_config\n",
        "        \n",
        "        llm_config = get_current_llm_config()\n",
        "        \n",
        "        if llm_config.get(\"base_url\") and llm_config.get(\"api_key\"):\n",
        "            # æ„å»ºå‚æ•°ï¼Œç¡®ä¿thinkingåŠŸèƒ½æ­£ç¡®è®¾ç½®\n",
        "            model_name = llm_config.get(\"model\", \"\").lower()\n",
        "            print(f\"ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: {model_name}\")\n",
        "            \n",
        "            # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨model_kwargsä¼ é€’å‚æ•°\n",
        "            model_kwargs = {}\n",
        "            if \"deepseek\" in model_name or \"qianwen\" in model_name or \"qwen\" in model_name:\n",
        "                model_kwargs[\"enable_thinking\"] = False\n",
        "                print(f\"ğŸ”§ ä¸ºæ¨¡å‹ {model_name} è®¾ç½® enable_thinking=False\")\n",
        "            \n",
        "            llm = ChatOpenAI(\n",
        "                base_url=llm_config.get(\"base_url\"),\n",
        "                api_key=llm_config.get(\"api_key\"),\n",
        "                model=llm_config.get(\"model\"),\n",
        "                temperature=llm_config.get(\"temperature\", 0.7),\n",
        "                model_kwargs=model_kwargs\n",
        "            )\n",
        "            print(\"âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\")\n",
        "            return llm\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ OpenAI APIæ–¹æ³•1å¤±è´¥: {e}\")\n",
        "        \n",
        "        # æ–¹æ³•2ï¼šå°è¯•ä½¿ç”¨extra_body\n",
        "        try:\n",
        "            from langchain_openai import ChatOpenAI\n",
        "            from common.utils import get_current_llm_config\n",
        "            \n",
        "            llm_config = get_current_llm_config()\n",
        "            \n",
        "            if llm_config.get(\"base_url\") and llm_config.get(\"api_key\"):\n",
        "                model_name = llm_config.get(\"model\", \"\").lower()\n",
        "                \n",
        "                llm = ChatOpenAI(\n",
        "                    base_url=llm_config.get(\"base_url\"),\n",
        "                    api_key=llm_config.get(\"api_key\"),\n",
        "                    model=llm_config.get(\"model\"),\n",
        "                    temperature=llm_config.get(\"temperature\", 0.7),\n",
        "                    extra_body={\"enable_thinking\": False}\n",
        "                )\n",
        "                print(\"âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•2ï¼šextra_bodyï¼‰\")\n",
        "                return llm\n",
        "        except Exception as e2:\n",
        "            print(f\"âš ï¸ OpenAI APIæ–¹æ³•2å¤±è´¥: {e2}\")\n",
        "    \n",
        "    # å›é€€æ–¹æ¡ˆï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„åŒ…è£…å™¨\n",
        "    from langchain_core.language_models import BaseChatModel\n",
        "    from langchain_core.messages import BaseMessage, AIMessage\n",
        "    from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "    \n",
        "    class VannaLLMWrapper(BaseChatModel):\n",
        "        \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "        \n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.vn = get_vanna_instance()\n",
        "        \n",
        "        def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "            # æ„å»ºæç¤ºè¯\n",
        "            prompt = \"\"\n",
        "            for msg in messages:\n",
        "                if isinstance(msg, SystemMessage):\n",
        "                    prompt = msg.content + \"\\n\\n\"\n",
        "                elif isinstance(msg, HumanMessage):\n",
        "                    prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "                elif isinstance(msg, AIMessage):\n",
        "                    prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "            \n",
        "            # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinking\n",
        "            try:\n",
        "                # ç›´æ¥è°ƒç”¨é¡¹ç›®ä¸­çš„LLMå®ä¾‹ï¼Œå®ƒåº”è¯¥å·²ç»æ­£ç¡®é…ç½®äº†thinkingå‚æ•°\n",
        "                response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            except TypeError:\n",
        "                # å¦‚æœä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤è°ƒç”¨\n",
        "                try:\n",
        "                    response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                except TypeError:\n",
        "                    # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                    response = self.vn.chat_with_llm(question=prompt)\n",
        "            \n",
        "            # è¿”å›ç»“æœ\n",
        "            message = AIMessage(content=response)\n",
        "            generation = ChatGeneration(message=message)\n",
        "            return ChatResult(generations=[generation])\n",
        "        \n",
        "        @property\n",
        "        def _llm_type(self) -> str:\n",
        "            return \"vanna_wrapper\"\n",
        "    \n",
        "    print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "    return VannaLLMWrapper()\n",
        "\n",
        "# è·å–LLMå®ä¾‹\n",
        "llm = get_llm()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:40:13,350 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:40:23,136 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:40:23,137 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:40:23,138 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:40:23,139 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:40:23,139 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:40:23,140 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:40:23,142 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:40:23,142 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:40:23,143 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:40:23,144 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:40:23,393 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:40:23,394 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:40:23,395 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:40:23,396 - vanna.BaseLLMChat - INFO -   model: qwen-plus\n",
            "2025-07-08 09:40:23,397 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:40:23,398 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:40:23,398 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:40:23,399 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:40:23,399 - vanna.BaseLLMChat - INFO -   stream: False\n",
            "2025-07-08 09:40:23,399 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:40:23,400 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:40:23,400 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000024E2E5135C0>\n",
            "2025-07-08 09:40:23,401 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:40:23,402 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:40:24,662 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:40:24,663 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n",
            "2025-07-08 09:40:24,668 - vanna.BaseLLMChat - INFO - \n",
            "Using model qwen-plus for 18.5 tokens (approx)\n",
            "2025-07-08 09:40:24,668 - vanna.BaseLLMChat - INFO - Enable thinking: False, Stream mode: False\n",
            "2025-07-08 09:40:24,669 - vanna.BaseLLMChat - INFO - ä½¿ç”¨éæµå¼å¤„ç†æ¨¡å¼\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\n",
            "\n",
            "ğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\n",
            "ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\n",
            "âœ… LLMæµ‹è¯•æˆåŠŸ: æµ‹è¯•æˆåŠŸ\n"
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    # ä½¿ç”¨ç±»é…ç½®å…è®¸é¢å¤–å­—æ®µ\n",
        "    model_config = {\"extra\": \"allow\"}\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # åœ¨åˆå§‹åŒ–åè®¾ç½®vnå®ä¾‹\n",
        "        object.__setattr__(self, 'vn', get_vanna_instance())\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:28:50,209 - app.VannaSingleton - INFO - åˆ›å»º Vanna å®ä¾‹...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 09:29:00,759 - app.ConfigUtils - INFO - === å½“å‰æ¨¡å‹é…ç½® ===\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæä¾›å•†: api\n",
            "2025-07-08 09:29:00,762 - app.ConfigUtils - INFO - LLMæ¨¡å‹: qianwen\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæä¾›å•†: api\n",
            "2025-07-08 09:29:00,763 - app.ConfigUtils - INFO - Embeddingæ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - å‘é‡æ•°æ®åº“: pgvector\n",
            "2025-07-08 09:29:00,764 - app.ConfigUtils - INFO - ==================\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - åˆ›å»ºQIANWEN+PGVECTORå®ä¾‹\n",
            "2025-07-08 09:29:00,765 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨PgVectorï¼Œè¿æ¥å­—ç¬¦ä¸²: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:00,766 - vanna.VannaFactory - INFO - å·²é…ç½®ä½¿ç”¨APIåµŒå…¥æ¨¡å‹: text-embedding-v4\n",
            "2025-07-08 09:29:01,087 - vanna.BaseLLMChat - INFO - ä¼ å…¥çš„ config å‚æ•°å¦‚ä¸‹ï¼š\n",
            "2025-07-08 09:29:01,088 - vanna.BaseLLMChat - INFO -   api_key: sk-db68e37f00974031935395315bfe07f0\n",
            "2025-07-08 09:29:01,089 - vanna.BaseLLMChat - INFO -   base_url: https://dashscope.aliyuncs.com/compatible-mode/v1\n",
            "2025-07-08 09:29:01,090 - vanna.BaseLLMChat - INFO -   model: qwen3-235b-a22b\n",
            "2025-07-08 09:29:01,091 - vanna.BaseLLMChat - INFO -   allow_llm_to_see_data: True\n",
            "2025-07-08 09:29:01,092 - vanna.BaseLLMChat - INFO -   temperature: 0.6\n",
            "2025-07-08 09:29:01,093 - vanna.BaseLLMChat - INFO -   n_results: 6\n",
            "2025-07-08 09:29:01,094 - vanna.BaseLLMChat - INFO -   language: Chinese\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   stream: True\n",
            "2025-07-08 09:29:01,095 - vanna.BaseLLMChat - INFO -   enable_thinking: False\n",
            "2025-07-08 09:29:01,096 - vanna.BaseLLMChat - INFO -   connection_string: postgresql://postgres:postgres@192.168.67.1:5432/highway_pgvector_db\n",
            "2025-07-08 09:29:01,097 - vanna.BaseLLMChat - INFO -   embedding_function: <core.embedding_function.EmbeddingFunction object at 0x0000018A8D2376B0>\n",
            "2025-07-08 09:29:01,098 - vanna.BaseLLMChat - INFO - temperature is changed to: 0.6\n",
            "2025-07-08 09:29:01,099 - vanna.BaseLLMChat - INFO - QianWenChat init\n",
            "2025-07-08 09:29:02,512 - vanna.VannaFactory - INFO - å·²è¿æ¥åˆ°ä¸šåŠ¡æ•°æ®åº“: 192.168.67.1:6432/highway_db\n",
            "2025-07-08 09:29:02,513 - app.VannaSingleton - INFO - Vanna å®ä¾‹åˆ›å»ºæˆåŠŸ\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\"VannaLLMWrapper\" object has no field \"vn\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 55\u001b[39m\n",
            "\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvanna_wrapper\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# åˆ›å»ºLLMå®ä¾‹\u001b[39;00m\n",
            "\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m llm = \u001b[43mVannaLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\u001b[39;00m\n",
            "\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mVannaLLMWrapper.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
            "\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvn\u001b[49m = get_vanna_instance()\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:997\u001b[39m, in \u001b[36mBaseModel.__setattr__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m    995\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n",
            "\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n",
            "\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setattr_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m    998\u001b[39m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n",
            "\u001b[32m    999\u001b[39m     \u001b[38;5;28mself\u001b[39m.__pydantic_setattr_handlers__[name] = setattr_handler\n",
            "\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\pydantic\\main.py:1044\u001b[39m, in \u001b[36mBaseModel._setattr_handler\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n",
            "\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__pydantic_fields__:\n",
            "\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.model_config.get(\u001b[33m'\u001b[39m\u001b[33mextra\u001b[39m\u001b[33m'\u001b[39m) != \u001b[33m'\u001b[39m\u001b[33mallow\u001b[39m\u001b[33m'\u001b[39m:\n",
            "\u001b[32m   1043\u001b[39m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n",
            "\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m object has no field \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n",
            "\u001b[32m   1047\u001b[39m         \u001b[38;5;28mself\u001b[39m.__pydantic_extra__[name] = value\n",
            "\n",
            "\u001b[31mValueError\u001b[39m: \"VannaLLMWrapper\" object has no field \"vn\""
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# ç”±äºChatOpenAIä¸æ”¯æŒenable_thinkingå‚æ•°ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "print(\"âš ï¸  æ£€æµ‹åˆ°thinkingå‚æ•°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨VannaåŒ…è£…å™¨...\")\n",
        "\n",
        "# ç›´æ¥åˆ›å»ºVannaåŒ…è£…å™¨\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "\n",
        "class VannaLLMWrapper(BaseChatModel):\n",
        "    \"\"\"Vanna LLMçš„LangChainåŒ…è£…å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vn = get_vanna_instance()\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
        "        # æ„å»ºæç¤ºè¯\n",
        "        prompt = \"\"\n",
        "        for msg in messages:\n",
        "            if isinstance(msg, SystemMessage):\n",
        "                prompt = msg.content + \"\\n\\n\"\n",
        "            elif isinstance(msg, HumanMessage):\n",
        "                prompt += f\"ç”¨æˆ·: {msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                prompt += f\"åŠ©æ‰‹: {msg.content}\\n\"\n",
        "        \n",
        "        # è°ƒç”¨Vannaï¼Œç¡®ä¿ç¦ç”¨thinkingå’Œstream\n",
        "        try:\n",
        "            # å°è¯•ç¦ç”¨thinkingå’Œstream\n",
        "            response = self.vn.chat_with_llm(question=prompt, enable_thinking=False, stream=False)\n",
        "            print(\"ğŸ”§ æˆåŠŸç¦ç”¨thinkingå’Œstream\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # å°è¯•åªç¦ç”¨stream\n",
        "                response = self.vn.chat_with_llm(question=prompt, stream=False)\n",
        "                print(\"ğŸ”§ æˆåŠŸç¦ç”¨stream\")\n",
        "            except TypeError:\n",
        "                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ\n",
        "                response = self.vn.chat_with_llm(question=prompt)\n",
        "                print(\"ğŸ”§ ä½¿ç”¨é»˜è®¤è°ƒç”¨\")\n",
        "        \n",
        "        # è¿”å›ç»“æœ\n",
        "        message = AIMessage(content=response)\n",
        "        generation = ChatGeneration(message=message)\n",
        "        return ChatResult(generations=[generation])\n",
        "    \n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vanna_wrapper\"\n",
        "\n",
        "# åˆ›å»ºLLMå®ä¾‹\n",
        "llm = VannaLLMWrapper()\n",
        "print(\"âœ… ä½¿ç”¨Vanna LLMåŒ…è£…å™¨\")\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"æ£€æŸ¥Vannaå®ä¾‹æ˜¯å¦æ­£å¸¸å·¥ä½œ...\")\n",
        "    \n",
        "    # ç›´æ¥æµ‹è¯•Vannaå®ä¾‹\n",
        "    try:\n",
        "        vn = get_vanna_instance()\n",
        "        direct_response = vn.chat_with_llm(question=\"æµ‹è¯•\", stream=False)\n",
        "        print(f\"âœ… Vannaç›´æ¥è°ƒç”¨æˆåŠŸ: {direct_response}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âŒ Vannaç›´æ¥è°ƒç”¨ä¹Ÿå¤±è´¥: {e2}\")\n",
        "        print(\"è¯·æ£€æŸ¥æ‚¨çš„LLMé…ç½®å’Œç½‘ç»œè¿æ¥\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: qwen3-235b-a22b\n",
            "ğŸ”§ ä¸ºæ¨¡å‹ qwen3-235b-a22b è®¾ç½® enable_thinking=False\n",
            "âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\n",
            "\n",
            "ğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\n",
            "âŒ LLMæµ‹è¯•å¤±è´¥: Completions.create() got an unexpected keyword argument 'enable_thinking'\n",
            "å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\n"
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# é‡æ–°è·å–LLMå®ä¾‹\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "llm = get_llm()\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: qwen3-235b-a22b\n",
            "ğŸ”§ ä¸ºæ¨¡å‹ qwen3-235b-a22b è®¾ç½® enable_thinking=False\n",
            "âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\n",
            "\n",
            "ğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\n",
            "âŒ LLMæµ‹è¯•å¤±è´¥: Completions.create() got an unexpected keyword argument 'enable_thinking'\n",
            "å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\n"
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# é‡æ–°è·å–LLMå®ä¾‹\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "llm = get_llm()\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: qwen3-235b-a22b\n",
            "ğŸ”§ ä¸ºæ¨¡å‹ qwen3-235b-a22b è®¾ç½® enable_thinking=False\n",
            "âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\n",
            "\n",
            "ğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\n",
            "âŒ LLMæµ‹è¯•å¤±è´¥: Completions.create() got an unexpected keyword argument 'enable_thinking'\n",
            "å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\n"
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# é‡æ–°è·å–LLMå®ä¾‹\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "llm = get_llm()\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: qwen3-235b-a22b\n",
            "ğŸ”§ ä¸ºæ¨¡å‹ qwen3-235b-a22b è®¾ç½® enable_thinking=False\n",
            "âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\n",
            "\n",
            "ğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\n",
            "âŒ LLMæµ‹è¯•å¤±è´¥: Completions.create() got an unexpected keyword argument 'enable_thinking'\n",
            "å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\n"
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# é‡æ–°è·å–LLMå®ä¾‹\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "llm = get_llm()\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: qwen3-235b-a22b\n",
            "ğŸ”§ ä¸ºæ¨¡å‹ qwen3-235b-a22b è®¾ç½® enable_thinking=False\n",
            "âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\n",
            "\n",
            "ğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\n",
            "âŒ LLMæµ‹è¯•å¤±è´¥: Completions.create() got an unexpected keyword argument 'enable_thinking'\n",
            "å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\n"
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# é‡æ–°è·å–LLMå®ä¾‹\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "llm = get_llm()\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\n",
            "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹: qwen3-235b-a22b\n",
            "ğŸ”§ ä¸ºæ¨¡å‹ qwen3-235b-a22b è®¾ç½® enable_thinking=False\n",
            "âœ… ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆæ–¹æ³•1ï¼šmodel_kwargsï¼‰\n",
            "\n",
            "ğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\n",
            "âŒ LLMæµ‹è¯•å¤±è´¥: Completions.create() got an unexpected keyword argument 'enable_thinking'\n",
            "å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\n"
          ]
        }
      ],
      "source": [
        "## 3.1 é‡æ–°åˆ›å»ºLLMå®ä¾‹ï¼ˆè§£å†³thinkingå‚æ•°é—®é¢˜ï¼‰\n",
        "\n",
        "# é‡æ–°è·å–LLMå®ä¾‹\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºLLMå®ä¾‹...\")\n",
        "llm = get_llm()\n",
        "\n",
        "# æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½\n",
        "print(\"\\nğŸ§ª æµ‹è¯•LLMåŸºç¡€åŠŸèƒ½...\")\n",
        "try:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    test_response = llm.invoke([HumanMessage(content=\"è¯·å›å¤'æµ‹è¯•æˆåŠŸ'\")])\n",
        "    print(f\"âœ… LLMæµ‹è¯•æˆåŠŸ: {test_response.content}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLMæµ‹è¯•å¤±è´¥: {e}\")\n",
        "    print(\"å¦‚æœä»ç„¶æœ‰thinkingé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ‚¨çš„app_config.pyä¸­çš„LLMé…ç½®\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. å®šä¹‰å·¥å…·å‡½æ•°\n",
        "### 4.1 generate_sql å·¥å…·"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… generate_sql å·¥å…·å·²å®šä¹‰\n"
          ]
        }
      ],
      "source": [
        "@tool\n",
        "def generate_sql(question: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢ã€‚\n",
        "    \n",
        "    Args:\n",
        "        question: éœ€è¦è½¬æ¢ä¸ºSQLçš„è‡ªç„¶è¯­è¨€é—®é¢˜\n",
        "    \n",
        "    Returns:\n",
        "        åŒ…å«SQLç”Ÿæˆç»“æœçš„å­—å…¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if VERBOSE:\n",
        "            print(f\"ğŸ”§ [generate_sql] è¾“å…¥é—®é¢˜: {question}\")\n",
        "        \n",
        "        vn = get_vanna_instance()\n",
        "        sql = vn.generate_sql(question=question, allow_llm_to_see_data=True)\n",
        "        \n",
        "        if sql is None:\n",
        "            # æ£€æŸ¥æ˜¯å¦æœ‰è§£é‡Šæ€§æ–‡æœ¬\n",
        "            explanation = getattr(vn, 'last_llm_explanation', None)\n",
        "            if explanation:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"sql\": None,\n",
        "                    \"error\": explanation,\n",
        "                    \"error_type\": \"no_relevant_data\"\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"sql\": None,\n",
        "                    \"error\": \"æ— æ³•ç”ŸæˆSQLæŸ¥è¯¢ï¼Œå¯èƒ½æ˜¯é—®é¢˜æè¿°ä¸å¤Ÿæ˜ç¡®æˆ–æ•°æ®è¡¨ç»“æ„ä¸åŒ¹é…\",\n",
        "                    \"error_type\": \"generation_failed\"\n",
        "                }\n",
        "        \n",
        "        if VERBOSE:\n",
        "            print(f\"âœ… [generate_sql] ç”Ÿæˆçš„SQL: {sql}\")\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"sql\": sql,\n",
        "            \"error\": None\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"sql\": None,\n",
        "            \"error\": f\"SQLç”Ÿæˆå¼‚å¸¸: {str(e)}\",\n",
        "            \"error_type\": \"exception\"\n",
        "        }\n",
        "\n",
        "print(\"âœ… generate_sql å·¥å…·å·²å®šä¹‰\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 4.2 valid_sql å·¥å…·"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… valid_sql å·¥å…·å·²å®šä¹‰\n"
          ]
        }
      ],
      "source": [
        "@tool\n",
        "def valid_sql(sql: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    éªŒè¯SQLè¯­å¥çš„æ­£ç¡®æ€§ã€‚\n",
        "    \n",
        "    Args:\n",
        "        sql: è¦éªŒè¯çš„SQLè¯­å¥\n",
        "    \n",
        "    Returns:\n",
        "        åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if VERBOSE:\n",
        "            print(f\"ğŸ”§ [valid_sql] éªŒè¯SQL: {sql[:100]}...\")\n",
        "        \n",
        "        # 1. åŸºç¡€æ ¼å¼æ£€æŸ¥\n",
        "        if not sql or not sql.strip():\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"valid\": False,\n",
        "                \"error\": \"SQLè¯­å¥ä¸ºç©º\"\n",
        "            }\n",
        "        \n",
        "        # 2. ç¦æ­¢è¯æ£€æŸ¥\n",
        "        forbidden_operations = ['UPDATE', 'DELETE', 'DROP', 'ALTER', 'INSERT']\n",
        "        sql_upper = sql.upper().strip()\n",
        "        \n",
        "        for operation in forbidden_operations:\n",
        "            if sql_upper.startswith(operation):\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"valid\": False,\n",
        "                    \"error\": f\"ä¸å…è®¸çš„æ“ä½œ: {operation}ã€‚æœ¬ç³»ç»Ÿåªæ”¯æŒæŸ¥è¯¢æ“ä½œ(SELECT)ã€‚\"\n",
        "                }\n",
        "        \n",
        "        # 3. è¯­æ³•éªŒè¯ï¼ˆä½¿ç”¨EXPLAINï¼‰\n",
        "        vn = get_vanna_instance()\n",
        "        explain_sql = f\"EXPLAIN {sql}\"\n",
        "        \n",
        "        try:\n",
        "            result = vn.run_sql(explain_sql)\n",
        "            if result is not None:\n",
        "                if VERBOSE:\n",
        "                    print(\"âœ… [valid_sql] SQLéªŒè¯é€šè¿‡\")\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"valid\": True,\n",
        "                    \"error\": None\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"valid\": False,\n",
        "                    \"error\": \"SQLè¯­æ³•éªŒè¯å¤±è´¥\"\n",
        "                }\n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            if VERBOSE:\n",
        "                print(f\"âŒ [valid_sql] éªŒè¯å¤±è´¥: {error_msg}\")\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"valid\": False,\n",
        "                \"error\": f\"SQLè¯­æ³•é”™è¯¯: {error_msg}\"\n",
        "            }\n",
        "            \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"valid\": False,\n",
        "            \"error\": f\"éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}\"\n",
        "        }\n",
        "\n",
        "print(\"âœ… valid_sql å·¥å…·å·²å®šä¹‰\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 4.3 run_sql å·¥å…·\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… run_sql å·¥å…·å·²å®šä¹‰\n"
          ]
        }
      ],
      "source": [
        "@tool\n",
        "def run_sql(sql: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶è¿”å›ç»“æœã€‚\n",
        "    \n",
        "    Args:\n",
        "        sql: è¦æ‰§è¡Œçš„SQLæŸ¥è¯¢è¯­å¥\n",
        "    \n",
        "    Returns:\n",
        "        åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if VERBOSE:\n",
        "            print(f\"ğŸ”§ [run_sql] æ‰§è¡ŒSQL: {sql[:100]}...\")\n",
        "        \n",
        "        vn = get_vanna_instance()\n",
        "        df = vn.run_sql(sql)\n",
        "        \n",
        "        if df is None:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"data\": None,\n",
        "                \"error\": \"SQLæ‰§è¡Œè¿”å›ç©ºç»“æœ\",\n",
        "                \"row_count\": 0\n",
        "            }\n",
        "        \n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"data\": None,\n",
        "                \"error\": f\"SQLæ‰§è¡Œè¿”å›éDataFrameç±»å‹: {type(df)}\",\n",
        "                \"row_count\": 0\n",
        "            }\n",
        "        \n",
        "        if df.empty:\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"data\": [],\n",
        "                \"columns\": list(df.columns),\n",
        "                \"row_count\": 0,\n",
        "                \"message\": \"æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®\"\n",
        "            }\n",
        "        \n",
        "        # å¤„ç†æ•°æ®ç»“æœ\n",
        "        total_rows = len(df)\n",
        "        limited_df = df.head(MAX_RETURN_ROWS)\n",
        "        \n",
        "        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼\n",
        "        rows = limited_df.to_dict(orient=\"records\")\n",
        "        columns = list(df.columns)\n",
        "        \n",
        "        if VERBOSE:\n",
        "            print(f\"âœ… [run_sql] æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {total_rows} è¡Œæ•°æ®\")\n",
        "        \n",
        "        result = {\n",
        "            \"success\": True,\n",
        "            \"data\": rows,\n",
        "            \"columns\": columns,\n",
        "            \"row_count\": len(rows),\n",
        "            \"total_row_count\": total_rows,\n",
        "            \"is_limited\": total_rows > MAX_RETURN_ROWS\n",
        "        }\n",
        "        \n",
        "        if total_rows > MAX_RETURN_ROWS:\n",
        "            result[\"message\"] = f\"å…± {total_rows} è¡Œæ•°æ®ï¼Œå·²é™åˆ¶æ˜¾ç¤ºå‰ {MAX_RETURN_ROWS} è¡Œ\"\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        if VERBOSE:\n",
        "            print(f\"âŒ [run_sql] æ‰§è¡Œå¤±è´¥: {error_msg}\")\n",
        "        \n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"data\": None,\n",
        "            \"error\": f\"SQLæ‰§è¡Œå¤±è´¥: {error_msg}\",\n",
        "            \"row_count\": 0\n",
        "        }\n",
        "\n",
        "print(\"âœ… run_sql å·¥å…·å·²å®šä¹‰\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 4.4 generate_summary å·¥å…·\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… generate_summary å·¥å…·å·²å®šä¹‰\n"
          ]
        }
      ],
      "source": [
        "@tool\n",
        "def generate_summary(question: str, query_result: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    ä¸ºæŸ¥è¯¢ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€æ‘˜è¦ã€‚\n",
        "    \n",
        "    Args:\n",
        "        question: åŸå§‹é—®é¢˜\n",
        "        query_result: æŸ¥è¯¢ç»“æœçš„JSONå­—ç¬¦ä¸²\n",
        "    \n",
        "    Returns:\n",
        "        åŒ…å«æ‘˜è¦ç»“æœçš„å­—å…¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if VERBOSE:\n",
        "            print(f\"ğŸ”§ [generate_summary] ä¸ºé—®é¢˜ç”Ÿæˆæ‘˜è¦: {question}\")\n",
        "        \n",
        "        # è§£ææŸ¥è¯¢ç»“æœ\n",
        "        try:\n",
        "            result_data = json.loads(query_result) if isinstance(query_result, str) else query_result\n",
        "        except:\n",
        "            result_data = {\"error\": \"æ— æ³•è§£ææŸ¥è¯¢ç»“æœ\"}\n",
        "        \n",
        "        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®\n",
        "        if not result_data.get(\"success\") or not result_data.get(\"data\"):\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"summary\": \"æŸ¥è¯¢æ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®ã€‚\"\n",
        "            }\n",
        "        \n",
        "        # é‡æ„DataFrameç”¨äºæ‘˜è¦ç”Ÿæˆ\n",
        "        rows = result_data.get(\"data\", [])\n",
        "        columns = result_data.get(\"columns\", [])\n",
        "        \n",
        "        if rows and columns:\n",
        "            df = pd.DataFrame(rows, columns=columns)\n",
        "            \n",
        "            # è°ƒç”¨Vannaç”Ÿæˆæ‘˜è¦\n",
        "            vn = get_vanna_instance()\n",
        "            summary = vn.generate_summary(question=question, df=df)\n",
        "            \n",
        "            if summary:\n",
        "                if VERBOSE:\n",
        "                    print(f\"âœ… [generate_summary] æ‘˜è¦ç”ŸæˆæˆåŠŸ\")\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"summary\": summary\n",
        "                }\n",
        "        \n",
        "        # ç”Ÿæˆé»˜è®¤æ‘˜è¦\n",
        "        row_count = result_data.get(\"row_count\", 0)\n",
        "        summary = f\"æ ¹æ®æ‚¨çš„é—®é¢˜ã€{question}ã€ï¼ŒæŸ¥è¯¢è¿”å›äº† {row_count} æ¡è®°å½•ã€‚\"\n",
        "        \n",
        "        if columns:\n",
        "            summary += f\"æ•°æ®åŒ…å«ä»¥ä¸‹å­—æ®µï¼š{', '.join(columns[:5])}\" \n",
        "            if len(columns) > 5:\n",
        "                summary += f\"ç­‰{len(columns)}ä¸ªå­—æ®µã€‚\"\n",
        "            else:\n",
        "                summary += \"ã€‚\"\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"summary\": summary\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        if VERBOSE:\n",
        "            print(f\"âŒ [generate_summary] ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}\")\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"summary\": f\"æŸ¥è¯¢æ‰§è¡Œå®Œæˆï¼Œå…±è¿”å›æ•°æ®ã€‚\"\n",
        "        }\n",
        "\n",
        "print(\"âœ… generate_summary å·¥å…·å·²å®šä¹‰\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. åˆ›å»º ReAct Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… å·¥å…·åˆ—è¡¨å·²å‡†å¤‡\n",
            "å¯ç”¨å·¥å…·: ['generate_sql', 'valid_sql', 'run_sql', 'generate_summary']\n"
          ]
        }
      ],
      "source": [
        "# ç³»ç»Ÿæç¤ºè¯\n",
        "SYSTEM_MESSAGE = f\"\"\"\n",
        "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ•°æ®æŸ¥è¯¢åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢æ•°æ®åº“ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥å›ç­”ä¸€èˆ¬æ€§é—®é¢˜ã€‚\n",
        "\n",
        "{DATABASE_SCOPE}\n",
        "\n",
        "=== å·¥ä½œæµç¨‹ ===\n",
        "1. åˆ¤æ–­é—®é¢˜ç±»å‹ï¼š\n",
        "   - å¦‚æœé—®é¢˜æ¶‰åŠä¸Šè¿°ä¸šåŠ¡æ•°æ®ï¼Œä½¿ç”¨å·¥å…·æŸ¥è¯¢æ•°æ®åº“\n",
        "   - å¦‚æœæ˜¯å¸¸è¯†æ€§é—®é¢˜ï¼ˆå¦‚\"è”æå‡ æœˆä¸Šå¸‚\"ï¼‰ï¼Œç›´æ¥ç”¨ä½ çš„çŸ¥è¯†å›ç­”\n",
        "\n",
        "2. æ•°æ®åº“æŸ¥è¯¢æµç¨‹ï¼š\n",
        "   a) ä½¿ç”¨ generate_sql ç”ŸæˆSQL\n",
        "   b) ä½¿ç”¨ valid_sql éªŒè¯SQL\n",
        "   c) å¦‚æœéªŒè¯é€šè¿‡ï¼Œä½¿ç”¨ run_sql æ‰§è¡ŒSQL\n",
        "   d) ä½¿ç”¨ generate_summary ç”Ÿæˆç»“æœæ‘˜è¦\n",
        "\n",
        "3. é”™è¯¯å¤„ç†ï¼š\n",
        "   - å¦‚æœæ— æ³•ç”ŸæˆSQLï¼Œè¯´æ˜æ•°æ®åº“ä¸­å¯èƒ½æ²¡æœ‰ç›¸å…³æ•°æ®\n",
        "   - å¯¹äºè¾¹ç•Œé—®é¢˜ï¼Œå¯ä»¥å…ˆå°è¯•æŸ¥è¯¢ï¼Œå¦‚æœå¤±è´¥åˆ™ç”¨å¸¸è¯†å›ç­”\n",
        "\n",
        "4. æ³¨æ„äº‹é¡¹ï¼š\n",
        "   - æ¯ä¸ªå·¥å…·è°ƒç”¨éƒ½è¦æ£€æŸ¥è¿”å›çš„ success å­—æ®µ\n",
        "   - å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œæ ¹æ® error ä¿¡æ¯å†³å®šä¸‹ä¸€æ­¥\n",
        "   - é¿å…é‡å¤è°ƒç”¨ç›¸åŒçš„å·¥å…·è¶…è¿‡2æ¬¡\n",
        "\n",
        "è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œæ™ºèƒ½é€‰æ‹©åˆé€‚çš„å¤„ç†æ–¹å¼ã€‚\n",
        "\"\"\"\n",
        "\n",
        "# åˆ›å»ºå·¥å…·åˆ—è¡¨\n",
        "tools = [generate_sql, valid_sql, run_sql, generate_summary]\n",
        "\n",
        "print(\"âœ… å·¥å…·åˆ—è¡¨å·²å‡†å¤‡\")\n",
        "print(f\"å¯ç”¨å·¥å…·: {[tool.name for tool in tools]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5.0 é‡æ–°åˆ›å»ºAgentï¼ˆä½¿ç”¨ä¿®å¤åçš„LLMï¼‰\n",
        "\n",
        "# é‡æ–°åˆ›å»ºAgent\n",
        "print(\"ğŸ”„ é‡æ–°åˆ›å»ºAgent...\")\n",
        "\n",
        "agent = None\n",
        "success_method = None\n",
        "\n",
        "# åŸºç¡€åˆ›å»ºï¼ˆç³»ç»Ÿæ¶ˆæ¯å°†åœ¨è°ƒç”¨æ—¶å¤„ç†ï¼‰\n",
        "try:\n",
        "    agent = create_react_agent(\n",
        "        llm,\n",
        "        tools=tools\n",
        "    )\n",
        "    success_method = \"åŸºç¡€åˆ›å»ºï¼ˆç³»ç»Ÿæ¶ˆæ¯å°†åœ¨è°ƒç”¨æ—¶å¤„ç†ï¼‰\"\n",
        "    print(\"âœ… ReAct Agent é‡æ–°åˆ›å»ºæˆåŠŸ\")\n",
        "    print(\"âš ï¸  æ³¨æ„ï¼šç³»ç»Ÿæ¶ˆæ¯å°†åœ¨æ¯æ¬¡è°ƒç”¨æ—¶æ‰‹åŠ¨æ·»åŠ \")\n",
        "except Exception as e3:\n",
        "    print(f\"âŒ Agentåˆ›å»ºå¤±è´¥: {e3}\")\n",
        "    raise Exception(\"æ— æ³•åˆ›å»º ReAct Agent\")\n",
        "\n",
        "print(f\"ğŸ¯ æˆåŠŸæ–¹æ³•: {success_method}\")\n",
        "print(f\"ğŸ“‹ Agent ç±»å‹: {type(agent)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æ–¹æ³•1å¤±è´¥: create_react_agent() got an unexpected keyword argument 'system_message'\n",
            "æ–¹æ³•2å¤±è´¥: create_react_agent() got an unexpected keyword argument 'state_modifier'\n",
            "âœ… ReAct Agent åˆ›å»ºæˆåŠŸï¼ˆæ–¹æ³•3ï¼šåŸºç¡€åˆ›å»ºï¼‰\n",
            "âš ï¸  æ³¨æ„ï¼šç³»ç»Ÿæ¶ˆæ¯å°†åœ¨æ¯æ¬¡è°ƒç”¨æ—¶æ‰‹åŠ¨æ·»åŠ \n",
            "ğŸ¯ æˆåŠŸæ–¹æ³•: åŸºç¡€åˆ›å»ºï¼ˆç³»ç»Ÿæ¶ˆæ¯å°†åœ¨è°ƒç”¨æ—¶å¤„ç†ï¼‰\n",
            "ğŸ“‹ Agent ç±»å‹: <class 'langgraph.graph.state.CompiledStateGraph'>\n"
          ]
        }
      ],
      "source": [
        "# åˆ›å»º ReAct Agent\n",
        "# å°è¯•å¤šç§å…¼å®¹çš„æ–¹å¼æ¥è®¾ç½®ç³»ç»Ÿæ¶ˆæ¯\n",
        "\n",
        "agent = None\n",
        "success_method = None\n",
        "\n",
        "# æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨ system_message å‚æ•°\n",
        "try:\n",
        "    agent = create_react_agent(\n",
        "        llm,\n",
        "        tools=tools,\n",
        "        system_message=SYSTEM_MESSAGE\n",
        "    )\n",
        "    success_method = \"system_message å‚æ•°\"\n",
        "    print(\"âœ… ReAct Agent åˆ›å»ºæˆåŠŸï¼ˆæ–¹æ³•1ï¼šsystem_message å‚æ•°ï¼‰\")\n",
        "except Exception as e:\n",
        "    if VERBOSE:\n",
        "        print(f\"æ–¹æ³•1å¤±è´¥: {e}\")\n",
        "    \n",
        "    # æ–¹æ³•2ï¼šå°è¯•ä½¿ç”¨ state_modifier å‚æ•°\n",
        "    try:\n",
        "        agent = create_react_agent(\n",
        "            llm,\n",
        "            tools=tools,\n",
        "            state_modifier=SYSTEM_MESSAGE\n",
        "        )\n",
        "        success_method = \"state_modifier å‚æ•°\"\n",
        "        print(\"âœ… ReAct Agent åˆ›å»ºæˆåŠŸï¼ˆæ–¹æ³•2ï¼šstate_modifier å‚æ•°ï¼‰\")\n",
        "    except Exception as e2:\n",
        "        if VERBOSE:\n",
        "            print(f\"æ–¹æ³•2å¤±è´¥: {e2}\")\n",
        "        \n",
        "        # æ–¹æ³•3ï¼šåŸºç¡€åˆ›å»ºï¼ˆå°†åœ¨è°ƒç”¨æ—¶å¤„ç†ç³»ç»Ÿæ¶ˆæ¯ï¼‰\n",
        "        try:\n",
        "            agent = create_react_agent(\n",
        "                llm,\n",
        "                tools=tools\n",
        "            )\n",
        "            success_method = \"åŸºç¡€åˆ›å»ºï¼ˆç³»ç»Ÿæ¶ˆæ¯å°†åœ¨è°ƒç”¨æ—¶å¤„ç†ï¼‰\"\n",
        "            print(\"âœ… ReAct Agent åˆ›å»ºæˆåŠŸï¼ˆæ–¹æ³•3ï¼šåŸºç¡€åˆ›å»ºï¼‰\")\n",
        "            print(\"âš ï¸  æ³¨æ„ï¼šç³»ç»Ÿæ¶ˆæ¯å°†åœ¨æ¯æ¬¡è°ƒç”¨æ—¶æ‰‹åŠ¨æ·»åŠ \")\n",
        "        except Exception as e3:\n",
        "            print(f\"âŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†:\")\n",
        "            print(f\"  æ–¹æ³•1: {e}\")\n",
        "            print(f\"  æ–¹æ³•2: {e2}\")\n",
        "            print(f\"  æ–¹æ³•3: {e3}\")\n",
        "            raise Exception(\"æ— æ³•åˆ›å»º ReAct Agent\")\n",
        "\n",
        "print(f\"ğŸ¯ æˆåŠŸæ–¹æ³•: {success_method}\")\n",
        "print(f\"ğŸ“‹ Agent ç±»å‹: {type(agent)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Agent çŠ¶æ€éªŒè¯:\n",
            "   - Agent å®ä¾‹: True\n",
            "   - Agent ç±»å‹: <class 'langgraph.graph.state.CompiledStateGraph'>\n",
            "   - åˆ›å»ºæ–¹æ³•: åŸºç¡€åˆ›å»ºï¼ˆç³»ç»Ÿæ¶ˆæ¯å°†åœ¨è°ƒç”¨æ—¶å¤„ç†ï¼‰\n",
            "   - å¯ç”¨å·¥å…·: 4 ä¸ª\n",
            "   - å·¥å…·åˆ—è¡¨: ['generate_sql', 'valid_sql', 'run_sql', 'generate_summary']\n",
            "   - åŸºç¡€è°ƒç”¨æµ‹è¯•: å°è¯•ä¸­...\n",
            "   - åŸºç¡€è°ƒç”¨æµ‹è¯•: âŒ å¤±è´¥ (Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': 'parameter.enable_thinking must be set to false for non-streaming calls', 'type': 'invalid_request_error'}, 'id': 'chatcmpl-9f3d39f8-df01-9096-a0ce-c11c829b0b24', 'request_id': '9f3d39f8-df01-9096-a0ce-c11c829b0b24'})\n",
            "   - è¯¦ç»†é”™è¯¯:\n",
            "\n",
            "==================================================\n",
            "âš ï¸  Agent éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\PaulWang\\AppData\\Local\\Temp\\ipykernel_40896\\2734479170.py\", line 24, in verify_agent\n",
            "    result = agent.invoke({\"messages\": simple_messages}, test_config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2719, in invoke\n",
            "    for chunk in self.stream(\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2436, in stream\n",
            "    for _ in runner.tick(\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 161, in tick\n",
            "    run_with_retry(\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 623, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 370, in invoke\n",
            "    ret = context.run(self.func, *args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py\", line 505, in call_model\n",
            "    response = cast(AIMessage, model_runnable.invoke(state, config))\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3047, in invoke\n",
            "    input_ = context.run(step.invoke, input_, config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5431, in invoke\n",
            "    return self.bound.invoke(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 372, in invoke\n",
            "    self.generate_prompt(\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 957, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 776, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1022, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 790, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 925, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1239, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Projects\\cursor_projects\\Vanna-Chainlit-Chromadb\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1034, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.BadRequestError: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': 'parameter.enable_thinking must be set to false for non-streaming calls', 'type': 'invalid_request_error'}, 'id': 'chatcmpl-9f3d39f8-df01-9096-a0ce-c11c829b0b24', 'request_id': '9f3d39f8-df01-9096-a0ce-c11c829b0b24'}\n",
            "During task with name 'agent' and id 'e3744fa2-a8df-45fa-2e57-f0e5dec4feb4'\n"
          ]
        }
      ],
      "source": [
        "## 5.1 Agent çŠ¶æ€éªŒè¯\n",
        "\n",
        "# éªŒè¯Agentæ˜¯å¦æ­£å¸¸åˆ›å»º\n",
        "def verify_agent():\n",
        "    \"\"\"éªŒè¯AgentçŠ¶æ€\"\"\"\n",
        "    print(\"ğŸ” Agent çŠ¶æ€éªŒè¯:\")\n",
        "    print(f\"   - Agent å®ä¾‹: {agent is not None}\")\n",
        "    print(f\"   - Agent ç±»å‹: {type(agent)}\")\n",
        "    print(f\"   - åˆ›å»ºæ–¹æ³•: {success_method}\")\n",
        "    print(f\"   - å¯ç”¨å·¥å…·: {len(tools)} ä¸ª\")\n",
        "    print(f\"   - å·¥å…·åˆ—è¡¨: {[tool.name for tool in tools]}\")\n",
        "    \n",
        "    # æµ‹è¯•åŸºç¡€åŠŸèƒ½\n",
        "    try:\n",
        "        # åˆ›å»ºä¸€ä¸ªæœ€ç®€å•çš„æ¶ˆæ¯ï¼ˆåŒ…å«ç³»ç»Ÿæ¶ˆæ¯ï¼Œå› ä¸ºæˆ‘ä»¬ç”¨çš„æ˜¯åŸºç¡€åˆ›å»ºï¼‰\n",
        "        simple_messages = [\n",
        "            SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚\"),\n",
        "            HumanMessage(content=\"ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ã€‚\")\n",
        "        ]\n",
        "        test_config = {\"recursion_limit\": 3}\n",
        "        \n",
        "        # å°è¯•è°ƒç”¨\n",
        "        print(\"   - åŸºç¡€è°ƒç”¨æµ‹è¯•: å°è¯•ä¸­...\")\n",
        "        result = agent.invoke({\"messages\": simple_messages}, test_config)\n",
        "        \n",
        "        # æ£€æŸ¥è¿”å›ç»“æœ\n",
        "        if result and \"messages\" in result:\n",
        "            final_message = result[\"messages\"][-1]\n",
        "            print(f\"   - åŸºç¡€è°ƒç”¨æµ‹è¯•: âœ… æˆåŠŸ\")\n",
        "            print(f\"   - è¿”å›æ¶ˆæ¯ç±»å‹: {type(final_message).__name__}\")\n",
        "            print(f\"   - æ¶ˆæ¯å†…å®¹é¢„è§ˆ: {final_message.content[:50]}...\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"   - åŸºç¡€è°ƒç”¨æµ‹è¯•: âŒ è¿”å›æ ¼å¼å¼‚å¸¸\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"   - åŸºç¡€è°ƒç”¨æµ‹è¯•: âŒ å¤±è´¥ ({e})\")\n",
        "        if VERBOSE:\n",
        "            import traceback\n",
        "            print(\"   - è¯¦ç»†é”™è¯¯:\")\n",
        "            traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# æ‰§è¡ŒéªŒè¯\n",
        "verify_success = verify_agent()\n",
        "print(f\"\\n{'='*50}\")\n",
        "if verify_success:\n",
        "    print(\"ğŸ‰ Agent éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹æµ‹è¯•ï¼\")\n",
        "    print(\"ğŸ’¡ æç¤ºï¼šç”±äºä½¿ç”¨åŸºç¡€åˆ›å»ºæ–¹å¼ï¼Œæ¯æ¬¡è°ƒç”¨éƒ½ä¼šåŒ…å«å®Œæ•´çš„ç³»ç»Ÿæ¶ˆæ¯\")\n",
        "else:\n",
        "    print(\"âš ï¸  Agent éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®\")\n",
        "print(f\"{'='*50}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. æµ‹è¯•å‡½æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_agent(question: str, max_iterations: int = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    æµ‹è¯•Agentå¤„ç†é—®é¢˜\n",
        "    \n",
        "    Args:\n",
        "        question: ç”¨æˆ·é—®é¢˜\n",
        "        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä½¿ç”¨MAX_TOOL_CALLS\n",
        "    \n",
        "    Returns:\n",
        "        å¤„ç†ç»“æœ\n",
        "    \"\"\"\n",
        "    if max_iterations is None:\n",
        "        max_iterations = MAX_TOOL_CALLS\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ¤” é—®é¢˜: {question}\")\n",
        "    print(f\"âš™ï¸  æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°: {max_iterations}\")\n",
        "    print(f\"âš™ï¸  Agent åˆ›å»ºæ–¹æ³•: {success_method}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    try:\n",
        "        # æ„å»ºæ¶ˆæ¯ - æ ¹æ®Agentåˆ›å»ºæ–¹å¼å†³å®šæ˜¯å¦åŒ…å«ç³»ç»Ÿæ¶ˆæ¯\n",
        "        if success_method == \"åŸºç¡€åˆ›å»ºï¼ˆç³»ç»Ÿæ¶ˆæ¯å°†åœ¨è°ƒç”¨æ—¶å¤„ç†ï¼‰\":\n",
        "            # å¦‚æœAgentåˆ›å»ºæ—¶æ²¡æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ \n",
        "            messages = [\n",
        "                SystemMessage(content=SYSTEM_MESSAGE),\n",
        "                HumanMessage(content=question)\n",
        "            ]\n",
        "        else:\n",
        "            # å¦‚æœAgentåˆ›å»ºæ—¶å·²åŒ…å«ç³»ç»Ÿæ¶ˆæ¯ï¼Œåªéœ€è¦ç”¨æˆ·æ¶ˆæ¯\n",
        "            messages = [\n",
        "                HumanMessage(content=question)\n",
        "            ]\n",
        "        \n",
        "        # è®¾ç½®é…ç½®ï¼ŒåŒ…æ‹¬é€’å½’é™åˆ¶\n",
        "        config = {\n",
        "            \"recursion_limit\": max_iterations + 5,  # é¢å¤–çš„ç¼“å†²\n",
        "            \"configurable\": {\n",
        "                \"thread_id\": f\"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        if VERBOSE:\n",
        "            print(f\"ğŸ“ å‘é€æ¶ˆæ¯æ•°é‡: {len(messages)}\")\n",
        "            print(f\"ğŸ“ æ¶ˆæ¯ç±»å‹: {[type(msg).__name__ for msg in messages]}\")\n",
        "        \n",
        "        # è°ƒç”¨Agent\n",
        "        start_time = datetime.now()\n",
        "        result = agent.invoke({\"messages\": messages}, config=config)\n",
        "        end_time = datetime.now()\n",
        "        \n",
        "        # æå–æœ€ç»ˆå“åº”\n",
        "        final_message = result[\"messages\"][-1]\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"âœ… æœ€ç»ˆç­”æ¡ˆ:\")\n",
        "        print(f\"{final_message.content}\")\n",
        "        print(f\"\\nâ±ï¸  å¤„ç†æ—¶é—´: {(end_time - start_time).total_seconds():.2f} ç§’\")\n",
        "        print(f\"ğŸ“Š æ¶ˆæ¯æ•°é‡: {len(result['messages'])}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"question\": question,\n",
        "            \"answer\": final_message.content,\n",
        "            \"messages\": result[\"messages\"],\n",
        "            \"duration\": (end_time - start_time).total_seconds()\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ å¤„ç†å¤±è´¥: {e}\")\n",
        "        if VERBOSE:\n",
        "            import traceback\n",
        "            print(f\"ğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:\")\n",
        "            traceback.print_exc()\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"question\": question,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "print(\"âœ… æµ‹è¯•å‡½æ•°å·²å®šä¹‰\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. æ‰§è¡Œæµ‹è¯•\n",
        "### 7.1 æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢é—®é¢˜\n",
        "test_questions_db = [\n",
        "    \"æŸ¥è¯¢æ‰€æœ‰æœåŠ¡åŒºçš„åç§°\",\n",
        "    \"ç»Ÿè®¡ä»Šå¤©çš„è¥ä¸šé¢\",\n",
        "    \"å“ªä¸ªæ¡£å£çš„æ”¶å…¥æœ€é«˜ï¼Ÿ\",\n",
        "    \"æ˜¨å¤©çš„è½¦æµé‡æ˜¯å¤šå°‘ï¼Ÿ\"\n",
        "]\n",
        "\n",
        "# é€‰æ‹©ä¸€ä¸ªé—®é¢˜æµ‹è¯•ï¼ˆå¯ä»¥ä¿®æ”¹ç´¢å¼•ï¼‰\n",
        "result = test_agent(test_questions_db[0], max_iterations=8)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 7.2 æµ‹è¯•å¸¸è¯†é—®é¢˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•å¸¸è¯†æ€§é—®é¢˜\n",
        "test_questions_common = [\n",
        "    \"è”æå‡ æœˆä»½ä¸Šå¸‚ï¼Ÿ\",\n",
        "    \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\",\n",
        "    \"Pythonæ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
        "    \"å¦‚ä½•åšç•ªèŒ„ç‚’è›‹ï¼Ÿ\"\n",
        "]\n",
        "\n",
        "# é€‰æ‹©ä¸€ä¸ªé—®é¢˜æµ‹è¯•\n",
        "result = test_agent(test_questions_common[0], max_iterations=5)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 7.3 æµ‹è¯•è¾¹ç•Œé—®é¢˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•è¾¹ç•Œé—®é¢˜ï¼ˆå¯èƒ½åœ¨æ•°æ®åº“ä¸­ï¼Œä¹Ÿå¯èƒ½éœ€è¦å¸¸è¯†ï¼‰\n",
        "test_questions_boundary = [\n",
        "    \"æœåŠ¡åŒºæœ‰å–è”æå—ï¼Ÿ\",  # å¯èƒ½éœ€è¦æŸ¥è¯¢å•†å“è¡¨\n",
        "    \"é«˜é€Ÿå…¬è·¯ä»€ä¹ˆæ—¶å€™å»ºæˆçš„ï¼Ÿ\",  # å¯èƒ½æ²¡æœ‰è¿™ä¸ªæ•°æ®\n",
        "    \"å¦‚ä½•è”ç³»å®¢æœï¼Ÿ\",  # ç³»ç»Ÿç›¸å…³ä½†å¯èƒ½ä¸åœ¨æ•°æ®åº“\n",
        "]\n",
        "\n",
        "# é€‰æ‹©ä¸€ä¸ªé—®é¢˜æµ‹è¯•\n",
        "result = test_agent(test_questions_boundary[0], max_iterations=10)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 7.4 æ‰¹é‡æµ‹è¯•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ‰¹é‡æµ‹è¯•å¤šä¸ªé—®é¢˜\n",
        "def batch_test(questions: List[str], max_iterations: int = None):\n",
        "    \"\"\"æ‰¹é‡æµ‹è¯•é—®é¢˜\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for i, question in enumerate(questions, 1):\n",
        "        print(f\"\\nğŸ”„ æµ‹è¯• {i}/{len(questions)}: {question}\")\n",
        "        result = test_agent(question, max_iterations)\n",
        "        results.append(result)\n",
        "        \n",
        "        # ç®€çŸ­æ€»ç»“\n",
        "        if result[\"success\"]:\n",
        "            print(f\"âœ… æˆåŠŸï¼Œè€—æ—¶ {result['duration']:.2f} ç§’\")\n",
        "        else:\n",
        "            print(f\"âŒ å¤±è´¥: {result.get('error', 'Unknown error')}\")\n",
        "    \n",
        "    # ç»Ÿè®¡\n",
        "    success_count = sum(1 for r in results if r[\"success\"])\n",
        "    total_time = sum(r.get(\"duration\", 0) for r in results)\n",
        "    \n",
        "    print(f\"\\nğŸ“Š æ‰¹é‡æµ‹è¯•å®Œæˆ:\")\n",
        "    print(f\"   - æˆåŠŸç‡: {success_count}/{len(questions)} ({success_count/len(questions)*100:.1f}%)\")\n",
        "    print(f\"   - æ€»è€—æ—¶: {total_time:.2f} ç§’\")\n",
        "    print(f\"   - å¹³å‡è€—æ—¶: {total_time/len(questions):.2f} ç§’/é—®é¢˜\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# æ‰§è¡Œæ‰¹é‡æµ‹è¯•\n",
        "all_test_questions = [\n",
        "    \"æŸ¥è¯¢æ‰€æœ‰æœåŠ¡åŒº\",\n",
        "    \"è”æå‡ æœˆä»½ä¸Šå¸‚ï¼Ÿ\",\n",
        "    \"ä»Šå¤©çš„è¥ä¸šé¢æ˜¯å¤šå°‘ï¼Ÿ\",\n",
        "    \"Pythonæ˜¯ä»€ä¹ˆç¼–ç¨‹è¯­è¨€ï¼Ÿ\"\n",
        "]\n",
        "\n",
        "# batch_results = batch_test(all_test_questions, max_iterations=8)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. è°ƒè¯•å·¥å…·\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_agent_execution(result: Dict[str, Any]):\n",
        "    \"\"\"åˆ†æAgentæ‰§è¡Œè¿‡ç¨‹\"\"\"\n",
        "    if not result.get(\"success\"):\n",
        "        print(\"âŒ æ‰§è¡Œå¤±è´¥ï¼Œæ— æ³•åˆ†æ\")\n",
        "        return\n",
        "    \n",
        "    messages = result.get(\"messages\", [])\n",
        "    \n",
        "    print(f\"\\nğŸ“ æ‰§è¡Œè¿‡ç¨‹åˆ†æ:\")\n",
        "    print(f\"æ€»æ¶ˆæ¯æ•°: {len(messages)}\")\n",
        "    \n",
        "    tool_calls = []\n",
        "    for i, msg in enumerate(messages):\n",
        "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
        "            for tool_call in msg.tool_calls:\n",
        "                tool_calls.append({\n",
        "                    \"index\": i,\n",
        "                    \"tool\": tool_call[\"name\"],\n",
        "                    \"args\": tool_call.get(\"args\", {})\n",
        "                })\n",
        "    \n",
        "    print(f\"\\nğŸ”§ å·¥å…·è°ƒç”¨åºåˆ— (å…± {len(tool_calls)} æ¬¡):\")\n",
        "    for tc in tool_calls:\n",
        "        print(f\"   {tc['index']}. {tc['tool']} - å‚æ•°: {tc['args']}\")\n",
        "    \n",
        "    # ç»Ÿè®¡å·¥å…·ä½¿ç”¨\n",
        "    from collections import Counter\n",
        "    tool_counter = Counter(tc['tool'] for tc in tool_calls)\n",
        "    \n",
        "    print(f\"\\nğŸ“Š å·¥å…·ä½¿ç”¨ç»Ÿè®¡:\")\n",
        "    for tool, count in tool_counter.items():\n",
        "        print(f\"   - {tool}: {count} æ¬¡\")\n",
        "\n",
        "# ä½¿ç”¨ç¤ºä¾‹ï¼ˆéœ€è¦å…ˆè¿è¡Œæµ‹è¯•ï¼‰\n",
        "# analyze_agent_execution(result)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 9. è‡ªå®šä¹‰æµ‹è¯•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„è‡ªå®šä¹‰é—®é¢˜è¿›è¡Œæµ‹è¯•\n",
        "custom_question = \"æŸ¥è¯¢ä»Šå¤©è¥ä¸šé¢æœ€é«˜çš„å‰3ä¸ªæ¡£å£\"\n",
        "\n",
        "# å¯ä»¥è°ƒæ•´æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°\n",
        "custom_max_iterations = 10\n",
        "\n",
        "# æ‰§è¡Œæµ‹è¯•\n",
        "custom_result = test_agent(custom_question, max_iterations=custom_max_iterations)\n",
        "\n",
        "# åˆ†ææ‰§è¡Œè¿‡ç¨‹\n",
        "if custom_result[\"success\"]:\n",
        "    analyze_agent_execution(custom_result)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 10. æ€»ç»“\n",
        "\n",
        "### å®ç°çš„åŠŸèƒ½ï¼š\n",
        "1. âœ… ä½¿ç”¨ `create_react_agent()` åˆ›å»ºæ™ºèƒ½Agent\n",
        "2. âœ… å®ç°å››ä¸ªå·¥å…·ï¼šgenerate_sql, valid_sql, run_sql, generate_summary\n",
        "3. âœ… Agentèƒ½å¤Ÿè‡ªä¸»åˆ¤æ–­æ˜¯æŸ¥è¯¢æ•°æ®åº“è¿˜æ˜¯ç”¨å¸¸è¯†å›ç­”\n",
        "4. âœ… æ”¯æŒé…ç½®æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯\n",
        "5. âœ… å¯¹è¾¹ç•Œé—®é¢˜çš„å¤„ç†ï¼šå…ˆå°è¯•æŸ¥è¯¢ï¼Œå¤±è´¥åˆ™ç”¨å¸¸è¯†\n",
        "\n",
        "### ä½¿ç”¨è¯´æ˜ï¼š\n",
        "1. ä¿®æ”¹ `DATABASE_SCOPE` å˜é‡æ¥æ›´æ–°æ•°æ®åº“ä¸šåŠ¡èŒƒå›´æè¿°\n",
        "2. è°ƒæ•´ `MAX_TOOL_CALLS` æ¥æ§åˆ¶æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°\n",
        "3. ä½¿ç”¨ `test_agent()` å‡½æ•°æµ‹è¯•å•ä¸ªé—®é¢˜\n",
        "4. ä½¿ç”¨ `batch_test()` æ‰¹é‡æµ‹è¯•å¤šä¸ªé—®é¢˜\n",
        "5. ä½¿ç”¨ `analyze_agent_execution()` åˆ†ææ‰§è¡Œè¿‡ç¨‹\n",
        "\n",
        "### æ³¨æ„äº‹é¡¹ï¼š\n",
        "- æ‰€æœ‰ä»£ç éƒ½åœ¨è¿™ä¸ªnotebookä¸­ï¼Œä¸å½±å“é¡¹ç›®å…¶ä»–éƒ¨åˆ†\n",
        "- valid_sql å·¥å…·æ˜¯æ–°åˆ›å»ºçš„ï¼Œä»ç°æœ‰ä»£ç ä¸­æå–äº†éªŒè¯é€»è¾‘\n",
        "- Agentä¼šæ ¹æ®å·¥å…·è¿”å›çš„successå’Œerrorä¿¡æ¯æ™ºèƒ½å†³ç­–ä¸‹ä¸€æ­¥\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 11. ä¾èµ–åŒ…è¯´æ˜\n",
        "\n",
        "### è¿è¡Œæ­¤ notebook éœ€è¦çš„åŒ…ï¼š\n",
        "\n",
        "å¦‚æœè¿è¡Œæ—¶é‡åˆ°ç¼ºåŒ…é”™è¯¯ï¼Œè¯·åœ¨æ‚¨çš„ `.venv` ç¯å¢ƒä¸­å®‰è£…ä»¥ä¸‹åŒ…ï¼š\n",
        "\n",
        "```bash\n",
        "# LangChain å’Œ LangGraph ç›¸å…³\n",
        "pip install langchain==0.3.7\n",
        "pip install langgraph==0.2.53\n",
        "pip install langchain-openai==0.2.9  # å¦‚æœä½¿ç”¨OpenAIå…¼å®¹API\n",
        "\n",
        "# å…¶ä»–å¯èƒ½éœ€è¦çš„ä¾èµ–\n",
        "pip install pandas  # å¦‚æœè¿˜æ²¡å®‰è£…\n",
        "pip install asyncio  # é€šå¸¸å·²å†…ç½®\n",
        "```\n",
        "\n",
        "### ç‰ˆæœ¬å…¼å®¹æ€§è¯´æ˜ï¼š\n",
        "- æœ¬ notebook åŸºäº LangChain/LangGraph v0.3.x å¼€å‘\n",
        "- `create_react_agent` å‡½æ•°åœ¨ `langgraph.prebuilt` æ¨¡å—ä¸­\n",
        "- å¦‚æœç‰ˆæœ¬ä¸åŒ¹é…ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å¯¼å…¥è·¯å¾„æˆ–APIç”¨æ³•\n",
        "\n",
        "### å¸¸è§é—®é¢˜ï¼š\n",
        "1. **ImportError: cannot import name 'create_react_agent'**\n",
        "   - ç¡®ä¿ langgraph ç‰ˆæœ¬ >= 0.2.0\n",
        "   - æ£€æŸ¥å¯¼å…¥è·¯å¾„æ˜¯å¦æ­£ç¡®\n",
        "\n",
        "2. **æ‰¾ä¸åˆ° Vanna å®ä¾‹**\n",
        "   - ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•çš„ common/vanna_instance.py å¯ä»¥æ­£å¸¸å¯¼å…¥\n",
        "   - æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®\n",
        "\n",
        "3. **LLM è°ƒç”¨å¤±è´¥**\n",
        "   - æ£€æŸ¥ app_config.py ä¸­çš„ LLM é…ç½®\n",
        "   - ç¡®ä¿ API key å’Œ endpoint æ­£ç¡®\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 12. å¼€å§‹ä½¿ç”¨\n",
        "\n",
        "### å¿«é€Ÿå¼€å§‹ï¼š\n",
        "1. ç¡®ä¿å·²æ¿€æ´» `.venv` ç¯å¢ƒ\n",
        "2. è¿è¡Œ Cell 1-5 è¿›è¡Œåˆå§‹åŒ–è®¾ç½®\n",
        "3. è¿è¡Œ Cell 6-16 åˆ›å»ºå·¥å…·å’ŒAgent\n",
        "4. è¿è¡Œ Cell 19 å®šä¹‰æµ‹è¯•å‡½æ•°\n",
        "5. ç„¶åå¯ä»¥æµ‹è¯•å„ç§é—®é¢˜ï¼š\n",
        "\n",
        "```python\n",
        "# æµ‹è¯•ç¤ºä¾‹\n",
        "test_agent(\"æŸ¥è¯¢ä»Šå¤©çš„è¥ä¸šé¢\")\n",
        "test_agent(\"è”æå‡ æœˆä»½ä¸Šå¸‚ï¼Ÿ\")\n",
        "test_agent(\"å“ªä¸ªæœåŠ¡åŒºè½¦æµé‡æœ€å¤§ï¼Ÿ\")\n",
        "```\n",
        "\n",
        "ç¥æ‚¨æµ‹è¯•æ„‰å¿«ï¼ğŸš€\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
