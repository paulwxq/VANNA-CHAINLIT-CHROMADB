"""
åŸºäº StateGraph çš„ã€å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„ React Agent æ ¸å¿ƒå®ç°
"""
import json
import pandas as pd
import httpx
import sys
import os
from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple
from contextlib import AsyncExitStack

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.pathä»¥è§£å†³æ¨¡å—å¯¼å…¥é—®é¢˜
try:
    project_root = Path(__file__).parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
except Exception as e:
    pass  # å¿½ç•¥è·¯å¾„æ·»åŠ é”™è¯¯

# ä½¿ç”¨ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºæ¨¡å—å¯¼å…¥æ—¶ï¼‰
    from core.logging import get_react_agent_logger
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥ï¼ˆç›´æ¥è¿è¡Œæ—¶ï¼‰
    from core.logging import get_react_agent_logger

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, ToolMessage, BaseMessage, SystemMessage, AIMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
import redis.asyncio as redis
try:
    from langgraph.checkpoint.redis import AsyncRedisSaver
except ImportError:
    AsyncRedisSaver = None

# ä»æ–°æ¨¡å—å¯¼å…¥é…ç½®ã€çŠ¶æ€å’Œå·¥å…·
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºæ¨¡å—å¯¼å…¥æ—¶ï¼‰
    from . import config
    from .state import AgentState
    from .sql_tools import sql_tools
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥ï¼ˆç›´æ¥è¿è¡Œæ—¶ï¼‰
    import config
    from state import AgentState
    from sql_tools import sql_tools
from langchain_core.runnables import RunnablePassthrough

logger = get_react_agent_logger("CustomReactAgent")

class CustomReactAgent:
    """
    ä¸€ä¸ªä½¿ç”¨ StateGraph æ„å»ºçš„ã€å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥å’ŒæŒä¹…åŒ–èƒ½åŠ›çš„ Agentã€‚
    """
    def __init__(self):
        """ç§æœ‰æ„é€ å‡½æ•°ï¼Œè¯·ä½¿ç”¨ create() ç±»æ–¹æ³•æ¥åˆ›å»ºå®ä¾‹ã€‚"""
        self.llm = None
        self.tools = None
        self.agent_executor = None
        self.checkpointer = None
        self._exit_stack = None
        self.redis_client = None

    @classmethod
    async def create(cls):
        """å¼‚æ­¥å·¥å‚æ–¹æ³•ï¼Œåˆ›å»ºå¹¶åˆå§‹åŒ– CustomReactAgent å®ä¾‹ã€‚"""
        instance = cls()
        await instance._async_init()
        return instance

    async def _async_init(self):
        """å¼‚æ­¥åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ã€‚"""
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ– CustomReactAgent...")

        # 1. åˆå§‹åŒ–å¼‚æ­¥Rediså®¢æˆ·ç«¯
        self.redis_client = redis.from_url(config.REDIS_URL, decode_responses=True)
        try:
            await self.redis_client.ping()
            logger.info(f"   âœ… Redisè¿æ¥æˆåŠŸ: {config.REDIS_URL}")
        except Exception as e:
            logger.error(f"   âŒ Redisè¿æ¥å¤±è´¥: {e}")
            raise

        # 2. åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            api_key=config.QWEN_API_KEY,
            base_url=config.QWEN_BASE_URL,
            model=config.QWEN_MODEL,
            temperature=0.1,
            timeout=config.NETWORK_TIMEOUT,  # æ·»åŠ è¶…æ—¶é…ç½®
            max_retries=0,  # ç¦ç”¨OpenAIå®¢æˆ·ç«¯é‡è¯•ï¼Œæ”¹ç”¨Agentå±‚ç»Ÿä¸€é‡è¯•
            streaming=True,
            extra_body={
                "enable_thinking": True,  # False by wxq
                "misc": {
                    "ensure_ascii": False
                }
            },
            # æ–°å¢ï¼šä¼˜åŒ–HTTPè¿æ¥é…ç½®
            http_client=httpx.Client(
                limits=httpx.Limits(
                    max_connections=config.HTTP_MAX_CONNECTIONS,
                    max_keepalive_connections=config.HTTP_MAX_KEEPALIVE_CONNECTIONS,
                    keepalive_expiry=config.HTTP_KEEPALIVE_EXPIRY,  # 30ç§’keep-aliveè¿‡æœŸ
                ),
                timeout=httpx.Timeout(
                    connect=config.HTTP_CONNECT_TIMEOUT,   # è¿æ¥è¶…æ—¶
                    read=config.NETWORK_TIMEOUT,           # è¯»å–è¶…æ—¶
                    write=config.HTTP_CONNECT_TIMEOUT,     # å†™å…¥è¶…æ—¶
                    pool=config.HTTP_POOL_TIMEOUT          # è¿æ¥æ± è¶…æ—¶
                )
            )
        )
        logger.info(f"   ReactAgent LLM å·²åˆå§‹åŒ–ï¼Œæ¨¡å‹: {config.QWEN_MODEL}")

        # 3. ç»‘å®šå·¥å…·
        self.tools = sql_tools
        self.llm_with_tools = self.llm.bind_tools(self.tools)
        logger.info(f"   å·²ç»‘å®š {len(self.tools)} ä¸ªå·¥å…·ã€‚")

        # 4. åˆå§‹åŒ– Redis Checkpointer
        if config.REDIS_ENABLED and AsyncRedisSaver is not None:
            try:
                self._exit_stack = AsyncExitStack()
                checkpointer_manager = AsyncRedisSaver.from_conn_string(config.REDIS_URL)
                self.checkpointer = await self._exit_stack.enter_async_context(checkpointer_manager)
                await self.checkpointer.asetup()
                logger.info(f"   AsyncRedisSaver æŒä¹…åŒ–å·²å¯ç”¨: {config.REDIS_URL}")
            except Exception as e:
                logger.error(f"   âŒ RedisSaver åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
                if self._exit_stack:
                    await self._exit_stack.aclose()
                self.checkpointer = None
        else:
            logger.warning("   Redis æŒä¹…åŒ–åŠŸèƒ½å·²ç¦ç”¨ã€‚")

        # 5. æ„å»º StateGraph
        self.agent_executor = self._create_graph()
        logger.info("   StateGraph å·²æ„å»ºå¹¶ç¼–è¯‘ã€‚")
        
        # 6. æ˜¾ç¤ºæ¶ˆæ¯è£å‰ªé…ç½®çŠ¶æ€
        if config.MESSAGE_TRIM_ENABLED:
            logger.info(f"   æ¶ˆæ¯è£å‰ªå·²å¯ç”¨: ä¿ç•™æ¶ˆæ¯æ•°={config.MESSAGE_TRIM_COUNT}, æœç´¢é™åˆ¶={config.MESSAGE_TRIM_SEARCH_LIMIT}")
        else:
            logger.info("   æ¶ˆæ¯è£å‰ªå·²ç¦ç”¨")
        
        logger.info("âœ… CustomReactAgent åˆå§‹åŒ–å®Œæˆã€‚")

    async def _reinitialize_checkpointer(self):
        """é‡æ–°åˆå§‹åŒ–checkpointerè¿æ¥"""
        try:
            # æ¸…ç†æ—§çš„è¿æ¥
            if self._exit_stack:
                try:
                    await self._exit_stack.aclose()
                except:
                    pass
                
            # é‡æ–°åˆ›å»º
            if config.REDIS_ENABLED and AsyncRedisSaver is not None:
                self._exit_stack = AsyncExitStack()
                checkpointer_manager = AsyncRedisSaver.from_conn_string(config.REDIS_URL)
                self.checkpointer = await self._exit_stack.enter_async_context(checkpointer_manager)
                await self.checkpointer.asetup()
                logger.info("âœ… Checkpointeré‡æ–°åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.checkpointer = None
                logger.warning("âš ï¸ Redisç¦ç”¨ï¼Œcheckpointerè®¾ä¸ºNone")
                
        except Exception as e:
            logger.error(f"âŒ Checkpointeré‡æ–°åˆå§‹åŒ–å¤±è´¥: {e}")
            self.checkpointer = None

    async def close(self):
        """æ¸…ç†èµ„æºï¼Œå…³é—­ Redis è¿æ¥ã€‚"""
        if self._exit_stack:
            await self._exit_stack.aclose()
            self._exit_stack = None
            self.checkpointer = None
            logger.info("âœ… RedisSaver èµ„æºå·²é€šè¿‡ AsyncExitStack é‡Šæ”¾ã€‚")
        
        if self.redis_client:
            await self.redis_client.aclose()
            logger.info("âœ… Rediså®¢æˆ·ç«¯å·²å…³é—­ã€‚")

    def _trim_messages_node(self, state: AgentState) -> AgentState:
        """
        æ¶ˆæ¯è£å‰ªèŠ‚ç‚¹ï¼šç¡®ä¿ä»HumanMessageå¼€å§‹çš„å®Œæ•´å¯¹è¯è½®æ¬¡
        
        è£å‰ªé€»è¾‘ï¼š
        1. å¦‚æœæ¶ˆæ¯æ•° <= MESSAGE_TRIM_COUNTï¼Œä¸è£å‰ª
        2. å–æœ€è¿‘ MESSAGE_TRIM_COUNT æ¡æ¶ˆæ¯
        3. æ£€æŸ¥ç¬¬ä¸€æ¡æ˜¯å¦ä¸ºHumanMessage
        4. å¦‚æœä¸æ˜¯ï¼Œå‘å‰æœç´¢æœ€å¤š MESSAGE_TRIM_SEARCH_LIMIT æ¡æ¶ˆæ¯æ‰¾HumanMessage
        5. å¦‚æœæ‰¾åˆ°ï¼Œä»HumanMessageå¼€å§‹ä¿ç•™ï¼›å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä»åŸç›®æ ‡ä½ç½®å¼€å§‹å¹¶è®°å½•WARNING
        """
        messages = state.get("messages", [])
        thread_id = state.get("thread_id", "unknown")
        original_count = len(messages)
        
        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦è£å‰ª
        if original_count <= config.MESSAGE_TRIM_COUNT:
            logger.info(f"[{thread_id}] æ¶ˆæ¯æ•°é‡ {original_count} <= {config.MESSAGE_TRIM_COUNT}ï¼Œæ— éœ€è£å‰ª")
            return state
        
        # 2. å¼€å§‹è£å‰ªé€»è¾‘
        target_count = config.MESSAGE_TRIM_COUNT
        search_limit = config.MESSAGE_TRIM_SEARCH_LIMIT
        
        # 3. å–æœ€è¿‘çš„target_countæ¡æ¶ˆæ¯
        recent_start_index = original_count - target_count
        recent_messages = messages[-target_count:]
        first_msg = recent_messages[0]
        
        if config.DEBUG_MODE:
            logger.info(f"[{thread_id}] å¼€å§‹æ¶ˆæ¯è£å‰ªåˆ†æ:")
            logger.info(f"   åŸå§‹æ¶ˆæ¯æ•°: {original_count}")
            logger.info(f"   ç›®æ ‡ä¿ç•™æ•°: {target_count}")
            logger.info(f"   åˆå§‹æˆªå–ç´¢å¼•: {recent_start_index}")
            logger.info(f"   ç¬¬ä¸€æ¡æ¶ˆæ¯ç±»å‹: {first_msg.type}")
        
        final_start_index = recent_start_index
        
        # 4. æ£€æŸ¥ç¬¬ä¸€æ¡æ˜¯å¦ä¸ºHumanMessage
        if first_msg.type != "human":
            if config.DEBUG_MODE:
                logger.info(f"   ç¬¬ä¸€æ¡ä¸æ˜¯HumanMessageï¼Œå¼€å§‹å‘å‰æœç´¢...")
            
            # 5. å‘å‰æœç´¢HumanMessage
            found_human = False
            search_start = recent_start_index - 1
            search_end = max(0, recent_start_index - search_limit)
            
            for i in range(search_start, search_end - 1, -1):
                if i >= 0 and messages[i].type == "human":
                    final_start_index = i
                    found_human = True
                    if config.DEBUG_MODE:
                        logger.info(f"   åœ¨ç´¢å¼• {i} æ‰¾åˆ°HumanMessageï¼Œå‘å‰æ‰©å±• {recent_start_index - i} æ¡")
                    break
            
            # 6. å¦‚æœæ²¡æ‰¾åˆ°HumanMessageï¼Œè®°å½•WARNING
            if not found_human:
                logger.warning(f"[{thread_id}] åœ¨å‘å‰ {search_limit} æ¡æ¶ˆæ¯ä¸­æœªæ‰¾åˆ°HumanMessageï¼Œä»åŸç›®æ ‡ä½ç½® {recent_start_index} å¼€å§‹æˆªæ–­")
                final_start_index = recent_start_index
        else:
            if config.DEBUG_MODE:
                logger.info(f"   ç¬¬ä¸€æ¡å°±æ˜¯HumanMessageï¼Œæ— éœ€å‘å‰æœç´¢")
        
        # 7. æ‰§è¡Œè£å‰ª
        final_messages = messages[final_start_index:]
        final_count = len(final_messages)
        
        # 8. è®°å½•è£å‰ªç»“æœ
        logger.info(f"[{thread_id}] æ¶ˆæ¯è£å‰ªå®Œæˆ: {original_count} â†’ {final_count} æ¡ (ä»ç´¢å¼• {final_start_index} å¼€å§‹)")
        
        if config.DEBUG_MODE:
            logger.info(f"   è£å‰ªè¯¦æƒ…:")
            logger.info(f"     åˆ é™¤æ¶ˆæ¯æ•°: {original_count - final_count}")
            logger.info(f"     ä¿ç•™æ¶ˆæ¯èŒƒå›´: [{final_start_index}:{original_count}]")
            
            # æ˜¾ç¤ºå‰å‡ æ¡å’Œåå‡ æ¡æ¶ˆæ¯ç±»å‹
            if final_count > 0:
                first_few = min(3, final_count)
                last_few = min(3, final_count)
                logger.info(f"     å‰{first_few}æ¡ç±»å‹: {[msg.type for msg in final_messages[:first_few]]}")
                if final_count > 3:
                    logger.info(f"     å{last_few}æ¡ç±»å‹: {[msg.type for msg in final_messages[-last_few:]]}")
        
        return {**state, "messages": final_messages}

    def _create_graph(self):
        """å®šä¹‰å¹¶ç¼–è¯‘æœ€ç»ˆçš„ã€æ­£ç¡®çš„ StateGraph ç»“æ„ã€‚"""
        builder = StateGraph(AgentState)

        # æ·»åŠ æ¶ˆæ¯è£å‰ªèŠ‚ç‚¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if config.MESSAGE_TRIM_ENABLED:
            builder.add_node("trim_messages", self._trim_messages_node)
        
        # å®šä¹‰æ‰€æœ‰éœ€è¦çš„èŠ‚ç‚¹ - å…¨éƒ¨æ”¹ä¸ºå¼‚æ­¥
        builder.add_node("agent", self._async_agent_node)
        builder.add_node("prepare_tool_input", self._async_prepare_tool_input_node)
        builder.add_node("tools", ToolNode(self.tools))
        builder.add_node("update_state_after_tool", self._async_update_state_after_tool_node)
        builder.add_node("format_final_response", self._async_format_final_response_node)

        # å»ºç«‹æ­£ç¡®çš„è¾¹è¿æ¥
        if config.MESSAGE_TRIM_ENABLED:
            # å¯ç”¨è£å‰ªï¼šSTART â†’ trim_messages â†’ agent
            builder.set_entry_point("trim_messages")
            builder.add_edge("trim_messages", "agent")
            logger.info("   âœ… æ¶ˆæ¯è£å‰ªèŠ‚ç‚¹å·²å¯ç”¨ï¼Œå·¥ä½œæµ: START â†’ trim_messages â†’ agent")
        else:
            # ç¦ç”¨è£å‰ªï¼šSTART â†’ agent
            builder.set_entry_point("agent")
            logger.info("   âš ï¸ æ¶ˆæ¯è£å‰ªèŠ‚ç‚¹å·²ç¦ç”¨ï¼Œå·¥ä½œæµ: START â†’ agent")
        
        builder.add_conditional_edges(
            "agent",
            self._async_should_continue,
            {
                "continue": "prepare_tool_input",
                "end": "format_final_response"
            }
        )
        builder.add_edge("prepare_tool_input", "tools")
        builder.add_edge("tools", "update_state_after_tool")
        builder.add_edge("update_state_after_tool", "agent")
        builder.add_edge("format_final_response", END)

        return builder.compile(checkpointer=self.checkpointer)

    async def _async_should_continue(self, state: AgentState) -> str:
        """å¼‚æ­¥åˆ¤æ–­æ˜¯ç»§ç»­è°ƒç”¨å·¥å…·è¿˜æ˜¯ç»“æŸã€‚"""
        thread_id = state.get("thread_id", "unknown")
        messages = state["messages"]
        total_messages = len(messages)
        
        # æ˜¾ç¤ºå½“å‰é€’å½’è®¡æ•°
        current_count = getattr(self, '_recursion_count', 0)
        
        logger.info(f"ğŸ”„ [Decision] _async_should_continue - Thread: {thread_id} | é€’å½’è®¡æ•°: {current_count}/{config.RECURSION_LIMIT}")
        logger.info(f"   æ¶ˆæ¯æ€»æ•°: {total_messages}")
        
        if not messages:
            logger.warning("   âš ï¸ æ¶ˆæ¯åˆ—è¡¨ä¸ºç©ºï¼Œè¿”å› 'end'")
            return "end"
        
        last_message = messages[-1]
        message_type = type(last_message).__name__
        
        logger.info(f"   æœ€åæ¶ˆæ¯ç±»å‹: {message_type}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰tool_calls
        has_tool_calls = hasattr(last_message, "tool_calls") and last_message.tool_calls
        
        if has_tool_calls:
            tool_calls_count = len(last_message.tool_calls)
            logger.info(f"   å‘ç°å·¥å…·è°ƒç”¨: {tool_calls_count} ä¸ª")
            
            # è¯¦ç»†è®°å½•æ¯ä¸ªå·¥å…·è°ƒç”¨
            for i, tool_call in enumerate(last_message.tool_calls):
                tool_name = tool_call.get('name', 'unknown')
                tool_id = tool_call.get('id', 'unknown')
                logger.info(f"     å·¥å…·è°ƒç”¨[{i}]: {tool_name} (ID: {tool_id})")
            
            logger.info("   ğŸ”„ å†³ç­–: continue (ç»§ç»­å·¥å…·è°ƒç”¨)")
            return "continue"
        else:
            logger.info("   âœ… æ— å·¥å…·è°ƒç”¨")
            
            # æ£€æŸ¥æ¶ˆæ¯å†…å®¹ä»¥äº†è§£ä¸ºä»€ä¹ˆç»“æŸ
            if hasattr(last_message, 'content'):
                content_preview = str(last_message.content)[:100] + "..." if len(str(last_message.content)) > 100 else str(last_message.content)
                logger.info(f"   æ¶ˆæ¯å†…å®¹é¢„è§ˆ: {content_preview}")
            
            logger.info("   ğŸ å†³ç­–: end (ç»“æŸå¯¹è¯)")
            return "end"

    async def _async_agent_node(self, state: AgentState) -> Dict[str, Any]:
        """å¼‚æ­¥Agent èŠ‚ç‚¹ï¼šä½¿ç”¨å¼‚æ­¥LLMè°ƒç”¨ã€‚"""
        # å¢åŠ é€’å½’è®¡æ•°
        if hasattr(self, '_recursion_count'):
            self._recursion_count += 1
        else:
            self._recursion_count = 1
            
        logger.info(f"ğŸ§  [Async Node] agent - Thread: {state['thread_id']} | é€’å½’è®¡æ•°: {self._recursion_count}/{config.RECURSION_LIMIT}")
        
        # è·å–å»ºè®®çš„ä¸‹ä¸€æ­¥æ“ä½œ
        next_step = state.get("suggested_next_step")
        
        # æ„å»ºå‘é€ç»™LLMçš„æ¶ˆæ¯åˆ—è¡¨
        messages_for_llm = state["messages"].copy()
        
        # ğŸ¯ æ·»åŠ æ•°æ®åº“èŒƒå›´ç³»ç»Ÿæç¤ºè¯ï¼ˆæ¯æ¬¡ç”¨æˆ·æé—®æ—¶æ·»åŠ ï¼‰
        if isinstance(state["messages"][-1], HumanMessage):
            db_scope_prompt = self._get_database_scope_prompt()
            if db_scope_prompt:
                messages_for_llm.insert(0, SystemMessage(content=db_scope_prompt))
                logger.info("   âœ… å·²æ·»åŠ æ•°æ®åº“èŒƒå›´åˆ¤æ–­æç¤ºè¯")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æéªŒè¯é”™è¯¯
        
        # è¡Œä¸ºæŒ‡ä»¤ä¸å·¥å…·å»ºè®®åˆ†ç¦»
        real_tools = {'valid_sql', 'run_sql'}
        
        if next_step:
            if next_step in real_tools:
                # åœºæ™¯1: å»ºè®®è°ƒç”¨ä¸€ä¸ªçœŸå®çš„å·¥å…·
                instruction = f"Suggestion: Based on the previous step, please use the '{next_step}' tool to continue."
                messages_for_llm.append(SystemMessage(content=instruction))
                logger.info(f"   âœ… å·²æ·»åŠ å·¥å…·å»ºè®®: {next_step}")

            elif next_step == "analyze_validation_error":
                # åœºæ™¯2: åˆ†æSQLéªŒè¯é”™è¯¯ï¼ˆç‰¹æ®ŠæŒ‡ä»¤ï¼‰
                for msg in reversed(state["messages"]):
                    if isinstance(msg, ToolMessage) and msg.name == "valid_sql":
                        error_guidance = self._generate_validation_error_guidance(msg.content)
                        messages_for_llm.append(SystemMessage(content=error_guidance))
                        logger.info("   âœ… å·²æ·»åŠ SQLéªŒè¯é”™è¯¯æŒ‡å¯¼")
                        break
            
            elif next_step == 'summarize_final_answer':
                # åœºæ™¯3: æ€»ç»“æœ€ç»ˆç­”æ¡ˆï¼ˆè¡Œä¸ºæŒ‡ä»¤ï¼‰
                instruction = "System Instruction: The SQL query was executed successfully. Please analyze the JSON data in the last message and summarize it in natural, user-friendly language as the final answer. Do not expose the raw JSON data or SQL statements in your response."
                messages_for_llm.append(SystemMessage(content=instruction))
                logger.info("   âœ… å·²æ·»åŠ  'æ€»ç»“ç­”æ¡ˆ' è¡Œä¸ºæŒ‡ä»¤")

            elif next_step == 'answer_with_common_sense':
                # åœºæ™¯4: åŸºäºå¸¸è¯†å›ç­”ï¼ˆç‰¹æ®ŠæŒ‡ä»¤ï¼‰
                instruction = (
                    "æ— æ³•ä¸ºå½“å‰é—®é¢˜ç”Ÿæˆæœ‰æ•ˆçš„SQLæŸ¥è¯¢ã€‚å¤±è´¥åŸå› å·²åœ¨ä¸Šä¸‹æ–‡ä¸­æä¾›ã€‚"
                    "è¯·ä½ ç›´æ¥åˆ©ç”¨è‡ªèº«çš„çŸ¥è¯†åº“æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸è¦å†é‡å¤è§£é‡Šå¤±è´¥çš„åŸå› ã€‚"
                )
                messages_for_llm.append(SystemMessage(content=instruction))
                logger.info("âœ… å·²æ·»åŠ  'å¸¸è¯†å›ç­”' è¡Œä¸ºæŒ‡ä»¤")

        # ğŸ›¡ï¸ æ·»åŠ é˜²å¹»è§‰ç³»ç»Ÿæç¤ºè¯ï¼ˆé‡ç‚¹é˜²æ­¢å‚æ•°ç¯¡æ”¹ï¼‰
        anti_hallucination_prompt = self._get_anti_hallucination_prompt(state)
        if anti_hallucination_prompt:
            messages_for_llm.append(SystemMessage(content=anti_hallucination_prompt))
            logger.info("   ğŸ›¡ï¸ å·²æ·»åŠ é˜²å¹»è§‰ç³»ç»Ÿæç¤ºè¯")

        # ğŸ” ã€æ–°å¢ã€‘è¯¦ç»†æ—¥å¿—ï¼šå‘é€ç»™LLMçš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼ˆæŒ‰å®é™…æäº¤é¡ºåºï¼‰
        logger.info("ğŸ“¤ å‘é€ç»™LLMçš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨å’Œå‚æ•°:")
        logger.info(f"   æ€»æ¶ˆæ¯æ•°: {len(messages_for_llm)}")
        logger.info("   æ¶ˆæ¯è¯¦æƒ…:")
        for i, msg in enumerate(messages_for_llm):
            msg_type = type(msg).__name__
            content = str(msg.content)
            
            # å¯¹äºé•¿å†…å®¹ï¼Œæ˜¾ç¤ºå‰500å­—ç¬¦å¹¶æ ‡è®°
            if len(content) > 500:
                content_display = content[:500] + f"... (å†…å®¹è¢«æˆªæ–­ï¼Œå®Œæ•´é•¿åº¦: {len(content)}å­—ç¬¦)"
            else:
                content_display = content
                
            logger.info(f"   [{i}] {msg_type}:")
            # å¤šè¡Œæ˜¾ç¤ºå†…å®¹ï¼Œä¾¿äºé˜…è¯»
            for line in content_display.split('\n'):
                logger.info(f"      {line}")

        # æ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†ç½‘ç»œè¿æ¥é—®é¢˜
        import asyncio
        max_retries = config.MAX_RETRIES
        for attempt in range(max_retries):
            try:
                # ğŸ” ã€è°ƒè¯•ã€‘æ‰“å°LLMè°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯
                logger.info(f"ğŸš€ å‡†å¤‡è°ƒç”¨LLM (å°è¯• {attempt + 1}/{max_retries})")
                logger.info(f"   LLMå®ä¾‹: {type(self.llm_with_tools)}")
                logger.info(f"   æ¶ˆæ¯æ•°é‡: {len(messages_for_llm)}")
                
                # ğŸ” ã€è°ƒè¯•ã€‘æ£€æŸ¥æ¶ˆæ¯æ ¼å¼æ˜¯å¦æ­£ç¡®
                for i, msg in enumerate(messages_for_llm):
                    logger.debug(f"   æ¶ˆæ¯[{i}] ç±»å‹: {type(msg)}")
                    logger.debug(f"   æ¶ˆæ¯[{i}] æœ‰content: {hasattr(msg, 'content')}")
                    if hasattr(msg, 'content'):
                        logger.debug(f"   æ¶ˆæ¯[{i}] contentç±»å‹: {type(msg.content)}")
                        logger.debug(f"   æ¶ˆæ¯[{i}] contenté•¿åº¦: {len(str(msg.content))}")
                
                # ä½¿ç”¨å¼‚æ­¥è°ƒç”¨
                logger.info("ğŸ”„ å¼€å§‹è°ƒç”¨LLM...")
                response = await self.llm_with_tools.ainvoke(messages_for_llm)
                logger.info("âœ… LLMè°ƒç”¨å®Œæˆ")
                
                # ğŸ” ã€è°ƒè¯•ã€‘è¯¦ç»†çš„å“åº”æ£€æŸ¥å’Œæ—¥å¿—
                logger.info(f"   å“åº”ç±»å‹: {type(response)}")
                logger.info(f"   å“åº”æœ‰content: {hasattr(response, 'content')}")
                logger.info(f"   å“åº”æœ‰tool_calls: {hasattr(response, 'tool_calls')}")
                logger.info(f"   LLMåŸå§‹å“åº”å†…å®¹: '{response.content}'")
                logger.info(f"   å“åº”å†…å®¹é•¿åº¦: {len(response.content) if response.content else 0}")
                logger.info(f"   å“åº”å†…å®¹ç±»å‹: {type(response.content)}")
                if hasattr(response, 'tool_calls'):
                    logger.info(f"   LLMæ˜¯å¦æœ‰å·¥å…·è°ƒç”¨: {response.tool_calls}")
                else:
                    logger.info(f"   LLMæ˜¯å¦æœ‰å·¥å…·è°ƒç”¨: æ— tool_callså±æ€§")

                if hasattr(response, 'tool_calls') and response.tool_calls:
                    logger.info(f"   å·¥å…·è°ƒç”¨æ•°é‡: {len(response.tool_calls)}")
                    for i, tool_call in enumerate(response.tool_calls):
                        logger.info(f"   å·¥å…·è°ƒç”¨[{i}]: {tool_call.get('name', 'Unknown')}")

                # ğŸ¯ æ”¹è¿›çš„å“åº”æ£€æŸ¥å’Œé‡è¯•é€»è¾‘
                # æ£€æŸ¥ç©ºå“åº”æƒ…å†µ - å°†ç©ºå“åº”ä¹Ÿè§†ä¸ºéœ€è¦é‡è¯•çš„æƒ…å†µ
                if not response.content and not (hasattr(response, 'tool_calls') and response.tool_calls):
                    logger.warning("   âš ï¸ LLMè¿”å›ç©ºå“åº”ä¸”æ— å·¥å…·è°ƒç”¨")
                    if attempt < max_retries - 1:
                        # ç©ºå“åº”ä¹Ÿè¿›è¡Œé‡è¯•
                        wait_time = config.RETRY_BASE_DELAY * (2 ** attempt)
                        logger.info(f"   ğŸ”„ ç©ºå“åº”é‡è¯•ï¼Œ{wait_time}ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é™çº§å›ç­”
                        logger.error(f"   âŒ å¤šæ¬¡å°è¯•ä»è¿”å›ç©ºå“åº”ï¼Œè¿”å›é™çº§å›ç­”")
                        fallback_content = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•æ­£ç¡®å¤„ç†æ‚¨çš„é—®é¢˜ã€‚è¯·ç¨åé‡è¯•æˆ–é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚"
                        fallback_response = AIMessage(content=fallback_content)
                        return {"messages": [fallback_response]}
                        
                elif response.content and response.content.strip() == "":
                    logger.warning("   âš ï¸ LLMè¿”å›åªåŒ…å«ç©ºç™½å­—ç¬¦çš„å†…å®¹")
                    if attempt < max_retries - 1:
                        # ç©ºç™½å­—ç¬¦ä¹Ÿè¿›è¡Œé‡è¯•
                        wait_time = config.RETRY_BASE_DELAY * (2 ** attempt)
                        logger.info(f"   ğŸ”„ ç©ºç™½å­—ç¬¦é‡è¯•ï¼Œ{wait_time}ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é™çº§å›ç­”
                        logger.error(f"   âŒ å¤šæ¬¡å°è¯•ä»è¿”å›ç©ºç™½å­—ç¬¦ï¼Œè¿”å›é™çº§å›ç­”")
                        fallback_content = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•æ­£ç¡®å¤„ç†æ‚¨çš„é—®é¢˜ã€‚è¯·ç¨åé‡è¯•æˆ–é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚"
                        fallback_response = AIMessage(content=fallback_content)
                        return {"messages": [fallback_response]}
                        
                elif not response.content and hasattr(response, 'tool_calls') and response.tool_calls:
                    logger.info("   âœ… LLMåªè¿”å›å·¥å…·è°ƒç”¨ï¼Œæ— æ–‡æœ¬å†…å®¹ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
                    
                # ğŸ¯ æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿å“åº”æ˜¯æœ‰æ•ˆçš„
                if ((response.content and response.content.strip()) or 
                    (hasattr(response, 'tool_calls') and response.tool_calls)):
                    logger.info(f"   âœ… å¼‚æ­¥LLMè°ƒç”¨æˆåŠŸï¼Œè¿”å›æœ‰æ•ˆå“åº”")
                    return {"messages": [response]}
                else:
                    # è¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä½œä¸ºæœ€åçš„ä¿éšœ
                    logger.error(f"   âŒ æ„å¤–çš„å“åº”æ ¼å¼ï¼Œè¿›è¡Œé‡è¯•")
                    if attempt < max_retries - 1:
                        wait_time = config.RETRY_BASE_DELAY * (2 ** attempt)
                        logger.info(f"   ğŸ”„ æ„å¤–å“åº”æ ¼å¼é‡è¯•ï¼Œ{wait_time}ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        fallback_content = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•æ­£ç¡®å¤„ç†æ‚¨çš„é—®é¢˜ã€‚è¯·ç¨åé‡è¯•æˆ–é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚"
                        fallback_response = AIMessage(content=fallback_content)
                        return {"messages": [fallback_response]}
                
            except Exception as e:
                error_msg = str(e)
                error_type = type(e).__name__
                logger.warning(f"   âš ï¸ LLMè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {error_type}: {error_msg}")
                
                # ğŸ¯ æ”¹è¿›çš„é”™è¯¯åˆ†ç±»é€»è¾‘ï¼šæ£€æŸ¥å¼‚å¸¸ç±»å‹å’Œé”™è¯¯æ¶ˆæ¯
                is_network_error = False
                is_parameter_error = False
                
                # 1. æ£€æŸ¥å¼‚å¸¸ç±»å‹
                network_exception_types = [
                    'APIConnectionError', 'ConnectTimeout', 'ReadTimeout', 
                    'TimeoutError', 'APITimeoutError', 'ConnectError', 
                    'HTTPError', 'RequestException', 'ConnectionError'
                ]
                if error_type in network_exception_types:
                    is_network_error = True
                    logger.info(f"   ğŸ“Š æ ¹æ®å¼‚å¸¸ç±»å‹åˆ¤æ–­ä¸ºç½‘ç»œé”™è¯¯: {error_type}")
                
                # 2. æ£€æŸ¥BadRequestErrorä¸­çš„å‚æ•°é”™è¯¯
                if error_type == 'BadRequestError':
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¶ˆæ¯æ ¼å¼é”™è¯¯
                    if any(keyword in error_msg.lower() for keyword in [
                        'must be followed by tool messages',
                        'invalid_parameter_error',
                        'assistant message with "tool_calls"',
                        'tool_call_id',
                        'message format'
                    ]):
                        is_parameter_error = True
                        logger.info(f"   ğŸ“Š æ ¹æ®é”™è¯¯æ¶ˆæ¯åˆ¤æ–­ä¸ºå‚æ•°æ ¼å¼é”™è¯¯: {error_msg[:100]}...")
                
                # 3. æ£€æŸ¥é”™è¯¯æ¶ˆæ¯å†…å®¹ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                error_msg_lower = error_msg.lower()
                network_keywords = [
                    'connection error', 'connect error', 'timeout', 'timed out',
                    'network', 'connection refused', 'connection reset',
                    'remote host', 'è¿œç¨‹ä¸»æœº', 'ç½‘ç»œè¿æ¥', 'è¿æ¥è¶…æ—¶',
                    'request timed out', 'read timeout', 'connect timeout'
                ]
                
                for keyword in network_keywords:
                    if keyword in error_msg_lower:
                        is_network_error = True
                        logger.info(f"   ğŸ“Š æ ¹æ®é”™è¯¯æ¶ˆæ¯åˆ¤æ–­ä¸ºç½‘ç»œé”™è¯¯: '{keyword}' in '{error_msg}'")
                        break
                
                # å¤„ç†å¯é‡è¯•çš„é”™è¯¯
                if is_network_error or is_parameter_error:
                    if attempt < max_retries - 1:
                        # æ¸è¿›å¼é‡è¯•é—´éš”ï¼š3, 6, 12ç§’
                        wait_time = config.RETRY_BASE_DELAY * (2 ** attempt)
                        error_type_desc = "ç½‘ç»œé”™è¯¯" if is_network_error else "å‚æ•°æ ¼å¼é”™è¯¯"
                        logger.info(f"   ğŸ”„ {error_type_desc}ï¼Œ{wait_time}ç§’åé‡è¯•...")
                        
                        # ğŸ¯ å¯¹äºå‚æ•°é”™è¯¯ï¼Œä¿®å¤æ¶ˆæ¯å†å²åé‡è¯•
                        if is_parameter_error:
                            try:
                                messages_for_llm = await self._handle_parameter_error_with_retry(
                                    messages_for_llm, error_msg, attempt
                                )
                                logger.info(f"   ğŸ”§ æ¶ˆæ¯å†å²ä¿®å¤å®Œæˆï¼Œç»§ç»­é‡è¯•...")
                            except Exception as fix_error:
                                logger.error(f"   âŒ æ¶ˆæ¯å†å²ä¿®å¤å¤±è´¥: {fix_error}")
                                # ä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¶ˆæ¯ç»§ç»­é‡è¯•
                        
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œè¿”å›ä¸€ä¸ªé™çº§çš„å›ç­”
                        error_type_desc = "ç½‘ç»œè¿æ¥" if is_network_error else "è¯·æ±‚æ ¼å¼"
                        logger.error(f"   âŒ {error_type_desc}æŒç»­å¤±è´¥ï¼Œè¿”å›é™çº§å›ç­”")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰SQLæ‰§è¡Œç»“æœå¯ä»¥åˆ©ç”¨
                        sql_data = await self._async_extract_latest_sql_data(state["messages"])
                        if sql_data:
                            fallback_content = f"æŠ±æ­‰ï¼Œç”±äº{error_type_desc}é—®é¢˜ï¼Œæ— æ³•ç”Ÿæˆå®Œæ•´çš„æ–‡å­—æ€»ç»“ã€‚ä¸è¿‡æŸ¥è¯¢å·²æˆåŠŸæ‰§è¡Œï¼Œç»“æœå¦‚ä¸‹ï¼š\n\n" + sql_data
                        else:
                            fallback_content = f"æŠ±æ­‰ï¼Œç”±äº{error_type_desc}é—®é¢˜ï¼Œæ— æ³•å®Œæˆæ­¤æ¬¡è¯·æ±‚ã€‚è¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚"
                            
                        fallback_response = AIMessage(content=fallback_content)
                        return {"messages": [fallback_response]}
                else:
                    # éç½‘ç»œé”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                    logger.error(f"   âŒ LLMè°ƒç”¨å‡ºç°éå¯é‡è¯•é”™è¯¯: {error_type}: {error_msg}")
                    raise e
    
    def _print_state_info(self, state: AgentState, node_name: str) -> None:
        """
        æ‰“å° state çš„å…¨éƒ¨ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•
        """
        logger.info(" ~" * 10 + " State Print Start" + " ~" * 10)
        logger.info(f"ğŸ“‹ [State Debug] {node_name} - å½“å‰çŠ¶æ€ä¿¡æ¯:")
        
        # ğŸ¯ æ‰“å° state ä¸­çš„æ‰€æœ‰å­—æ®µ
        logger.info("   Stateä¸­çš„æ‰€æœ‰å­—æ®µ:")
        for key, value in state.items():
            if key == "messages":
                logger.info(f"     {key}: {len(value)} æ¡æ¶ˆæ¯")
            else:
                logger.info(f"     {key}: {value}")
        
        # åŸæœ‰çš„è¯¦ç»†æ¶ˆæ¯ä¿¡æ¯
        logger.info(f"   ç”¨æˆ·ID: {state.get('user_id', 'N/A')}")
        logger.info(f"   çº¿ç¨‹ID: {state.get('thread_id', 'N/A')}")
        logger.info(f"   å»ºè®®ä¸‹ä¸€æ­¥: {state.get('suggested_next_step', 'N/A')}")
        
        messages = state.get("messages", [])
        logger.info(f"   æ¶ˆæ¯å†å²æ•°é‡: {len(messages)}")
        
        if messages:
            logger.info("   æœ€è¿‘çš„æ¶ˆæ¯:")
            for i, msg in enumerate(messages[-10:], start=max(0, len(messages)-10)):  # æ˜¾ç¤ºæœ€å10æ¡æ¶ˆæ¯
                msg_type = type(msg).__name__
                content = str(msg.content)
                
                # å¯¹äºé•¿å†…å®¹ï¼Œä½¿ç”¨å¤šè¡Œæ˜¾ç¤º
                if len(content) > 200:
                    logger.info(f"     [{i}] {msg_type}:")
                    logger.info(f"         {content}")
                else:
                    logger.info(f"     [{i}] {msg_type}: {content}")
                
                # å¦‚æœæ˜¯ AIMessage ä¸”æœ‰å·¥å…·è°ƒç”¨ï¼Œæ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    for tool_call in msg.tool_calls:
                        tool_name = tool_call.get('name', 'Unknown')
                        tool_args = tool_call.get('args', {})
                        logger.info(f"         å·¥å…·è°ƒç”¨: {tool_name}")
                        
                        # å¯¹äºå¤æ‚å‚æ•°ï¼Œä½¿ç”¨JSONæ ¼å¼åŒ–
                        import json
                        try:
                            formatted_args = json.dumps(tool_args, ensure_ascii=False, indent=2)
                            logger.info(f"         å‚æ•°:")
                            for line in formatted_args.split('\n'):
                                logger.info(f"           {line}")
                        except Exception:
                            logger.info(f"         å‚æ•°: {str(tool_args)}")
        
        logger.info(" ~" * 10 + " State Print End" + " ~" * 10)

    async def _async_prepare_tool_input_node(self, state: AgentState) -> Dict[str, Any]:
        """å¼‚æ­¥å‡†å¤‡å·¥å…·è¾“å…¥èŠ‚ç‚¹ï¼šä¸ºgenerate_sqlå·¥å…·æ³¨å…¥history_messagesã€‚"""
        # å¢åŠ é€’å½’è®¡æ•°
        if hasattr(self, '_recursion_count'):
            self._recursion_count += 1
        else:
            self._recursion_count = 1
            
        logger.info(f"ğŸ”§ [Async Node] prepare_tool_input - Thread: {state['thread_id']} | é€’å½’è®¡æ•°: {self._recursion_count}/{config.RECURSION_LIMIT}")
        
        # è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆåº”è¯¥æ˜¯æ¥è‡ªagentçš„AIMessageï¼‰
        last_message = state["messages"][-1]

        if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
            return {"messages": [last_message]}

        # å¼ºåˆ¶ä¿®æ­£LLMå¹»è§‰å‡ºçš„é—®é¢˜
        for tool_call in last_message.tool_calls:
            if tool_call['name'] == 'generate_sql':
                original_user_question = next((msg.content for msg in reversed(state['messages']) if isinstance(msg, HumanMessage)), None)
                if original_user_question and tool_call['args'].get('question') != original_user_question:
                    logger.warning(
                        f"ä¿®æ­£ 'generate_sql' çš„é—®é¢˜å‚æ•°ã€‚\n"
                        f"  - LLMæä¾›: '{tool_call['args'].get('question')}'\n"
                        f"  + ä¿®æ­£ä¸º: '{original_user_question}'"
                    )
                    tool_call['args']['question'] = original_user_question

        # æ¢å¤åŸå§‹çš„ã€æ›´å¥å£®çš„å†å²æ¶ˆæ¯è¿‡æ»¤å’Œæ³¨å…¥é€»è¾‘
        new_tool_calls = []
        for tool_call in last_message.tool_calls:
            if tool_call["name"] == "generate_sql":
                logger.info("æ£€æµ‹åˆ° generate_sql è°ƒç”¨ï¼Œå¼€å§‹æ³¨å…¥å†å²æ¶ˆæ¯ã€‚")
                modified_args = tool_call["args"].copy()
                
                clean_history = []
                
                # æ‰¾åˆ°å½“å‰ç”¨æˆ·é—®é¢˜ï¼Œç¡®ä¿ä¸åŒ…å«åœ¨å†å²ä¸Šä¸‹æ–‡ä¸­
                current_user_question = None
                messages_for_history = []
                
                # ä»æœ€åå¼€å§‹æ‰¾åˆ°å½“å‰ç”¨æˆ·é—®é¢˜
                for i in range(len(state["messages"]) - 1, -1, -1):
                    msg = state["messages"][i]
                    if isinstance(msg, HumanMessage):
                        current_user_question = msg.content
                        messages_for_history = state["messages"][:i]  # æ’é™¤å½“å‰ç”¨æˆ·é—®é¢˜åŠä¹‹åçš„æ¶ˆæ¯
                        break
                
                # å¤„ç†å†å²æ¶ˆæ¯ï¼Œç¡®ä¿ä¸åŒ…å«å½“å‰ç”¨æˆ·é—®é¢˜
                for msg in messages_for_history:
                    if isinstance(msg, HumanMessage):
                        clean_history.append({"type": "human", "content": msg.content})
                    elif isinstance(msg, AIMessage):
                        if not msg.tool_calls and msg.content:
                            # æ³¨é‡Šæ‰ [Formatted Output] æ¸…ç†é€»è¾‘ - æºå¤´å·²ä¸ç”Ÿæˆå‰ç¼€
                            # clean_content = msg.content.replace("[Formatted Output]\n", "").strip()
                            clean_content = msg.content.strip()
                            if clean_content:
                                clean_history.append({"type": "ai", "content": clean_content})
                
                modified_args["history_messages"] = clean_history
                logger.info(f"æ³¨å…¥äº† {len(clean_history)} æ¡è¿‡æ»¤åçš„å†å²æ¶ˆæ¯")
                
                new_tool_calls.append({
                    "name": tool_call["name"],
                    "args": modified_args,
                    "id": tool_call["id"],
                })
            else:
                new_tool_calls.append(tool_call)
        
        last_message.tool_calls = new_tool_calls
        return {"messages": [last_message]}

    def _filter_and_format_history(self, messages: list) -> list:
        """
        è¿‡æ»¤å’Œæ ¼å¼åŒ–å†å²æ¶ˆæ¯ï¼Œä¸ºgenerate_sqlå·¥å…·æä¾›å¹²å‡€çš„ä¸Šä¸‹æ–‡ã€‚
        åªä¿ç•™å†å²ä¸­çš„ç”¨æˆ·æé—®å’ŒAIçš„æœ€ç»ˆå›ç­”ã€‚
        """
        clean_history = []
        # å¤„ç†é™¤æœ€åä¸€ä¸ªï¼ˆå³å½“å‰çš„å·¥å…·è°ƒç”¨ï¼‰ä¹‹å¤–çš„æ‰€æœ‰æ¶ˆæ¯
        messages_to_process = messages[:-1]

        for msg in messages_to_process:
            if isinstance(msg, HumanMessage):
                clean_history.append({"type": "human", "content": msg.content})
            elif isinstance(msg, AIMessage):
                # åªä¿ç•™æœ€ç»ˆçš„ã€é¢å‘ç”¨æˆ·çš„å›ç­”ï¼ˆä¸åŒ…å«å·¥å…·è°ƒç”¨çš„çº¯æ–‡æœ¬å›ç­”ï¼‰
                if not msg.tool_calls and msg.content:
                    # æ³¨é‡Šæ‰ [Formatted Output] æ¸…ç†é€»è¾‘ - æºå¤´å·²ä¸ç”Ÿæˆå‰ç¼€
                    # clean_content = msg.content.replace("[Formatted Output]\n", "").strip()
                    clean_content = msg.content.strip()
                    if clean_content:
                        clean_history.append({"type": "ai", "content": clean_content})
        
        return clean_history

    async def _async_update_state_after_tool_node(self, state: AgentState) -> Dict[str, Any]:
        """å¼‚æ­¥æ›´æ–°å·¥å…·æ‰§è¡Œåçš„çŠ¶æ€ã€‚"""
        # å¢åŠ é€’å½’è®¡æ•°
        if hasattr(self, '_recursion_count'):
            self._recursion_count += 1
        else:
            self._recursion_count = 1
            
        logger.info(f"ğŸ“ [Async Node] update_state_after_tool - Thread: {state['thread_id']} | é€’å½’è®¡æ•°: {self._recursion_count}/{config.RECURSION_LIMIT}")
        
        # è·å–æœ€åä¸€æ¡å·¥å…·æ¶ˆæ¯
        last_message = state["messages"][-1]
        tool_name = last_message.name
        tool_output = last_message.content
        next_step = None

        if tool_name == 'generate_sql':
            # ä½¿ç”¨ .lower() å°†è¾“å‡ºè½¬ä¸ºå°å†™ï¼Œå¯ä»¥åŒæ—¶æ•è· "failed" å’Œ "Failed" ç­‰æƒ…å†µ
            tool_output_lower = tool_output.lower()
            if "failed" in tool_output_lower or "æ— æ³•ç”Ÿæˆ" in tool_output_lower or "å¤±è´¥" in tool_output_lower:
                next_step = 'answer_with_common_sense'
            else:
                next_step = 'valid_sql'
        
        elif tool_name == 'valid_sql':
            if "å¤±è´¥" in tool_output:
                next_step = 'analyze_validation_error'
            else:
                next_step = 'run_sql'

        elif tool_name == 'run_sql':
            next_step = 'summarize_final_answer'
            
        logger.info(f"   Tool '{tool_name}' executed. Suggested next step: {next_step}")
        return {"suggested_next_step": next_step}

    def _clear_history_messages_parameter(self, messages: List[BaseMessage]) -> None:
        """
        å°† generate_sql å·¥å…·çš„ history_messages å‚æ•°è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
        """
        for message in messages:
            if hasattr(message, "tool_calls") and message.tool_calls:
                for tool_call in message.tool_calls:
                    if tool_call["name"] == "generate_sql" and "history_messages" in tool_call["args"]:
                        tool_call["args"]["history_messages"] = ""
                        logger.info(f"   å·²å°† generate_sql çš„ history_messages è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²")

    async def _async_format_final_response_node(self, state: AgentState) -> Dict[str, Any]:
        """å¼‚æ­¥æ ¼å¼åŒ–æœ€ç»ˆå“åº”èŠ‚ç‚¹ã€‚"""
        # å¢åŠ é€’å½’è®¡æ•°
        if hasattr(self, '_recursion_count'):
            self._recursion_count += 1
        else:
            self._recursion_count = 1
            
        logger.info(f"âœ¨ [Async Node] format_final_response - Thread: {state['thread_id']} | é€’å½’è®¡æ•°: {self._recursion_count}/{config.RECURSION_LIMIT}")
        
        # è¿™ä¸ªèŠ‚ç‚¹ä¸»è¦ç”¨äºæœ€ç»ˆå¤„ç†ï¼Œé€šå¸¸ä¸éœ€è¦ä¿®æ”¹çŠ¶æ€
        return {"messages": state["messages"]}

    async def _async_generate_api_data(self, state: AgentState) -> Dict[str, Any]:
        """å¼‚æ­¥ç”ŸæˆAPIæ ¼å¼çš„æ•°æ®ç»“æ„"""
        logger.info("ğŸ“Š å¼‚æ­¥ç”ŸæˆAPIæ ¼å¼æ•°æ®...")
        
        last_message = state['messages'][-1]
        response_content = last_message.content
        
        # æ³¨é‡Šæ‰ [Formatted Output] æ¸…ç†é€»è¾‘ - æºå¤´å·²ä¸ç”Ÿæˆå‰ç¼€
        # if response_content.startswith("[Formatted Output]\n"):
        #     response_content = response_content.replace("[Formatted Output]\n", "")
        
        api_data = {
            "response": response_content
        }

        # --- æ–°å¢é€»è¾‘ï¼šä¸º answer_with_common_sense åœºæ™¯æ‹¼æ¥å“åº” ---
        if state.get("suggested_next_step") == 'answer_with_common_sense':
            failure_reason = self._find_generate_sql_failure_reason(state['messages'])
            if failure_reason:
                # å°† "Database query failed. Reason: " å‰ç¼€ç§»é™¤ï¼Œä½¿å…¶æ›´è‡ªç„¶
                cleaned_reason = failure_reason.replace("Database query failed. Reason:", "").strip()
                # æ‹¼æ¥å¤±è´¥åŸå› å’ŒLLMçš„å¸¸è¯†å›ç­”
                api_data["response"] = f"{cleaned_reason}\n\n{response_content}"
                logger.info("   âœ… å·²æˆåŠŸæ‹¼æ¥ 'å¤±è´¥åŸå› ' å’Œ 'å¸¸è¯†å›ç­”'")
        
        sql_info = await self._async_extract_sql_and_data(state['messages'])
        if sql_info['sql']:
            api_data["sql"] = sql_info['sql']
        if sql_info['records']:
            api_data["records"] = sql_info['records']
        
        # ç”ŸæˆAgentå…ƒæ•°æ®
        api_data["react_agent_meta"] = await self._async_collect_agent_metadata(state)
        
        logger.info(f"   APIæ•°æ®ç”Ÿæˆå®Œæˆï¼ŒåŒ…å«å­—æ®µ: {list(api_data.keys())}")
        return api_data

    def _find_generate_sql_failure_reason(self, messages: List[BaseMessage]) -> Optional[str]:
        """ä»åå‘å‰æŸ¥æ‰¾æœ€è¿‘ä¸€æ¬¡generate_sqlå¤±è´¥çš„åŸå› """
        for msg in reversed(messages):
            if isinstance(msg, ToolMessage) and msg.name == 'generate_sql':
                # æ‰¾åˆ°æœ€è¿‘çš„generate_sqlå·¥å…·æ¶ˆæ¯
                if "failed" in msg.content.lower() or "å¤±è´¥" in msg.content.lower():
                    return msg.content
                else:
                    # å¦‚æœæ˜¯æˆåŠŸçš„æ¶ˆæ¯ï¼Œè¯´æ˜å½“å‰è½®æ¬¡æ²¡æœ‰å¤±è´¥ï¼Œåœæ­¢æŸ¥æ‰¾
                    return None
        return None

    async def _async_extract_sql_and_data(self, messages: List[BaseMessage]) -> Dict[str, Any]:
        """å¼‚æ­¥ä»æ¶ˆæ¯å†å²ä¸­æå–SQLå’Œæ•°æ®è®°å½•"""
        result = {"sql": None, "records": None}
        
        # æŸ¥æ‰¾æœ€åä¸€ä¸ªHumanMessageä¹‹åçš„å·¥å…·æ‰§è¡Œç»“æœ
        last_human_index = -1
        for i in range(len(messages) - 1, -1, -1):
            if isinstance(messages[i], HumanMessage):
                last_human_index = i
                break
        
        if last_human_index == -1:
            return result
        
        # åœ¨å½“å‰å¯¹è¯è½®æ¬¡ä¸­æŸ¥æ‰¾å·¥å…·æ‰§è¡Œç»“æœ
        current_conversation = messages[last_human_index:]
        
        sql_query = None
        sql_data = None
        
        for msg in current_conversation:
            if isinstance(msg, ToolMessage):
                if msg.name == 'generate_sql':
                    # æå–ç”Ÿæˆçš„SQL
                    content = msg.content
                    if content and not any(keyword in content for keyword in ["å¤±è´¥", "æ— æ³•ç”Ÿæˆ", "Database query failed"]):
                        sql_query = content.strip()
                        
                elif msg.name == 'run_sql':
                    # æå–SQLæ‰§è¡Œç»“æœ
                    try:
                        import json
                        parsed_data = json.loads(msg.content)
                        if isinstance(parsed_data, list) and len(parsed_data) > 0:
                            # DataFrame.to_json(orient='records') æ ¼å¼
                            columns = list(parsed_data[0].keys()) if parsed_data else []
                            sql_data = {
                                "columns": columns,
                                "rows": parsed_data,
                                "total_row_count": len(parsed_data),
                                "is_limited": False  # å½“å‰ç‰ˆæœ¬æ²¡æœ‰å®ç°é™åˆ¶
                            }
                    except (json.JSONDecodeError, Exception) as e:
                        logger.warning(f"   è§£æSQLç»“æœå¤±è´¥: {e}")
        
        if sql_query:
            result["sql"] = sql_query
        if sql_data:
            result["records"] = sql_data
            
        return result

    async def _async_collect_agent_metadata(self, state: AgentState) -> Dict[str, Any]:
        """æ”¶é›†Agentå…ƒæ•°æ®"""
        messages = state['messages']
        
        # ç»Ÿè®¡å·¥å…·ä½¿ç”¨æƒ…å†µ
        tools_used = []
        sql_execution_count = 0
        context_injected = False
        
        # è®¡ç®—å¯¹è¯è½®æ¬¡ï¼ˆHumanMessageçš„æ•°é‡ï¼‰
        conversation_rounds = sum(1 for msg in messages if isinstance(msg, HumanMessage))
        
        # åˆ†æå·¥å…·è°ƒç”¨å’Œæ‰§è¡Œ
        for msg in messages:
            if isinstance(msg, ToolMessage):
                if msg.name not in tools_used:
                    tools_used.append(msg.name)
                if msg.name == 'run_sql':
                    sql_execution_count += 1
            elif isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tool_call in msg.tool_calls:
                    tool_name = tool_call.get('name')
                    if tool_name and tool_name not in tools_used:
                        tools_used.append(tool_name)
                    
                    # æ£€æŸ¥æ˜¯å¦æ³¨å…¥äº†å†å²ä¸Šä¸‹æ–‡
                    if (tool_name == 'generate_sql' and 
                        tool_call.get('args', {}).get('history_messages')):
                        context_injected = True
        
        # æ„å»ºæ‰§è¡Œè·¯å¾„ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        execution_path = ["agent"]
        if tools_used:
            execution_path.extend(["prepare_tool_input", "tools"])
        execution_path.append("format_final_response")
        
        return {
            "thread_id": state['thread_id'],
            "conversation_rounds": conversation_rounds,
            "tools_used": tools_used,
            "execution_path": execution_path,
            "total_messages": len(messages),
            "sql_execution_count": sql_execution_count,
            "context_injected": context_injected,
            "agent_version": "custom_react_v1"
        }

    async def _async_extract_latest_sql_data(self, messages: List[BaseMessage]) -> Optional[str]:
        """ä»æ¶ˆæ¯å†å²ä¸­æå–æœ€è¿‘çš„run_sqlæ‰§è¡Œç»“æœï¼Œä½†ä»…é™äºå½“å‰å¯¹è¯è½®æ¬¡ã€‚"""
        logger.info("ğŸ” æå–æœ€æ–°çš„SQLæ‰§è¡Œç»“æœ...")
        
        # ğŸ¯ åªæŸ¥æ‰¾æœ€åä¸€ä¸ªHumanMessageä¹‹åçš„SQLæ‰§è¡Œç»“æœ
        last_human_index = -1
        for i in range(len(messages) - 1, -1, -1):
            if isinstance(messages[i], HumanMessage):
                last_human_index = i
                break
        
        if last_human_index == -1:
            logger.info("   æœªæ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯ï¼Œè·³è¿‡SQLæ•°æ®æå–")
            return None
        
        # åªåœ¨å½“å‰å¯¹è¯è½®æ¬¡ä¸­æŸ¥æ‰¾SQLç»“æœ
        current_conversation = messages[last_human_index:]
        logger.info(f"   å½“å‰å¯¹è¯è½®æ¬¡åŒ…å« {len(current_conversation)} æ¡æ¶ˆæ¯")
        
        for msg in reversed(current_conversation):
            if isinstance(msg, ToolMessage) and msg.name == 'run_sql':
                logger.info(f"   æ‰¾åˆ°å½“å‰å¯¹è¯è½®æ¬¡çš„run_sqlç»“æœ: {msg.content[:100]}...")
                
                # ğŸ¯ å¤„ç†Unicodeè½¬ä¹‰åºåˆ—ï¼Œå°†å…¶è½¬æ¢ä¸ºæ­£å¸¸çš„ä¸­æ–‡å­—ç¬¦
                try:
                    # å…ˆå°è¯•è§£æJSONä»¥éªŒè¯æ ¼å¼
                    parsed_data = json.loads(msg.content)
                    # é‡æ–°åºåˆ—åŒ–ï¼Œç¡®ä¿ä¸­æ–‡å­—ç¬¦æ­£å¸¸æ˜¾ç¤º
                    formatted_content = json.dumps(parsed_data, ensure_ascii=False, separators=(',', ':'))
                    logger.info(f"   å·²è½¬æ¢Unicodeè½¬ä¹‰åºåˆ—ä¸ºä¸­æ–‡å­—ç¬¦")
                    return formatted_content
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œç›´æ¥è¿”å›åŸå†…å®¹
                    logger.warning(f"   SQLç»“æœä¸æ˜¯æœ‰æ•ˆJSONæ ¼å¼ï¼Œè¿”å›åŸå§‹å†…å®¹")
                    return msg.content
        
        logger.info("   å½“å‰å¯¹è¯è½®æ¬¡ä¸­æœªæ‰¾åˆ°run_sqlæ‰§è¡Œç»“æœ")
        return None

    async def chat(self, message: str, user_id: str, thread_id: Optional[str] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·èŠå¤©è¯·æ±‚ã€‚
        """
        if not thread_id:
            now = pd.Timestamp.now()
            milliseconds = int(now.microsecond / 1000)
            thread_id = f"{user_id}:{now.strftime('%Y%m%d%H%M%S')}{milliseconds:03d}"
            logger.info(f"ğŸ†• æ–°å»ºä¼šè¯ï¼ŒThread ID: {thread_id}")
        
        # åˆå§‹åŒ–é€’å½’è®¡æ•°å™¨ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
        self._recursion_count = 0
        
        run_config = {
            "configurable": {
                "thread_id": thread_id,
            },
            "recursion_limit": config.RECURSION_LIMIT
        }
        
        logger.info(f"ğŸ”¢ é€’å½’é™åˆ¶è®¾ç½®: {config.RECURSION_LIMIT}")
        
        inputs = {
            "messages": [HumanMessage(content=message)],
            "user_id": user_id,
            "thread_id": thread_id,
            "suggested_next_step": None,
        }

        try:
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†ç”¨æˆ·æ¶ˆæ¯: {message[:50]}...")
            
            # æ£€æŸ¥checkpointerçŠ¶æ€ï¼Œå¦‚æœRedisè¿æ¥æœ‰é—®é¢˜åˆ™é‡æ–°åˆå§‹åŒ–
            if self.checkpointer:
                try:
                    # ç®€å•çš„è¿æ¥æµ‹è¯• - ä¸ç”¨aget_tupleå› ä¸ºå¯èƒ½æ²¡æœ‰æ•°æ®
                    # ç›´æ¥æµ‹è¯•Redisè¿æ¥
                    if hasattr(self.checkpointer, 'conn') and self.checkpointer.conn:
                        await self.checkpointer.conn.ping()
                except Exception as checkpoint_error:
                    if "Event loop is closed" in str(checkpoint_error) or "closed" in str(checkpoint_error).lower():
                        logger.warning(f"âš ï¸ Checkpointerè¿æ¥å¼‚å¸¸ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–: {checkpoint_error}")
                        await self._reinitialize_checkpointer()
                        # é‡æ–°æ„å»ºgraphä½¿ç”¨æ–°çš„checkpointer
                        self.agent_executor = self._create_graph()
                    else:
                        logger.warning(f"âš ï¸ Checkpointeræµ‹è¯•å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ: {checkpoint_error}")
            
            final_state = await self.agent_executor.ainvoke(inputs, run_config)
            
            # ğŸ” è°ƒè¯•ï¼šæ‰“å° final_state çš„æ‰€æœ‰ keys
            logger.info(f"ğŸ” Final state keys: {list(final_state.keys())}")
            
            answer = final_state["messages"][-1].content
            
            # ğŸ¯ æå–æœ€è¿‘çš„ run_sql æ‰§è¡Œç»“æœï¼ˆä¸ä¿®æ”¹messagesï¼‰
            sql_data = await self._async_extract_latest_sql_data(final_state["messages"])
            
            logger.info(f"âœ… å¤„ç†å®Œæˆ - Final Answer: '{answer}'")
            
            # æ„å»ºè¿”å›ç»“æœï¼ˆä¿æŒç®€åŒ–æ ¼å¼ç”¨äºshell.pyï¼‰
            result = {
                "success": True, 
                "answer": answer, 
                "thread_id": thread_id
            }
            
            # åªæœ‰å½“å­˜åœ¨SQLæ•°æ®æ—¶æ‰æ·»åŠ åˆ°è¿”å›ç»“æœä¸­
            if sql_data:
                result["sql_data"] = sql_data
                logger.info("   ğŸ“Š å·²åŒ…å«SQLåŸå§‹æ•°æ®")
            
            # ç”ŸæˆAPIæ ¼å¼æ•°æ®
            api_data = await self._async_generate_api_data(final_state)
            result["api_data"] = api_data
            logger.info("   ğŸ”Œ å·²ç”ŸæˆAPIæ ¼å¼æ•°æ®")
            
            return result
            
        except Exception as e:
            # ç‰¹æ®Šå¤„ç†Redisç›¸å…³çš„Event loopé”™è¯¯
            if "Event loop is closed" in str(e):
                logger.error(f"âŒ Redis Event loopå·²å…³é—­ - Thread: {thread_id}: {e}")
                # å°è¯•é‡æ–°åˆå§‹åŒ–checkpointer
                try:
                    await self._reinitialize_checkpointer()
                    self.agent_executor = self._create_graph()
                    logger.info("ğŸ”„ å·²é‡æ–°åˆå§‹åŒ–checkpointerï¼Œè¯·é‡è¯•è¯·æ±‚")
                except Exception as reinit_error:
                    logger.error(f"âŒ é‡æ–°åˆå§‹åŒ–å¤±è´¥: {reinit_error}")
                
                return {
                    "success": False, 
                    "error": "Redisè¿æ¥é—®é¢˜ï¼Œè¯·é‡è¯•", 
                    "thread_id": thread_id,
                    "retry_suggested": True
                }
            else:
                logger.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ - Thread: {thread_id}: {e}", exc_info=True)
                return {"success": False, "error": str(e), "thread_id": thread_id}
    
    async def get_conversation_history(self, thread_id: str, include_tools: bool = False) -> Dict[str, Any]:
        """
        ä» checkpointer è·å–æŒ‡å®šçº¿ç¨‹çš„å¯¹è¯å†å²ï¼Œæ”¯æŒæ¶ˆæ¯è¿‡æ»¤å’Œæ—¶é—´æˆ³ã€‚
        
        Args:
            thread_id: çº¿ç¨‹ID
            include_tools: æ˜¯å¦åŒ…å«å·¥å…·æ¶ˆæ¯ï¼Œé»˜è®¤Falseï¼ˆåªè¿”å›humanå’Œaiæ¶ˆæ¯ï¼‰
            
        Returns:
            DictåŒ…å«: {
                "messages": List[Dict],  # æ¶ˆæ¯åˆ—è¡¨
                "thread_created_at": str,  # çº¿ç¨‹åˆ›å»ºæ—¶é—´
                "total_checkpoints": int   # æ€»checkpointæ•°
            }
        """
        if not self.checkpointer:
            return {"messages": [], "thread_created_at": None, "total_checkpoints": 0}
        
        thread_config = {"configurable": {"thread_id": thread_id}}
        
        try:
            # è·å–æ‰€æœ‰å†å²checkpointï¼ŒæŒ‰æ—¶é—´å€’åº
            checkpoints = []
            async for checkpoint_tuple in self.checkpointer.alist(thread_config):
                checkpoints.append(checkpoint_tuple)
            
            if not checkpoints:
                return {"messages": [], "thread_created_at": None, "total_checkpoints": 0}
            
            # è§£æthread_idä¸­çš„åˆ›å»ºæ—¶é—´
            thread_created_at = self._parse_thread_creation_time(thread_id)
            
            # æ„å»ºæ¶ˆæ¯åˆ°æ—¶é—´æˆ³çš„æ˜ å°„
            message_timestamps = self._build_message_timestamp_map(checkpoints)
            
            # è·å–æœ€æ–°çŠ¶æ€çš„æ¶ˆæ¯
            latest_checkpoint = checkpoints[0]
            messages = latest_checkpoint.checkpoint.get('channel_values', {}).get('messages', [])
            
            # è¿‡æ»¤å’Œæ ¼å¼åŒ–æ¶ˆæ¯
            filtered_messages = []
            for msg in messages:
                # ç¡®å®šæ¶ˆæ¯ç±»å‹
                if isinstance(msg, HumanMessage):
                    msg_type = "human"
                elif isinstance(msg, ToolMessage):
                    if not include_tools:
                        continue  # è·³è¿‡å·¥å…·æ¶ˆæ¯
                    msg_type = "tool"
                else:  # AIMessage
                    msg_type = "ai"
                    # å¦‚æœä¸åŒ…å«å·¥å…·æ¶ˆæ¯ï¼Œè·³è¿‡åªæœ‰å·¥å…·è°ƒç”¨æ²¡æœ‰å†…å®¹çš„AIæ¶ˆæ¯
                    if not include_tools and (not msg.content and hasattr(msg, 'tool_calls') and msg.tool_calls):
                        continue
                
                # è·å–æ¶ˆæ¯ID
                msg_id = getattr(msg, 'id', None)
                if not msg_id:
                    continue  # è·³è¿‡æ²¡æœ‰IDçš„æ¶ˆæ¯
                
                # è·å–æ—¶é—´æˆ³
                timestamp = message_timestamps.get(msg_id)
                if not timestamp:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²¾ç¡®æ—¶é—´æˆ³ï¼Œä½¿ç”¨æœ€æ–°checkpointçš„æ—¶é—´
                    timestamp = latest_checkpoint.checkpoint.get('ts')
                
                filtered_messages.append({
                    "id": msg_id,
                    "type": msg_type,
                    "content": msg.content,
                    "timestamp": timestamp
                })
            
            return {
                "messages": filtered_messages,
                "thread_created_at": thread_created_at,
                "total_checkpoints": len(checkpoints)
            }
            
        except RuntimeError as e:
            if "Event loop is closed" in str(e):
                logger.warning(f"âš ï¸ Event loopå·²å…³é—­ï¼Œå°è¯•é‡æ–°è·å–å¯¹è¯å†å²: {thread_id}")
                return {"messages": [], "thread_created_at": None, "total_checkpoints": 0}
            else:
                raise
        except Exception as e:
            logger.error(f"âŒ è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return {"messages": [], "thread_created_at": None, "total_checkpoints": 0}
    
    def _parse_thread_creation_time(self, thread_id: str) -> str:
        """è§£æthread_idä¸­çš„åˆ›å»ºæ—¶é—´ï¼Œè¿”å›å¸¦æ¯«ç§’çš„æ ¼å¼"""
        try:
            if ':' in thread_id:
                parts = thread_id.split(':')
                if len(parts) >= 2:
                    timestamp_part = parts[1]
                    if len(timestamp_part) >= 14:
                        year = timestamp_part[:4]
                        month = timestamp_part[4:6] 
                        day = timestamp_part[6:8]
                        hour = timestamp_part[8:10]
                        minute = timestamp_part[10:12]
                        second = timestamp_part[12:14]
                        ms = timestamp_part[14:17] if len(timestamp_part) > 14 else "000"
                        return f"{year}-{month}-{day} {hour}:{minute}:{second}.{ms}"
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æthreadåˆ›å»ºæ—¶é—´å¤±è´¥: {e}")
        return None
    
    def _build_message_timestamp_map(self, checkpoints: List) -> Dict[str, str]:
        """æ„å»ºæ¶ˆæ¯IDåˆ°æ—¶é—´æˆ³çš„æ˜ å°„"""
        message_timestamps = {}
        
        # æŒ‰æ—¶é—´æ­£åºæ’åˆ—checkpointï¼ˆæœ€æ—©çš„åœ¨å‰ï¼‰
        checkpoints_sorted = sorted(checkpoints, key=lambda x: x.checkpoint.get('ts', ''))
        
        for checkpoint_tuple in checkpoints_sorted:
            checkpoint_ts = checkpoint_tuple.checkpoint.get('ts')
            messages = checkpoint_tuple.checkpoint.get('channel_values', {}).get('messages', [])
            
            # ä¸ºè¿™ä¸ªcheckpointä¸­çš„æ–°æ¶ˆæ¯åˆ†é…æ—¶é—´æˆ³
            for msg in messages:
                msg_id = getattr(msg, 'id', None)
                if msg_id and msg_id not in message_timestamps:
                    message_timestamps[msg_id] = checkpoint_ts
        
        return message_timestamps 

    async def get_user_recent_conversations(self, user_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šç”¨æˆ·çš„æœ€è¿‘èŠå¤©è®°å½•åˆ—è¡¨
        åˆ©ç”¨thread_idæ ¼å¼ 'user_id:timestamp' æ¥æŸ¥è¯¢
        """
        if not self.checkpointer:
            return []
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„å¼‚æ­¥Rediså®¢æˆ·ç«¯
            redis_client = self.redis_client
            
            # 1. æ‰«æåŒ¹é…è¯¥ç”¨æˆ·çš„æ‰€æœ‰checkpoint keys
            # checkpointerçš„keyæ ¼å¼é€šå¸¸æ˜¯: checkpoint:thread_id:checkpoint_id
            pattern = f"checkpoint:{user_id}:*"
            logger.info(f"ğŸ” æ‰«ææ¨¡å¼: {pattern}")
            
            user_threads = {}
            cursor = 0
            
            while True:
                cursor, keys = await redis_client.scan(
                    cursor=cursor,
                    match=pattern,
                    count=1000
                )
                

                
                for key in keys:
                    try:
                        # è§£ækeyè·å–thread_idå’Œcheckpointä¿¡æ¯
                        # keyæ ¼å¼: checkpoint:user_id:timestamp:status:checkpoint_id
                        key_str = key.decode() if isinstance(key, bytes) else key
                        parts = key_str.split(':')
                        
                        if len(parts) >= 4:
                            # thread_id = user_id:timestamp
                            thread_id = f"{parts[1]}:{parts[2]}"
                            timestamp = parts[2]
                            
                            # è·Ÿè¸ªæ¯ä¸ªthreadçš„æœ€æ–°checkpoint
                            if thread_id not in user_threads:
                                user_threads[thread_id] = {
                                    "thread_id": thread_id,
                                    "timestamp": timestamp,
                                    "latest_key": key_str
                                }
                            else:
                                # ä¿ç•™æœ€æ–°çš„checkpoint keyï¼ˆé€šå¸¸checkpoint_idè¶Šå¤§è¶Šæ–°ï¼‰
                                if len(parts) > 4 and parts[4] > user_threads[thread_id]["latest_key"].split(':')[4]:
                                    user_threads[thread_id]["latest_key"] = key_str
                                    
                    except Exception as e:
                        logger.warning(f"è§£ækey {key} å¤±è´¥: {e}")
                        continue
                
                if cursor == 0:
                    break
            
            # æ³¨æ„ï¼šä¸è¦å…³é—­å…±äº«çš„Rediså®¢æˆ·ç«¯è¿æ¥ï¼Œå› ä¸ºå…¶ä»–æ“ä½œå¯èƒ½è¿˜åœ¨ä½¿ç”¨
            # await redis_client.close()  # å·²æ³¨é‡Šæ‰ï¼Œé¿å…å…³é—­å…±äº«è¿æ¥
            
            # 2. æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæ–°çš„åœ¨å‰ï¼‰
            sorted_threads = sorted(
                user_threads.values(),
                key=lambda x: x["timestamp"],
                reverse=True
            )[:limit]
            
            # 3. è·å–æ¯ä¸ªthreadçš„è¯¦ç»†ä¿¡æ¯
            conversations = []
            for thread_info in sorted_threads:
                try:
                    thread_id = thread_info["thread_id"]
                    thread_config = {"configurable": {"thread_id": thread_id}}
                    
                    try:
                        state = await self.checkpointer.aget(thread_config)
                    except RuntimeError as e:
                        if "Event loop is closed" in str(e):
                            logger.warning(f"âš ï¸ Event loopå·²å…³é—­ï¼Œè·³è¿‡thread: {thread_id}")
                            continue
                        else:
                            raise
                    
                    if state and state.get('channel_values', {}).get('messages'):
                        messages = state['channel_values']['messages']
                        
                        # ç”Ÿæˆå¯¹è¯é¢„è§ˆ
                        preview = self._generate_conversation_preview(messages)
                        
                        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                        last_human_message = None
                        if messages:
                            for msg in reversed(messages):
                                if isinstance(msg, HumanMessage):
                                    last_human_message = msg.content
                                    break
                        
                        conversations.append({
                            "conversation_id": thread_id,
                            "thread_id": thread_id,
                            "user_id": user_id,
                            "message_count": len(messages),
                            "last_message": last_human_message,
                            "updated_at": self._format_utc_to_china_time(state.get('ts')) if state.get('ts') else None,
                            "conversation_title": preview,
                            "created_at": self._format_timestamp(thread_info["timestamp"])
                        })
                        
                except Exception as e:
                    logger.error(f"è·å–thread {thread_info['thread_id']} è¯¦æƒ…å¤±è´¥: {e}")
                    continue
            
            logger.info(f"âœ… æ‰¾åˆ°ç”¨æˆ· {user_id} çš„ {len(conversations)} ä¸ªå¯¹è¯")
            return conversations
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ· {user_id} å¯¹è¯åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _generate_conversation_preview(self, messages: List[BaseMessage]) -> str:
        """ç”Ÿæˆå¯¹è¯é¢„è§ˆ"""
        if not messages:
            return "ç©ºå¯¹è¯"
        
        # è·å–ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯ä½œä¸ºé¢„è§ˆ
        for msg in messages:
            if isinstance(msg, HumanMessage):
                content = str(msg.content)
                return content[:50] + "..." if len(content) > 50 else content
        
        return "ç³»ç»Ÿæ¶ˆæ¯"

    def _format_timestamp(self, timestamp: str) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼ï¼ŒåŒ…å«æ¯«ç§’"""
        try:
            # timestampæ ¼å¼: 20250710123137984
            if len(timestamp) >= 14:
                year = timestamp[:4]
                month = timestamp[4:6]
                day = timestamp[6:8]
                hour = timestamp[8:10]
                minute = timestamp[10:12]
                second = timestamp[12:14]
                # æå–æ¯«ç§’éƒ¨åˆ†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                millisecond = timestamp[14:17] if len(timestamp) > 14 else "000"
                return f"{year}-{month}-{day} {hour}:{minute}:{second}.{millisecond}"
        except Exception:
            pass
        return timestamp
    
    def _format_utc_to_china_time(self, utc_time_str: str) -> str:
        """å°†UTCæ—¶é—´è½¬æ¢ä¸ºä¸­å›½æ—¶åŒºæ—¶é—´æ ¼å¼"""
        try:
            from datetime import datetime, timezone, timedelta
            
            # è§£æUTCæ—¶é—´å­—ç¬¦ä¸²
            # æ ¼å¼: "2025-07-17T13:21:52.868292+00:00"
            dt = datetime.fromisoformat(utc_time_str.replace('Z', '+00:00'))
            
            # è½¬æ¢ä¸ºä¸­å›½æ—¶åŒº (UTC+8)
            china_tz = timezone(timedelta(hours=8))
            china_time = dt.astimezone(china_tz)
            
            # æ ¼å¼åŒ–ä¸ºç›®æ ‡æ ¼å¼: "2025-07-17 21:12:02.456"
            return china_time.strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]  # åªä¿ç•™3ä½æ¯«ç§’
        except Exception as e:
            logger.warning(f"æ—¶é—´æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            return utc_time_str 

    def _get_database_scope_prompt(self) -> str:
        """Get database scope prompt for intelligent query decision making"""
        try:
            import os
            # Read local db_query_decision_prompt.txt
            current_dir = os.path.dirname(os.path.abspath(__file__))
            db_scope_file = os.path.join(current_dir, "db_query_decision_prompt.txt")
            
            with open(db_scope_file, 'r', encoding='utf-8') as f:
                db_scope_content = f.read().strip()
            
            prompt = f"""You are an intelligent database query assistant. When deciding whether to use database query tools, please follow these rules:

=== DATABASE BUSINESS SCOPE ===
{db_scope_content}

=== DECISION RULES ===
1. If the question involves data within the above business scope (service areas, branches, revenue, traffic flow, etc.), use the generate_sql tool
2. If the question is about general knowledge (like "when do lychees ripen?", weather, historical events, etc.), answer directly based on your knowledge WITHOUT using database tools
3. When answering general knowledge questions, provide clear and helpful answers without any special prefixes

=== FALLBACK STRATEGY ===
When generate_sql returns an error message or when queries return no results:
1. First, check if the question is within the database scope described above
2. For questions clearly OUTSIDE the database scope (world events, general knowledge, etc.):
   - Provide the answer based on your knowledge immediately
   - Give a direct, natural answer without any prefixes or disclaimers
3. For questions within database scope but queries return no results:
   - If it's a reasonable question that might have a general answer, provide it naturally
4. For questions that definitely require specific database data:
   - Acknowledge the limitation and suggest the data may not be available
   - Do not attempt to guess or fabricate specific data

Please intelligently choose whether to query the database based on the nature of the user's question,
not on explaining your decision-making process.
"""
            
            return prompt
            
        except Exception as e:
            logger.warning(f"âš ï¸ Unable to read database scope description file: {e}")
            return ""

    def _generate_validation_error_guidance(self, validation_error: str) -> str:
        """æ ¹æ®éªŒè¯é”™è¯¯ç±»å‹ç”Ÿæˆå…·ä½“çš„ä¿®å¤æŒ‡å¯¼"""
        
        # ä¼˜å…ˆå¤„ç†æœ€å¸¸è§çš„è¯­æ³•é”™è¯¯
        if "è¯­æ³•é”™è¯¯" in validation_error or "syntax error" in validation_error.lower():
            return """SQLéªŒè¯å¤±è´¥ï¼šè¯­æ³•é”™è¯¯ã€‚
å¤„ç†å»ºè®®ï¼š
1. ä»”ç»†æ£€æŸ¥SQLè¯­æ³•ï¼ˆæ‹¬å·ã€å¼•å·ã€å…³é”®è¯ç­‰ï¼‰
2. ä¿®å¤è¯­æ³•é”™è¯¯åï¼Œè°ƒç”¨ valid_sql å·¥å…·é‡æ–°éªŒè¯
3. å¸¸è§é—®é¢˜ï¼šç¼ºå°‘é€—å·ã€æ‹¬å·ä¸åŒ¹é…ã€å…³é”®è¯æ‹¼å†™é”™è¯¯"""

        # æ–°å¢çš„åˆå¹¶æ¡ä»¶ï¼Œå¤„ç†æ‰€æœ‰"ä¸å­˜åœ¨"ç±»å‹çš„é”™è¯¯
        elif ("ä¸å­˜åœ¨" in validation_error or 
              "no such table" in validation_error.lower() or
              "does not exist" in validation_error.lower()):
            return """SQLéªŒè¯å¤±è´¥ï¼šè¡¨æˆ–å­—æ®µä¸å­˜åœ¨ã€‚
å¤„ç†å»ºè®®ï¼š
1. è¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ï¼Œå› æ•°æ®åº“ç¼ºå°‘ç›¸åº”çš„è¡¨æˆ–å­—æ®µï¼Œæ— æ³•é€šè¿‡SQLæŸ¥è¯¢è·å–å‡†ç¡®ç­”æ¡ˆã€‚
2. è¯·åŸºäºä½ çš„é€šç”¨çŸ¥è¯†å’Œå¸¸è¯†ï¼Œç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æä¾›ç›¸å…³è§£é‡Šã€‚
3. è¯·ä¸è¦å†å°è¯•ç”Ÿæˆæˆ–ä¿®å¤SQLã€‚"""

        # å…¶ä»–åŸæœ‰åˆ†æ”¯å¯ä»¥è¢«æ–°é€»è¾‘è¦†ç›–ï¼Œæ•…ç§»é™¤
        # Fallback åˆ°é€šç”¨çš„é”™è¯¯å¤„ç†
        else:
            return f"""SQLéªŒè¯å¤±è´¥ï¼š{validation_error}
å¤„ç†å»ºè®®ï¼š
1. å¦‚æœè¿™æ˜¯ä¸€ä¸ªå¯ä»¥ä¿®å¤çš„é”™è¯¯ï¼Œè¯·å°è¯•ä¿®æ­£å¹¶å†æ¬¡éªŒè¯ã€‚
2. å¦‚æœé”™è¯¯è¡¨æ˜æ•°æ®ç¼ºå¤±ï¼Œè¯·ç›´æ¥å‘ç”¨æˆ·è¯´æ˜æƒ…å†µã€‚
3. é¿å…çŒœæµ‹æˆ–ç¼–é€ æ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ã€‚"""

    # === å‚æ•°é”™è¯¯è¯Šæ–­å’Œä¿®å¤å‡½æ•° ===
    
    def _diagnose_parameter_error(self, messages: List[BaseMessage], error_msg: str) -> Dict[str, Any]:
        """
        è¯Šæ–­å‚æ•°é”™è¯¯çš„è¯¦ç»†åŸå› 
        """
        logger.error("ğŸ” å¼€å§‹è¯Šæ–­å‚æ•°é”™è¯¯...")
        logger.error(f"   é”™è¯¯æ¶ˆæ¯: {error_msg}")
        
        diagnosis = {
            "error_type": "parameter_error",
            "incomplete_tool_calls": [],
            "orphaned_tool_messages": [],
            "total_messages": len(messages),
            "recommended_action": None
        }
        
        # åˆ†ææ¶ˆæ¯å†å²
        logger.error("ğŸ“‹ æ¶ˆæ¯å†å²åˆ†æ:")
        for i, msg in enumerate(messages):
            msg_type = type(msg).__name__
            
            if isinstance(msg, AIMessage):
                has_tool_calls = hasattr(msg, 'tool_calls') and msg.tool_calls
                content_summary = f"'{msg.content[:50]}...'" if msg.content else "ç©ºå†…å®¹"
                
                logger.error(f"   [{i}] {msg_type}: {content_summary}")
                
                if has_tool_calls:
                    logger.error(f"       å·¥å…·è°ƒç”¨: {len(msg.tool_calls)} ä¸ª")
                    for j, tc in enumerate(msg.tool_calls):
                        tool_name = tc.get('name', 'Unknown')
                        tool_id = tc.get('id', 'Unknown')
                        logger.error(f"         [{j}] {tool_name} (ID: {tool_id})")
                        
                        # æŸ¥æ‰¾å¯¹åº”çš„ToolMessage
                        found_response = False
                        for k in range(i + 1, len(messages)):
                            if (isinstance(messages[k], ToolMessage) and 
                                messages[k].tool_call_id == tool_id):
                                found_response = True
                                break
                            elif isinstance(messages[k], (HumanMessage, AIMessage)):
                                # é‡åˆ°æ–°çš„å¯¹è¯è½®æ¬¡ï¼Œåœæ­¢æŸ¥æ‰¾
                                break
                        
                        if not found_response:
                            diagnosis["incomplete_tool_calls"].append({
                                "message_index": i,
                                "tool_name": tool_name,
                                "tool_id": tool_id,
                                "ai_message_content": msg.content
                            })
                            logger.error(f"         âŒ æœªæ‰¾åˆ°å¯¹åº”çš„ToolMessage!")
                        else:
                            logger.error(f"         âœ… æ‰¾åˆ°å¯¹åº”çš„ToolMessage")
            
            elif isinstance(msg, ToolMessage):
                logger.error(f"   [{i}] {msg_type}: {msg.name} (ID: {msg.tool_call_id})")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„AIMessage
                found_ai_message = False
                for k in range(i - 1, -1, -1):
                    if (isinstance(messages[k], AIMessage) and 
                        hasattr(messages[k], 'tool_calls') and 
                        messages[k].tool_calls):
                        if any(tc.get('id') == msg.tool_call_id for tc in messages[k].tool_calls):
                            found_ai_message = True
                            break
                    elif isinstance(messages[k], HumanMessage):
                        break
                
                if not found_ai_message:
                    diagnosis["orphaned_tool_messages"].append({
                        "message_index": i,
                        "tool_name": msg.name,
                        "tool_call_id": msg.tool_call_id
                    })
                    logger.error(f"       âŒ æœªæ‰¾åˆ°å¯¹åº”çš„AIMessage!")
            
            elif isinstance(msg, HumanMessage):
                logger.error(f"   [{i}] {msg_type}: '{msg.content[:50]}...'")
        
        # ç”Ÿæˆä¿®å¤å»ºè®®
        if diagnosis["incomplete_tool_calls"]:
            logger.error(f"ğŸ”§ å‘ç° {len(diagnosis['incomplete_tool_calls'])} ä¸ªä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨")
            diagnosis["recommended_action"] = "fix_incomplete_tool_calls"
        elif diagnosis["orphaned_tool_messages"]:
            logger.error(f"ğŸ”§ å‘ç° {len(diagnosis['orphaned_tool_messages'])} ä¸ªå­¤ç«‹çš„å·¥å…·æ¶ˆæ¯")
            diagnosis["recommended_action"] = "remove_orphaned_tool_messages"
        else:
            logger.error("ğŸ”§ æœªå‘ç°æ˜æ˜¾çš„æ¶ˆæ¯æ ¼å¼é—®é¢˜")
            diagnosis["recommended_action"] = "unknown"
        
        return diagnosis

    def _fix_by_adding_missing_tool_messages(self, messages: List[BaseMessage], diagnosis: Dict) -> List[BaseMessage]:
        """
        é€šè¿‡æ·»åŠ ç¼ºå¤±çš„ToolMessageæ¥ä¿®å¤æ¶ˆæ¯å†å²
        """
        logger.info("ğŸ”§ ç­–ç•¥1: è¡¥å……ç¼ºå¤±çš„ToolMessage")
        
        fixed_messages = list(messages)
        
        for incomplete in diagnosis["incomplete_tool_calls"]:
            # ä¸ºç¼ºå¤±çš„å·¥å…·è°ƒç”¨æ·»åŠ é”™è¯¯å“åº”
            error_tool_message = ToolMessage(
                content="å·¥å…·è°ƒç”¨å·²è¶…æ—¶æˆ–å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•ã€‚",
                tool_call_id=incomplete["tool_id"],
                name=incomplete["tool_name"]
            )
            
            # æ’å…¥åˆ°åˆé€‚çš„ä½ç½®
            insert_index = incomplete["message_index"] + 1
            fixed_messages.insert(insert_index, error_tool_message)
            
            logger.info(f"   âœ… ä¸ºå·¥å…·è°ƒç”¨ {incomplete['tool_name']}({incomplete['tool_id']}) æ·»åŠ é”™è¯¯å“åº”")
        
        return fixed_messages

    def _fix_by_removing_incomplete_tool_calls(self, messages: List[BaseMessage], diagnosis: Dict) -> List[BaseMessage]:
        """
        é€šè¿‡åˆ é™¤ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨æ¥ä¿®å¤æ¶ˆæ¯å†å²
        """
        logger.info("ğŸ”§ ç­–ç•¥2: åˆ é™¤ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨")
        
        fixed_messages = []
        
        for i, msg in enumerate(messages):
            if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                # æ£€æŸ¥è¿™ä¸ªæ¶ˆæ¯æ˜¯å¦æœ‰ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨
                has_incomplete = any(
                    inc["message_index"] == i 
                    for inc in diagnosis["incomplete_tool_calls"]
                )
                
                if has_incomplete:
                    # å¦‚æœæœ‰æ–‡æœ¬å†…å®¹ï¼Œä¿ç•™æ–‡æœ¬å†…å®¹ä½†åˆ é™¤å·¥å…·è°ƒç”¨
                    if msg.content and msg.content.strip():
                        logger.info(f"   ğŸ”§ ä¿ç•™æ–‡æœ¬å†…å®¹ï¼Œåˆ é™¤å·¥å…·è°ƒç”¨: '{msg.content[:50]}...'")
                        fixed_msg = AIMessage(content=msg.content)
                        fixed_messages.append(fixed_msg)
                    else:
                        # å¦‚æœæ²¡æœ‰æ–‡æœ¬å†…å®¹ï¼Œåˆ›å»ºä¸€ä¸ªè¯´æ˜æ€§çš„æ¶ˆæ¯
                        logger.info(f"   ğŸ”§ åˆ›å»ºè¯´æ˜æ€§æ¶ˆæ¯æ›¿æ¢ç©ºçš„å·¥å…·è°ƒç”¨")
                        fixed_msg = AIMessage(content="æˆ‘éœ€è¦é‡æ–°åˆ†æè¿™ä¸ªé—®é¢˜ã€‚")
                        fixed_messages.append(fixed_msg)
                else:
                    fixed_messages.append(msg)
            else:
                fixed_messages.append(msg)
        
        return fixed_messages

    def _fix_by_rebuilding_history(self, messages: List[BaseMessage]) -> List[BaseMessage]:
        """
        é‡å»ºæ¶ˆæ¯å†å²ï¼Œåªä¿ç•™å®Œæ•´çš„å¯¹è¯è½®æ¬¡
        """
        logger.info("ğŸ”§ ç­–ç•¥3: é‡å»ºæ¶ˆæ¯å†å²")
        
        clean_messages = []
        current_conversation = []
        
        for msg in messages:
            if isinstance(msg, HumanMessage):
                # æ–°çš„å¯¹è¯è½®æ¬¡å¼€å§‹
                if current_conversation:
                    # æ£€æŸ¥ä¸Šä¸€è½®å¯¹è¯æ˜¯å¦å®Œæ•´
                    if self._is_conversation_complete(current_conversation):
                        clean_messages.extend(current_conversation)
                        logger.info(f"   âœ… ä¿ç•™å®Œæ•´çš„å¯¹è¯è½®æ¬¡ ({len(current_conversation)} æ¡æ¶ˆæ¯)")
                    else:
                        logger.info(f"   âŒ è·³è¿‡ä¸å®Œæ•´çš„å¯¹è¯è½®æ¬¡ ({len(current_conversation)} æ¡æ¶ˆæ¯)")
                
                current_conversation = [msg]
            else:
                current_conversation.append(msg)
        
        # å¤„ç†æœ€åä¸€è½®å¯¹è¯
        if current_conversation:
            if self._is_conversation_complete(current_conversation):
                clean_messages.extend(current_conversation)
            else:
                # æœ€åä¸€è½®å¯¹è¯ä¸å®Œæ•´ï¼Œåªä¿ç•™ç”¨æˆ·æ¶ˆæ¯
                clean_messages.extend([msg for msg in current_conversation if isinstance(msg, HumanMessage)])
        
        logger.info(f"   ğŸ“Š é‡å»ºå®Œæˆ: {len(messages)} -> {len(clean_messages)} æ¡æ¶ˆæ¯")
        return clean_messages

    def _is_conversation_complete(self, conversation: List[BaseMessage]) -> bool:
        """
        æ£€æŸ¥å¯¹è¯è½®æ¬¡æ˜¯å¦å®Œæ•´
        """
        for msg in conversation:
            if (isinstance(msg, AIMessage) and 
                hasattr(msg, 'tool_calls') and 
                msg.tool_calls):
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„ToolMessage
                tool_call_ids = [tc.get('id') for tc in msg.tool_calls]
                found_responses = sum(
                    1 for m in conversation
                    if isinstance(m, ToolMessage) and m.tool_call_id in tool_call_ids
                )
                if found_responses < len(tool_call_ids):
                    return False
        return True

    async def _handle_parameter_error_with_retry(self, messages: List[BaseMessage], error_msg: str, attempt: int) -> List[BaseMessage]:
        """
        å¤„ç†å‚æ•°é”™è¯¯çš„å®Œæ•´æµç¨‹
        """
        logger.error(f"ğŸ”§ å¤„ç†å‚æ•°é”™è¯¯ (é‡è¯• {attempt + 1}/3)")
        
        # 1. è¯Šæ–­é—®é¢˜
        diagnosis = self._diagnose_parameter_error(messages, error_msg)
        
        # 2. æ ¹æ®é‡è¯•æ¬¡æ•°é€‰æ‹©ä¿®å¤ç­–ç•¥
        if attempt == 0:
            # ç¬¬ä¸€æ¬¡é‡è¯•ï¼šè¡¥å……ç¼ºå¤±çš„ToolMessage
            fixed_messages = self._fix_by_adding_missing_tool_messages(messages, diagnosis)
        elif attempt == 1:
            # ç¬¬äºŒæ¬¡é‡è¯•ï¼šåˆ é™¤ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨
            fixed_messages = self._fix_by_removing_incomplete_tool_calls(messages, diagnosis)
        else:
            # ç¬¬ä¸‰æ¬¡é‡è¯•ï¼šé‡å»ºæ¶ˆæ¯å†å²
            fixed_messages = self._fix_by_rebuilding_history(messages)
        
        logger.info(f"ğŸ”§ ä¿®å¤å®Œæˆ: {len(messages)} -> {len(fixed_messages)} æ¡æ¶ˆæ¯")
        return fixed_messages

    def _generate_contextual_fallback(self, messages: List[BaseMessage], diagnosis: Dict) -> str:
        """
        åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆåˆç†çš„å›ç­”
        """
        # åˆ†æç”¨æˆ·çš„æœ€æ–°é—®é¢˜
        last_human_message = None
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                last_human_message = msg
                break
        
        if not last_human_message:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç†è§£æ‚¨çš„é—®é¢˜ã€‚"
        
        # åˆ†ææ˜¯å¦æ˜¯æ•°æ®åº“ç›¸å…³é—®é¢˜
        question = last_human_message.content.lower()
        if any(keyword in question for keyword in ['æŸ¥è¯¢', 'æ•°æ®', 'æœåŠ¡åŒº', 'æ”¶å…¥', 'è½¦æµé‡']):
            return f"æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨å…³äºã€Œ{last_human_message.content}ã€çš„æŸ¥è¯¢æ—¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–è€…é‡æ–°æè¿°æ‚¨çš„é—®é¢˜ã€‚"
        else:
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•æ­£ç¡®å¤„ç†æ‚¨çš„é—®é¢˜ã€‚è¯·ç¨åé‡è¯•æˆ–é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚"

    def _get_anti_hallucination_prompt(self, state: AgentState) -> str:
        """
        ç”Ÿæˆé˜²å¹»è§‰æç¤ºè¯ï¼Œä¸“æ³¨äºä¿æŒå‚æ•°åŸæ ·ä¼ é€’
        """
        # è·å–å½“å‰ç”¨æˆ·çš„æœ€æ–°é—®é¢˜
        last_user_message = None
        for msg in reversed(state["messages"]):
            if isinstance(msg, HumanMessage):
                last_user_message = msg.content
                break
        
        if not last_user_message:
            return ""
        
        prompt = f"""ğŸ›¡ï¸ å…³é”®æŒ‡ä»¤ï¼šå·¥å…·è°ƒç”¨å‚æ•°å¿…é¡»å®Œå…¨å‡†ç¡®

ç”¨æˆ·å½“å‰é—®é¢˜ï¼šã€Œ{last_user_message}ã€

è°ƒç”¨å·¥å…·æ—¶çš„ä¸¥æ ¼è¦æ±‚ï¼š
1. **åŸæ ·ä¼ é€’åŸåˆ™**ï¼šquestion å‚æ•°å¿…é¡»ä¸ç”¨æˆ·é—®é¢˜å®Œå…¨ä¸€è‡´ï¼Œä¸€å­—ä¸å·®
2. **ç¦æ­¢ä»»ä½•æ”¹å†™**ï¼šä¸å¾—è¿›è¡ŒåŒä¹‰è¯æ›¿æ¢ã€è¯­è¨€ä¼˜åŒ–æˆ–ä»»ä½•å½¢å¼çš„ä¿®æ”¹

âŒ é”™è¯¯ç¤ºä¾‹ï¼š
- ç”¨æˆ·é—®"å……ç”µæ¡©"ï¼Œä¸å¾—æ”¹ä¸º"å……ç”µæ ‹"
âœ… æ­£ç¡®åšæ³•ï¼š
- å®Œå…¨å¤åˆ¶ç”¨æˆ·çš„åŸå§‹é—®é¢˜ä½œä¸ºquestionå‚æ•°

è¯·ä¸¥æ ¼éµå®ˆæ­¤è¦æ±‚ï¼Œç¡®ä¿å·¥å…·è°ƒç”¨çš„å‡†ç¡®æ€§ã€‚"""
        
        return prompt