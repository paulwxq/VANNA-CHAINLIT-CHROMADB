# Data Pipeline API Vectorè¡¨ç®¡ç†åŠŸèƒ½é›†æˆæ–¹æ¡ˆ

## æ¦‚è¿°

ä¸º Data Pipeline API é›†æˆ Vector è¡¨ç®¡ç†åŠŸèƒ½ï¼Œæ”¯æŒåœ¨æ‰§è¡Œè®­ç»ƒæ•°æ®åŠ è½½æ—¶è¿›è¡Œ Vector è¡¨çš„å¤‡ä»½å’Œæ¸…ç©ºæ“ä½œã€‚æœ¬æ–¹æ¡ˆåŸºäºå·²å®ç°çš„å‘½ä»¤è¡ŒåŠŸèƒ½ï¼ˆè¯¦è§ `vector_table_management_design.md`ï¼‰ï¼Œæœ€å¤§ç¨‹åº¦å¤ç”¨ç°æœ‰ä»£ç ï¼Œç¡®ä¿ API ä¸å‘½ä»¤è¡ŒåŠŸèƒ½ä¿æŒä¸€è‡´ã€‚

## éœ€æ±‚å›é¡¾

### 1. API å‚æ•°æ”¯æŒ
- **å®Œæ•´æ‰§è¡Œæ¨¡å¼**ï¼š`POST /api/v0/data_pipeline/tasks/{task_id}/execute`
  ```json
  {
      "execution_mode": "complete",
      "backup_vector_tables": false,
      "truncate_vector_tables": false
  }
  ```

- **å•æ­¥æ‰§è¡Œæ¨¡å¼**ï¼šä»…åœ¨ `step_name` ä¸º `"training_load"` æ—¶æ”¯æŒ
  ```json
  {
      "execution_mode": "step", 
      "step_name": "training_load",
      "backup_vector_tables": false,
      "truncate_vector_tables": false
  }
  ```

### 2. å‚æ•°é€»è¾‘
- `backup_vector_tables`ï¼šå¯å•ç‹¬ä½¿ç”¨
- `truncate_vector_tables`ï¼šè‡ªåŠ¨å¯ç”¨ `backup_vector_tables`
- é `training_load` æ­¥éª¤ä¼ é€’è¿™äº›å‚æ•°æ—¶ï¼šå¿½ç•¥å¹¶è®°å½• WARNING æ—¥å¿—
- é»˜è®¤å€¼ï¼šå‡ä¸º `false`

### 3. å¤ç”¨åŸåˆ™
- æœ€å¤§ç¨‹åº¦å¤ç”¨å‘½ä»¤è¡Œå®ç°çš„ `VectorTableManager` ç±»
- ä¿æŒä¸å‘½ä»¤è¡ŒåŠŸèƒ½çš„ä¸€è‡´æ€§
- ä¸å½±å“ç°æœ‰å‘½ä»¤è¡Œæ‰§è¡Œé€»è¾‘

## ä¿®æ”¹æ–¹æ¡ˆ

### 1. API è¯·æ±‚å‚æ•°æ‰©å±•

#### 1.1 unified_api.py ä¿®æ”¹

**ä½ç½®**ï¼š`@app.route('/api/v0/data_pipeline/tasks/<task_id>/execute', methods=['POST'])`

```python
@app.route('/api/v0/data_pipeline/tasks/<task_id>/execute', methods=['POST'])
def execute_data_pipeline_task(task_id):
    """æ‰§è¡Œæ•°æ®ç®¡é“ä»»åŠ¡"""
    try:
        req = request.get_json(force=True) if request.is_json else {}
        execution_mode = req.get('execution_mode', 'complete')
        step_name = req.get('step_name')
        
        # æ–°å¢ï¼šVectorè¡¨ç®¡ç†å‚æ•°
        backup_vector_tables = req.get('backup_vector_tables', False)
        truncate_vector_tables = req.get('truncate_vector_tables', False)
        
        # ç°æœ‰éªŒè¯é€»è¾‘...
        
        # æ–°å¢ï¼šVectorè¡¨ç®¡ç†å‚æ•°éªŒè¯å’Œè­¦å‘Š
        if execution_mode == 'step' and step_name != 'training_load':
            if backup_vector_tables or truncate_vector_tables:
                logger.warning(
                    f"âš ï¸ Vectorè¡¨ç®¡ç†å‚æ•°ä»…åœ¨training_loadæ­¥éª¤æœ‰æ•ˆï¼Œå½“å‰æ­¥éª¤: {step_name}ï¼Œå¿½ç•¥å‚æ•°"
                )
                backup_vector_tables = False
                truncate_vector_tables = False
        
        # æ„å»ºæ‰§è¡Œå‘½ä»¤æ—¶æ·»åŠ æ–°å‚æ•°
        cmd = [
            python_executable,
            str(script_path),
            "--task-id", task_id,
            "--execution-mode", execution_mode
        ]
        
        if step_name:
            cmd.extend(["--step-name", step_name])
            
        # æ–°å¢ï¼šVectorè¡¨ç®¡ç†å‚æ•°ä¼ é€’
        if backup_vector_tables:
            cmd.append("--backup-vector-tables")
        if truncate_vector_tables:
            cmd.append("--truncate-vector-tables")
        
        # å…¶ä½™é€»è¾‘ä¿æŒä¸å˜...
```

#### 1.2 task_executor.py ä¿®æ”¹

**æ–°å¢å‘½ä»¤è¡Œå‚æ•°è§£æ**ï¼š

```python
def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    parser = argparse.ArgumentParser(description='Data Pipeline ä»»åŠ¡æ‰§è¡Œå™¨')
    parser.add_argument('--task-id', required=True, help='ä»»åŠ¡ID')
    parser.add_argument('--execution-mode', default='complete', choices=['complete', 'step'], help='æ‰§è¡Œæ¨¡å¼')
    parser.add_argument('--step-name', help='æ­¥éª¤åç§°ï¼ˆå½“execution-mode=stepæ—¶å¿…éœ€ï¼‰')
    
    # æ–°å¢ï¼šVectorè¡¨ç®¡ç†å‚æ•°
    parser.add_argument('--backup-vector-tables', action='store_true', help='å¤‡ä»½vectorè¡¨æ•°æ®')
    parser.add_argument('--truncate-vector-tables', action='store_true', help='æ¸…ç©ºvectorè¡¨æ•°æ®ï¼ˆè‡ªåŠ¨å¯ç”¨å¤‡ä»½ï¼‰')
    
    args = parser.parse_args()
    
    # ç°æœ‰éªŒè¯é€»è¾‘...
    
    try:
        # ä¼ é€’æ–°å‚æ•°åˆ°execute_task
        result = asyncio.run(execute_task(
            args.task_id, 
            args.execution_mode, 
            args.step_name,
            args.backup_vector_tables,
            args.truncate_vector_tables
        ))
```

**ä¿®æ”¹execute_taskå‡½æ•°ç­¾å**ï¼š

```python
async def execute_task(task_id: str, execution_mode: str, step_name: str = None, 
                      backup_vector_tables: bool = False, truncate_vector_tables: bool = False):
    """æ‰§è¡Œä»»åŠ¡çš„å¼‚æ­¥å‡½æ•°"""
    executor = None
    try:
        executor = SimpleWorkflowExecutor(task_id, backup_vector_tables, truncate_vector_tables)
        
        if execution_mode == "complete":
            return await executor.execute_complete_workflow()
        elif execution_mode == "step":
            return await executor.execute_single_step(step_name)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ‰§è¡Œæ¨¡å¼: {execution_mode}")
            
    finally:
        if executor:
            executor.cleanup()
```

### 2. SimpleWorkflowExecutor æ‰©å±•

#### 2.1 æ„é€ å‡½æ•°ä¿®æ”¹

**ä½ç½®**ï¼š`data_pipeline/api/simple_workflow.py`

```python
class SimpleWorkflowExecutor:
    """ç®€åŒ–çš„ä»»åŠ¡å·¥ä½œæµæ‰§è¡Œå™¨"""
    
    def __init__(self, task_id: str, backup_vector_tables: bool = False, truncate_vector_tables: bool = False):
        """
        åˆå§‹åŒ–å·¥ä½œæµæ‰§è¡Œå™¨
        
        Args:
            task_id: ä»»åŠ¡ID
            backup_vector_tables: æ˜¯å¦å¤‡ä»½vectorè¡¨æ•°æ®
            truncate_vector_tables: æ˜¯å¦æ¸…ç©ºvectorè¡¨æ•°æ®ï¼ˆè‡ªåŠ¨å¯ç”¨å¤‡ä»½ï¼‰
        """
        self.task_id = task_id
        self.backup_vector_tables = backup_vector_tables
        self.truncate_vector_tables = truncate_vector_tables
        
        # å‚æ•°é€»è¾‘ï¼štruncateè‡ªåŠ¨å¯ç”¨backup
        if self.truncate_vector_tables:
            self.backup_vector_tables = True
        
        self.logger = get_logger("SimpleWorkflowExecutor", task_id)
        
        # è®°å½•Vectorè¡¨ç®¡ç†å‚æ•°çŠ¶æ€
        if self.backup_vector_tables or self.truncate_vector_tables:
            self.logger.info(f"ğŸ—‚ï¸ Vectorè¡¨ç®¡ç†å·²å¯ç”¨: backup={self.backup_vector_tables}, truncate={self.truncate_vector_tables}")
        
        # ç°æœ‰åˆå§‹åŒ–é€»è¾‘...
```

#### 2.2 _create_orchestrator æ–¹æ³•ä¿®æ”¹

```python
def _create_orchestrator(self):
    """åˆ›å»ºå·¥ä½œæµç¼–æ’å™¨"""
    # ç°æœ‰å‚æ•°è·å–é€»è¾‘...
    
    # åˆ›å»ºSchemaWorkflowOrchestratoræ—¶ä¼ é€’Vectorè¡¨ç®¡ç†å‚æ•°
    orchestrator = SchemaWorkflowOrchestrator(
        db_connection=db_connection,
        table_list_file=table_list_file,
        business_context=business_context,
        output_dir=self.task_output_dir,
        task_id=self.task_id,
        enable_question_sql_generation=enable_qa_generation,
        enable_sql_validation=enable_sql_validation,
        enable_training_data_load=enable_training_load,
        # æ–°å¢ï¼šVectorè¡¨ç®¡ç†å‚æ•°
        backup_vector_tables=self.backup_vector_tables,
        truncate_vector_tables=self.truncate_vector_tables
    )
    
    return orchestrator
```

#### 2.3 execute_single_step æ–¹æ³•ä¿®æ”¹

```python
async def execute_single_step(self, step_name: str) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
    try:
        # æ–°å¢ï¼šétraining_loadæ­¥éª¤çš„Vectorè¡¨ç®¡ç†å‚æ•°è­¦å‘Š
        if step_name != 'training_load' and (self.backup_vector_tables or self.truncate_vector_tables):
            self.logger.warning(
                f"âš ï¸ Vectorè¡¨ç®¡ç†å‚æ•°ä»…åœ¨training_loadæ­¥éª¤æœ‰æ•ˆï¼Œå½“å‰æ­¥éª¤: {step_name}ï¼Œå¿½ç•¥å‚æ•°"
            )
            # ä¸´æ—¶ç¦ç”¨Vectorè¡¨ç®¡ç†å‚æ•°
            temp_backup = self.backup_vector_tables
            temp_truncate = self.truncate_vector_tables
            self.backup_vector_tables = False
            self.truncate_vector_tables = False
        
        # ç°æœ‰æ­¥éª¤æ‰§è¡Œé€»è¾‘...
        
        # åˆ›å»ºå·¥ä½œæµç¼–æ’å™¨ï¼ˆä¼šæ ¹æ®å½“å‰å‚æ•°çŠ¶æ€åˆ›å»ºï¼‰
        orchestrator = self._create_orchestrator()
        
        # æ‰§è¡ŒæŒ‡å®šæ­¥éª¤...
        
        # æ¢å¤åŸå§‹å‚æ•°çŠ¶æ€ï¼ˆå¦‚æœè¢«ä¸´æ—¶ä¿®æ”¹ï¼‰
        if step_name != 'training_load' and ('temp_backup' in locals()):
            self.backup_vector_tables = temp_backup
            self.truncate_vector_tables = temp_truncate
        
        # ç°æœ‰è¿”å›é€»è¾‘...
```

### 3. SchemaWorkflowOrchestrator å‚æ•°æ‰©å±•

#### 3.1 æ„é€ å‡½æ•°ä¿®æ”¹

**ä½ç½®**ï¼š`data_pipeline/schema_workflow.py`

```python
class SchemaWorkflowOrchestrator:
    def __init__(self, 
                 # ç°æœ‰å‚æ•°...
                 backup_vector_tables: bool = False,
                 truncate_vector_tables: bool = False):
        """
        åˆå§‹åŒ–å·¥ä½œæµç¼–æ’å™¨
        
        Args:
            # ç°æœ‰å‚æ•°è¯´æ˜...
            backup_vector_tables: æ˜¯å¦å¤‡ä»½vectorè¡¨æ•°æ®
            truncate_vector_tables: æ˜¯å¦æ¸…ç©ºvectorè¡¨æ•°æ®ï¼ˆè‡ªåŠ¨å¯ç”¨å¤‡ä»½ï¼‰
        """
        # ç°æœ‰åˆå§‹åŒ–é€»è¾‘...
        
        # æ–°å¢ï¼šVectorè¡¨ç®¡ç†å‚æ•°
        self.backup_vector_tables = backup_vector_tables
        self.truncate_vector_tables = truncate_vector_tables
        
        # å‚æ•°é€»è¾‘ï¼štruncateè‡ªåŠ¨å¯ç”¨backup
        if self.truncate_vector_tables:
            self.backup_vector_tables = True
            self.logger.info("ğŸ”„ å¯ç”¨truncateæ—¶è‡ªåŠ¨å¯ç”¨backup")
```

#### 3.2 å¤ç”¨ç°æœ‰Vectorè¡¨ç®¡ç†æ–¹æ³•

```python
async def _execute_vector_table_management(self):
    """ç‹¬ç«‹æ‰§è¡ŒVectorè¡¨ç®¡ç†ï¼ˆå¤ç”¨å‘½ä»¤è¡Œå®ç°ï¼‰"""
    if not (self.backup_vector_tables or self.truncate_vector_tables):
        return
        
    self.logger.info("ğŸ—‚ï¸ å¼€å§‹æ‰§è¡ŒVectorè¡¨ç®¡ç†...")
    
    try:
        # ç›´æ¥å¤ç”¨å‘½ä»¤è¡Œå®ç°çš„VectorTableManager
        from data_pipeline.trainer.vector_table_manager import VectorTableManager
        
        vector_manager = VectorTableManager(
            task_output_dir=str(self.output_dir),
            task_id=self.task_id
        )
        
        # æ‰§è¡Œvectorè¡¨ç®¡ç†
        vector_stats = await vector_manager.execute_vector_management(
            backup=self.backup_vector_tables,
            truncate=self.truncate_vector_tables
        )
        
        # è®°å½•ç»“æœåˆ°å·¥ä½œæµçŠ¶æ€
        self.workflow_state["artifacts"]["vector_management"] = vector_stats
        
        self.logger.info("âœ… Vectorè¡¨ç®¡ç†å®Œæˆ")
        
        return vector_stats
        
    except Exception as e:
        self.logger.error(f"âŒ Vectorè¡¨ç®¡ç†å¤±è´¥: {e}")
        raise
```

### 4. API å“åº”æ ¼å¼æ‰©å±•

#### 4.1 å®Œæ•´å·¥ä½œæµå“åº”

```json
{
    "success": true,
    "task_id": "task_20250721_113010",
    "execution_mode": "complete",
    "result": {
        "workflow_state": {...},
        "artifacts": {
            "vector_management": {
                "backup_performed": true,
                "truncate_performed": true,
                "tables_backed_up": {
                    "langchain_pg_collection": {
                        "row_count": 1234,
                        "file_size": "45.6 KB",
                        "backup_file": "langchain_pg_collection_20250721_113010.csv",
                        "backup_path": "/path/to/task/vector_bak/langchain_pg_collection_20250721_113010.csv"
                    },
                    "langchain_pg_embedding": {
                        "row_count": 12345,
                        "file_size": "2.1 MB",
                        "backup_file": "langchain_pg_embedding_20250721_113010.csv",
                        "backup_path": "/path/to/task/vector_bak/langchain_pg_embedding_20250721_113010.csv"
                    }
                },
                "truncate_results": {
                    "langchain_pg_embedding": {
                        "success": true,
                        "rows_before": 12345,
                        "rows_after": 0
                    }
                },
                "duration": 12.5,
                "backup_directory": "/path/to/task/vector_bak"
            }
        }
    }
}
```

#### 4.2 å•æ­¥æ‰§è¡Œå“åº”

```json
{
    "success": true,
    "task_id": "task_20250721_113010",
    "execution_mode": "step",
    "step_name": "training_load",
    "result": {
        "training_data_load": {...},
        "vector_management": {
            // åŒå®Œæ•´å·¥ä½œæµçš„vector_managementç»“æ„
        }
    }
}
```

### 5. æ—¥å¿—å¢å¼º

#### 5.1 API å±‚æ—¥å¿—

```python
# unified_api.py ä¸­çš„æ—¥å¿—å¢å¼º
if backup_vector_tables or truncate_vector_tables:
    logger.info(f"ğŸ“‹ APIè¯·æ±‚åŒ…å«Vectorè¡¨ç®¡ç†å‚æ•°: backup={backup_vector_tables}, truncate={truncate_vector_tables}")

# étraining_loadæ­¥éª¤çš„è­¦å‘Šæ—¥å¿—
if execution_mode == 'step' and step_name != 'training_load':
    if backup_vector_tables or truncate_vector_tables:
        logger.warning(
            f"âš ï¸ Vectorè¡¨ç®¡ç†å‚æ•°ä»…åœ¨training_loadæ­¥éª¤æœ‰æ•ˆï¼Œå½“å‰æ­¥éª¤: {step_name}ï¼Œå¿½ç•¥å‚æ•°"
        )
```

#### 5.2 å·¥ä½œæµå±‚æ—¥å¿—

```python
# SimpleWorkflowExecutor ä¸­çš„æ—¥å¿—å¢å¼º
if self.backup_vector_tables or self.truncate_vector_tables:
    self.logger.info(f"ğŸ—‚ï¸ Vectorè¡¨ç®¡ç†å·²å¯ç”¨: backup={self.backup_vector_tables}, truncate={self.truncate_vector_tables}")

# è®°å½•å¤‡ä»½æ–‡ä»¶ä¿¡æ¯
if vector_stats and vector_stats.get("backup_performed"):
    self.logger.info("ğŸ“ Vectorè¡¨å¤‡ä»½æ–‡ä»¶:")
    for table_name, info in vector_stats.get("tables_backed_up", {}).items():
        if info.get("success", False):
            self.logger.info(f"   âœ… {table_name}: {info['backup_file']} ({info['file_size']})")
```

## å½±å“è¯„ä¼°

### 1. å¯¹å‘½ä»¤è¡Œæ‰§è¡Œçš„å½±å“

**âœ… æ— å½±å“**ï¼š
- æ‰€æœ‰ä¿®æ”¹éƒ½æ˜¯åœ¨ API å±‚é¢æ·»åŠ å‚æ•°ä¼ é€’
- å¤ç”¨ç°æœ‰çš„ `VectorTableManager` ç±»ï¼Œä¸ä¿®æ”¹å…¶å®ç°
- `SchemaWorkflowOrchestrator` çš„ä¿®æ”¹åªæ˜¯æ·»åŠ æ–°å‚æ•°ï¼Œä¿æŒå‘åå…¼å®¹
- å‘½ä»¤è¡Œè°ƒç”¨è·¯å¾„ä¸æ¶‰åŠ `SimpleWorkflowExecutor`

**éªŒè¯ç‚¹**ï¼š
- ç°æœ‰å‘½ä»¤è¡Œè„šæœ¬ç»§ç»­æ­£å¸¸å·¥ä½œ
- `VectorTableManager` çš„è¡Œä¸ºä¿æŒä¸€è‡´
- å‚æ•°ä¼ é€’é€»è¾‘ä¸å‘½ä»¤è¡Œå®ç°ç›¸åŒ

### 2. API å‘åå…¼å®¹æ€§

**âœ… å®Œå…¨å…¼å®¹**ï¼š
- æ–°å‚æ•°éƒ½æœ‰é»˜è®¤å€¼ `false`
- ä¸åŒ…å«æ–°å‚æ•°çš„è¯·æ±‚ç»§ç»­æ­£å¸¸å·¥ä½œ
- å“åº”æ ¼å¼å‘åå…¼å®¹ï¼ˆæ–°å¢å­—æ®µä¸å½±å“ç°æœ‰è§£æï¼‰

### 3. é”™è¯¯å¤„ç†å…¼å®¹æ€§

**âœ… ä¼˜é›…å¤„ç†**ï¼š
- é `training_load` æ­¥éª¤ä¼ é€’Vectorå‚æ•°ï¼šå¿½ç•¥ + WARNINGæ—¥å¿—
- Vectorè¡¨ç®¡ç†å¤±è´¥ï¼šè®°å½•é”™è¯¯ï¼Œä¸å½±å“å…¶ä»–æ­¥éª¤
- ä¿æŒç°æœ‰é”™è¯¯å¤„ç†æœºåˆ¶

## å®æ–½æ­¥éª¤

### é˜¶æ®µ1ï¼šå‚æ•°ä¼ é€’é“¾è·¯
1. ä¿®æ”¹ `unified_api.py` çš„executeè·¯ç”±
2. ä¿®æ”¹ `task_executor.py` å‚æ•°è§£æ
3. ä¿®æ”¹ `SimpleWorkflowExecutor` æ„é€ å‡½æ•°

### é˜¶æ®µ2ï¼šå·¥ä½œæµé›†æˆ
1. ä¿®æ”¹ `SchemaWorkflowOrchestrator` æ„é€ å‡½æ•°
2. åœ¨ `SimpleWorkflowExecutor` ä¸­é›†æˆVectorè¡¨ç®¡ç†è°ƒç”¨
3. ç¡®ä¿å¤ç”¨ç°æœ‰ `VectorTableManager`

### é˜¶æ®µ3ï¼šå“åº”å’Œæ—¥å¿—
1. æ‰©å±•APIå“åº”æ ¼å¼
2. å¢å¼ºæ—¥å¿—è®°å½•
3. æ·»åŠ å¤‡ä»½æ–‡ä»¶è·¯å¾„ä¿¡æ¯

### é˜¶æ®µ4ï¼šæµ‹è¯•éªŒè¯
1. APIåŠŸèƒ½æµ‹è¯•
2. å‘½ä»¤è¡Œå…¼å®¹æ€§æµ‹è¯•
3. è¾¹ç•Œæ¡ä»¶æµ‹è¯•

## æµ‹è¯•ç”¨ä¾‹

### 1. åŸºæœ¬åŠŸèƒ½æµ‹è¯•

```bash
# å®Œæ•´å·¥ä½œæµ + Vectorè¡¨ç®¡ç†
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "complete",
    "backup_vector_tables": true,
    "truncate_vector_tables": true
  }'

# å•æ­¥æ‰§è¡Œ + Vectorè¡¨ç®¡ç†
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "step",
    "step_name": "training_load",
    "backup_vector_tables": true
  }'
```

### 2. è¾¹ç•Œæ¡ä»¶æµ‹è¯•

```bash
# étraining_loadæ­¥éª¤ä¼ é€’Vectorå‚æ•°ï¼ˆåº”å¿½ç•¥å¹¶è­¦å‘Šï¼‰
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "step",
    "step_name": "ddl_generation",
    "backup_vector_tables": true
  }'

# ä¸åŒ…å«Vectorå‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "complete"
  }'
```

### 3. å‘½ä»¤è¡Œå…¼å®¹æ€§æµ‹è¯•

```bash
# éªŒè¯ç°æœ‰å‘½ä»¤è¡ŒåŠŸèƒ½ä¸å—å½±å“
python -m data_pipeline.schema_workflow --db-connection "..." --table-list "./tables.txt" --business-context "æµ‹è¯•" --backup-vector-tables

python -m data_pipeline.trainer.run_training --data_path "./training_data/" --truncate-vector-tables
```

## é£é™©æ§åˆ¶

### 1. ä»£ç å¤ç”¨é£é™©
- **é£é™©**ï¼šä¿®æ”¹ `VectorTableManager` å¯èƒ½å½±å“å‘½ä»¤è¡Œ
- **æ§åˆ¶**ï¼šå®Œå…¨å¤ç”¨ï¼Œä¸ä¿®æ”¹ç°æœ‰å®ç°

### 2. å‚æ•°ä¼ é€’é£é™©
- **é£é™©**ï¼šå‚æ•°ä¼ é€’é“¾è·¯å¤æ‚ï¼Œå®¹æ˜“é—æ¼
- **æ§åˆ¶**ï¼šåˆ†é˜¶æ®µæµ‹è¯•ï¼Œé€å±‚éªŒè¯

### 3. å“åº”æ ¼å¼é£é™©
- **é£é™©**ï¼šæ–°å“åº”å­—æ®µå¯èƒ½å½±å“ç°æœ‰å®¢æˆ·ç«¯
- **æ§åˆ¶**ï¼šé‡‡ç”¨å‘åå…¼å®¹çš„æ‰©å±•æ–¹å¼

## æ€»ç»“

æœ¬æ–¹æ¡ˆé€šè¿‡æœ€å°åŒ–ä¿®æ”¹å®ç°APIå¯¹Vectorè¡¨ç®¡ç†åŠŸèƒ½çš„æ”¯æŒï¼Œä¸»è¦ç‰¹ç‚¹ï¼š

1. **æœ€å¤§å¤ç”¨**ï¼šç›´æ¥å¤ç”¨å‘½ä»¤è¡Œå®ç°çš„ `VectorTableManager`
2. **å‚æ•°ä¸€è‡´**ï¼šAPIä¸å‘½ä»¤è¡Œä½¿ç”¨ç›¸åŒçš„å‚æ•°é€»è¾‘
3. **å‘åå…¼å®¹**ï¼šç°æœ‰APIè°ƒç”¨å®Œå…¨ä¸å—å½±å“
4. **ä¼˜é›…é™çº§**ï¼šéé€‚ç”¨åœºæ™¯ä¸‹å¿½ç•¥å‚æ•°å¹¶è®°å½•è­¦å‘Š
5. **å®Œæ•´å“åº”**ï¼šAPIè¿”å›è¯¦ç»†çš„å¤‡ä»½æ–‡ä»¶ä¿¡æ¯

è¯¥æ–¹æ¡ˆç¡®ä¿äº†åŠŸèƒ½çš„ä¸€è‡´æ€§å’Œä»£ç çš„å¯ç»´æŠ¤æ€§ï¼ŒåŒæ—¶æœ€å°åŒ–äº†å¯¹ç°æœ‰ç³»ç»Ÿçš„å½±å“ã€‚ 