# Data Pipeline ä½¿ç”¨è¯´æ˜

## ç›®å½•

1. [åŠŸèƒ½æ¦‚è¿°](#1-åŠŸèƒ½æ¦‚è¿°)
2. [å®‰è£…ä¸é…ç½®](#2-å®‰è£…ä¸é…ç½®)
3. [ä¸€é”®æ‰§è¡Œå®Œæ•´å·¥ä½œæµï¼ˆæ¨èï¼‰](#3-ä¸€é”®æ‰§è¡Œå®Œæ•´å·¥ä½œæµæ¨è)
4. [ç”ŸæˆDDLå’ŒMDæ–‡æ¡£](#4-ç”Ÿæˆddlå’Œmdæ–‡æ¡£)
5. [ç”ŸæˆQuestion-SQLè®­ç»ƒæ•°æ®](#5-ç”Ÿæˆquestion-sqlè®­ç»ƒæ•°æ®)
6. [SQLéªŒè¯å’Œä¿®å¤](#6-sqléªŒè¯å’Œä¿®å¤)
7. [è®­ç»ƒæ•°æ®ç®¡ç†](#7-è®­ç»ƒæ•°æ®ç®¡ç†)
8. [é…ç½®è¯¦è§£](#8-é…ç½®è¯¦è§£)
9. [å¸¸è§é—®é¢˜](#9-å¸¸è§é—®é¢˜)
10. [æœ€ä½³å®è·µ](#10-æœ€ä½³å®è·µ)

## 1. åŠŸèƒ½æ¦‚è¿°

Data Pipeline æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ•°æ®åº“é€†å‘å·¥ç¨‹å’Œè®­ç»ƒæ•°æ®ç”Ÿæˆç³»ç»Ÿï¼Œæä¾›ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

### 1.1 DDLå’ŒMDæ–‡æ¡£ç”Ÿæˆ
- è‡ªåŠ¨è¿æ¥PostgreSQLæ•°æ®åº“
- æ‰¹é‡å¤„ç†è¡¨æ¸…å•
- ä½¿ç”¨LLMç”Ÿæˆä¸­æ–‡æ³¨é‡Š
- è‡ªåŠ¨æ£€æµ‹æšä¸¾å­—æ®µ
- ç”Ÿæˆæ ‡å‡†åŒ–çš„DDLå’ŒMDæ–‡æ¡£

### 1.2 Question-SQLè®­ç»ƒæ•°æ®ç”Ÿæˆ
- éªŒè¯DDLå’ŒMDæ–‡ä»¶å®Œæ•´æ€§
- åˆ†æè¡¨ç»“æ„æå–ä¸šåŠ¡ä¸»é¢˜
- ä¸ºæ¯ä¸ªä¸»é¢˜ç”Ÿæˆé«˜è´¨é‡çš„Question-SQLå¯¹
- æ”¯æŒä¸­æ–­æ¢å¤å’Œå¹¶è¡Œå¤„ç†

### 1.3 SQLéªŒè¯å’Œä¿®å¤
- è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„SQLè¯­å¥
- ä½¿ç”¨EXPLAINè¯­æ³•æ£€æŸ¥SQLæœ‰æ•ˆæ€§
- LLMè‡ªåŠ¨ä¿®å¤æ— æ•ˆSQLè¯­å¥
- è¯¦ç»†çš„éªŒè¯æŠ¥å‘Šå’Œç»Ÿè®¡ä¿¡æ¯

### 1.4 è®­ç»ƒæ•°æ®ç®¡ç†
- è‡ªåŠ¨è¯†åˆ«å¤šç§è®­ç»ƒæ•°æ®æ ¼å¼
- ç»Ÿä¸€çš„è®­ç»ƒæ•°æ®åŠ è½½å’Œå¤„ç†
- æ”¯æŒDDLã€æ–‡æ¡£ã€Q&Aå¯¹ç­‰å¤šç§æ•°æ®ç±»å‹

### 1.5 ä¸€é”®å·¥ä½œæµç¼–æ’å™¨ï¼ˆæ¨èï¼‰
- ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–æ‰§è¡Œå®Œæ•´æµç¨‹
- DDL/MDç”Ÿæˆ â†’ Question-SQLç”Ÿæˆ â†’ SQLéªŒè¯ä¿®å¤
- è¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Šå’Œæ€§èƒ½æŒ‡æ ‡
- æ”¯æŒçµæ´»é…ç½®å’Œé”™è¯¯æ¢å¤

## 2. å®‰è£…ä¸é…ç½®

### 2.1 ä¾èµ–å®‰è£…

```bash
pip install asyncpg asyncio
```

### 2.2 åŸºæœ¬é…ç½®

Data Pipeline ä½¿ç”¨é¡¹ç›®ç°æœ‰çš„ LLM é…ç½®ï¼Œæ— éœ€é¢å¤–é…ç½®æ•°æ®åº“è¿æ¥ã€‚

### 2.3 ç›®å½•ç»“æ„

```
data_pipeline/
â”œâ”€â”€ ddl_generation/          # DDL/MDæ–‡æ¡£ç”Ÿæˆå·¥å…·
â”‚   â”œâ”€â”€ ddl_md_generator.py
â”‚   â””â”€â”€ training_data_agent.py
â”œâ”€â”€ qa_generation/           # Q&Aç”Ÿæˆå·¥å…·
â”‚   â”œâ”€â”€ qs_agent.py
â”‚   â””â”€â”€ qs_generator.py
â”œâ”€â”€ validators/              # SQLéªŒè¯å·¥å…·  
â”‚   â”œâ”€â”€ sql_validate_cli.py
â”‚   â”œâ”€â”€ sql_validation_agent.py
â”‚   â””â”€â”€ sql_validator.py
â”œâ”€â”€ trainer/                 # è®­ç»ƒæ•°æ®ç®¡é“
â”‚   â”œâ”€â”€ run_training.py
â”‚   â””â”€â”€ vanna_trainer.py
â”œâ”€â”€ training_data/           # è®­ç»ƒæ•°æ®å­˜å‚¨ç›®å½•
â”œâ”€â”€ tools/                   # æ ¸å¿ƒå·¥å…·
â”œâ”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”œâ”€â”€ config.py               # é…ç½®æ–‡ä»¶
â””â”€â”€ schema_workflow.py  # å·¥ä½œæµç¼–æ’å™¨
```

## 3. ä¸€é”®æ‰§è¡Œå®Œæ•´å·¥ä½œæµï¼ˆæ¨èï¼‰

### 3.1 å·¥ä½œæµç¼–æ’å™¨æ¦‚è¿°

`SchemaWorkflowOrchestrator` æ˜¯ Data Pipeline çš„æ ¸å¿ƒç»„ä»¶ï¼Œæä¾›ç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–å¤„ç†æµç¨‹ï¼š

1. **DDLå’ŒMDæ–‡æ¡£ç”Ÿæˆ** - è¿æ¥æ•°æ®åº“ï¼Œç”Ÿæˆè¡¨ç»“æ„æ–‡æ¡£
2. **Question-SQLå¯¹ç”Ÿæˆ** - åŸºäºæ–‡æ¡£ç”Ÿæˆè®­ç»ƒæ•°æ®
3. **SQLéªŒè¯å’Œä¿®å¤** - éªŒè¯SQLæœ‰æ•ˆæ€§å¹¶è‡ªåŠ¨ä¿®å¤é”™è¯¯
4. **è®­ç»ƒæ•°æ®åŠ è½½** - å°†ç”Ÿæˆçš„æ•°æ®åŠ è½½åˆ°å‘é‡æ•°æ®åº“ä¸­

### 3.2 å‘½ä»¤è¡Œä½¿ç”¨

#### åŸºæœ¬ä½¿ç”¨ï¼ˆå®Œæ•´å·¥ä½œæµï¼‰
```bash
python -m data_pipeline.schema_workflow \
  --db-connection "postgresql://user:pass@localhost:5432/highway_db" \
  --table-list tables.txt \
  --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ" \
  --output-dir ./data_pipeline/training_data/
```

#### è·³è¿‡SQLéªŒè¯
```bash
python -m data_pipeline.schema_workflow \
  --db-connection "postgresql://user:pass@localhost:5432/ecommerce_db" \
  --table-list tables.txt \
  --business-context "ç”µå•†ç³»ç»Ÿ" \
  --skip-validation
```

#### ç¦ç”¨LLMä¿®å¤
```bash
python -m data_pipeline.schema_workflow \
  --db-connection "postgresql://user:pass@localhost:5432/management_db" \
  --table-list tables.txt \
  --business-context "ç®¡ç†ç³»ç»Ÿ" \
  --disable-llm-repair
```

#### ä¸ä¿®æ”¹åŸå§‹æ–‡ä»¶ï¼ˆä»…ç”ŸæˆæŠ¥å‘Šï¼‰
```bash
python -m data_pipeline.schema_workflow \
  --db-connection "postgresql://user:pass@localhost:5432/business_db" \
  --table-list tables.txt \
  --business-context "ä¸šåŠ¡ç³»ç»Ÿ" \
  --no-modify-file
```

### 3.3 ç¼–ç¨‹æ–¹å¼ä½¿ç”¨

```python
import asyncio
from data_pipeline.schema_workflow import SchemaWorkflowOrchestrator

async def run_complete_workflow():
    # åˆ›å»ºå·¥ä½œæµç¼–æ’å™¨
    orchestrator = SchemaWorkflowOrchestrator(
        db_connection="postgresql://user:pass@localhost:5432/highway_db",
        table_list_file="tables.txt",
        business_context="é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ",
        output_dir="./data_pipeline/training_data/",
        enable_sql_validation=True,      # å¯ç”¨SQLéªŒè¯
        enable_llm_repair=True,          # å¯ç”¨LLMä¿®å¤
        modify_original_file=True        # ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶
    )
    
    # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
    report = await orchestrator.execute_complete_workflow()
    
    # å¤„ç†ç»“æœ
    if report["success"]:
        print(f"âœ… å·¥ä½œæµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“„ æœ€ç»ˆè¾“å‡ºæ–‡ä»¶: {report['final_outputs']['primary_output_file']}")
        print(f"â“ æœ€ç»ˆé—®é¢˜æ•°é‡: {report['final_outputs']['final_question_count']}")
        print(f"â±ï¸  æ€»è€—æ—¶: {report['performance_metrics']['total_duration']} ç§’")
    else:
        print(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {report['error']['message']}")
        print(f"ğŸ’¥ å¤±è´¥æ­¥éª¤: {report['error']['failed_step']}")

# è¿è¡Œå·¥ä½œæµç¨‹
asyncio.run(run_complete_workflow())
```

### 3.4 å·¥ä½œæµå‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--db-connection` | æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²ï¼ˆåŒ…å«æ•°æ®åº“åï¼‰ | å¿…éœ€ |
| `--table-list` | è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„ | å¿…éœ€ |
| `--business-context` | ä¸šåŠ¡ä¸Šä¸‹æ–‡æè¿° | å¿…éœ€ |
| `--output-dir` | è¾“å‡ºç›®å½• | `./data_pipeline/training_data/` |
| `--skip-validation` | è·³è¿‡SQLéªŒè¯æ­¥éª¤ | `False`ï¼ˆé»˜è®¤æ‰§è¡ŒSQLéªŒè¯ï¼‰ |
| `--disable-llm-repair` | ç¦ç”¨LLMä¿®å¤åŠŸèƒ½ | `False`ï¼ˆé»˜è®¤å¯ç”¨LLMä¿®å¤ï¼‰ |
| `--no-modify-file` | ä¸ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶ | `False`ï¼ˆé»˜è®¤ä¿®æ”¹åŸæ–‡ä»¶ï¼‰ |
| `--skip-training-load` | è·³è¿‡è®­ç»ƒæ•°æ®åŠ è½½æ­¥éª¤ | `False`ï¼ˆé»˜è®¤æ‰§è¡Œè®­ç»ƒæ•°æ®åŠ è½½ï¼‰ |
| `--verbose` | å¯ç”¨è¯¦ç»†æ—¥å¿— | `False` |
| `--log-file` | æ—¥å¿—æ–‡ä»¶è·¯å¾„ | æ—  |

### 3.5 å·¥ä½œæµæ‰§è¡ŒæŠ¥å‘Š

å·¥ä½œæµç¼–æ’å™¨ä¼šç”Ÿæˆè¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

```python
{
    "success": True,
    "workflow_summary": {
        "total_duration": 285.34,
        "completed_steps": ["ddl_md_generation", "question_sql_generation", "sql_validation", "training_data_load"],
        "total_steps": 4
    },
    "processing_results": {
        "ddl_md_generation": {
            "total_tables": 8,
            "processed_successfully": 8,
            "duration": 89.23
        },
        "question_sql_generation": {
            "total_questions": 50,
            "total_themes": 5,
            "duration": 123.45
        },
        "sql_validation": {
            "success_rate": 0.94,
            "valid_sql_count": 47,
            "invalid_sql_count": 3,
            "duration": 32.99
        },
        "training_data_load": {
            "total_records": 195,
            "data_type_counts": {
                "ddl": 8,
                "documentation": 8,
                "sql": 47
            },
            "duration": 39.67
        }
    },
    "final_outputs": {
        "primary_output_file": "./data_pipeline/training_data/qs_highway_db_20240123_143052_pair.json",
        "final_question_count": 47
    },
    "performance_metrics": {
        "step1_duration": 89.23,
        "step2_duration": 123.45,
        "step3_duration": 32.99,
        "step4_duration": 39.67,
        "total_duration": 285.34
    }
}
```

## 4. ç”ŸæˆDDLå’ŒMDæ–‡æ¡£ï¼ˆåˆ†æ­¥æ‰§è¡Œï¼‰

### 4.1 å‘½ä»¤æ ¼å¼

```bash
python -m data_pipeline.ddl_generation.ddl_md_generator \
  --db-connection <æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²> \
  --table-list <è¡¨æ¸…å•æ–‡ä»¶> \
  --business-context <ä¸šåŠ¡ä¸Šä¸‹æ–‡> \
  [å¯é€‰å‚æ•°]
```

### 4.2 å¿…éœ€å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--db-connection` | PostgreSQLæ•°æ®åº“è¿æ¥å­—ç¬¦ä¸² | `postgresql://user:pass@localhost:5432/dbname` |
| `--table-list` | è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„ | `./tables.txt` |
| `--business-context` | ä¸šåŠ¡ä¸Šä¸‹æ–‡æè¿° | `"é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ"` |

### 4.3 å¯é€‰å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--output-dir` | è¾“å‡ºç›®å½•è·¯å¾„ | `./data_pipeline/training_data/` |
| `--pipeline` | å¤„ç†é“¾ç±»å‹ | `full` |
| `--max-concurrent` | æœ€å¤§å¹¶å‘è¡¨æ•°é‡ | `1` |
| `--verbose` | å¯ç”¨è¯¦ç»†æ—¥å¿— | `False` |
| `--log-file` | æ—¥å¿—æ–‡ä»¶è·¯å¾„ | `æ— ` |
| `--no-filter-system-tables` | ç¦ç”¨ç³»ç»Ÿè¡¨è¿‡æ»¤ | `False` |
| `--check-permissions-only` | ä»…æ£€æŸ¥æ•°æ®åº“æƒé™ | `False` |

### 4.4 ä½¿ç”¨ç¤ºä¾‹

#### åŸºæœ¬ä½¿ç”¨
```bash
python -m data_pipeline.ddl_generation.ddl_md_generator \
  --db-connection "postgresql://postgres:postgres@localhost:5432/highway_db" \
  --table-list ./tables.txt \
  --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ"
```

#### æŒ‡å®šè¾“å‡ºç›®å½•å’Œå¯ç”¨è¯¦ç»†æ—¥å¿—
```bash
python -m data_pipeline.ddl_generation.ddl_md_generator \
  --db-connection "postgresql://postgres:postgres@localhost:5432/highway_db" \
  --table-list ./tables.txt \
  --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ" \
  --output-dir ./data_pipeline/training_data/ \
  --verbose
```

#### æƒé™æ£€æŸ¥
```bash
python -m data_pipeline.ddl_generation.ddl_md_generator \
  --db-connection "postgresql://postgres:postgres@localhost:5432/highway_db" \
  --check-permissions-only
```

## 5. ç”ŸæˆQuestion-SQLè®­ç»ƒæ•°æ®ï¼ˆåˆ†æ­¥æ‰§è¡Œï¼‰

### 5.1 å‰ç½®æ¡ä»¶

å¿…é¡»å…ˆæ‰§è¡ŒDDLå’ŒMDæ–‡æ¡£ç”Ÿæˆï¼Œç¡®ä¿è¾“å‡ºç›®å½•ä¸­æœ‰å®Œæ•´çš„DDLå’ŒMDæ–‡ä»¶ã€‚

### 5.2 å‘½ä»¤æ ¼å¼

```bash
python -m data_pipeline.qa_generation.qs_generator \
  --output-dir <è¾“å‡ºç›®å½•> \
  --table-list <è¡¨æ¸…å•æ–‡ä»¶> \
  --business-context <ä¸šåŠ¡ä¸Šä¸‹æ–‡> \
  [å¯é€‰å‚æ•°]
```

### 5.3 å¿…éœ€å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--output-dir` | åŒ…å«DDLå’ŒMDæ–‡ä»¶çš„ç›®å½• | `./data_pipeline/training_data/` |
| `--table-list` | è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºéªŒè¯ï¼‰ | `./tables.txt` |
| `--business-context` | ä¸šåŠ¡ä¸Šä¸‹æ–‡æè¿° | `"é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ"` |

### 5.4 ä½¿ç”¨ç¤ºä¾‹

#### åŸºæœ¬ä½¿ç”¨
```bash
python -m data_pipeline.qa_generation.qs_generator \
  --output-dir ./data_pipeline/training_data/ \
  --table-list ./tables.txt \
  --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ" \
   highway_db
```

#### å¯ç”¨è¯¦ç»†æ—¥å¿—
```bash
python -m data_pipeline.qa_generation.qs_generator \
  --output-dir ./data_pipeline/training_data/ \
  --table-list ./tables.txt \
  --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ" \
   highway_db \
  --verbose
```

## 6. SQLéªŒè¯å’Œä¿®å¤

### 6.1 å‘½ä»¤æ ¼å¼

ç”ŸæˆQuestion-SQLå¯¹åï¼Œå¯ä»¥ä½¿ç”¨SQLéªŒè¯åŠŸèƒ½ã€‚**æ³¨æ„ï¼šå‘½ä»¤è¡Œä½¿ç”¨æ—¶ï¼Œé»˜è®¤å¯ç”¨LLMä¿®å¤å’Œæ–‡ä»¶ä¿®æ”¹åŠŸèƒ½**ã€‚

```bash
python -m data_pipeline.validators.sql_validate_cli \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --input-file ./qs_highway_db_20240123_143052_pair.json \
  --output-dir ./validation_reports
```

### 6.2 SQLéªŒè¯å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--db-connection` | æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸² | å¿…éœ€ |
| `--input-file` | Question-SQLæ–‡ä»¶è·¯å¾„ | å¿…éœ€ |
| `--output-dir` | éªŒè¯æŠ¥å‘Šè¾“å‡ºç›®å½• | è¾“å…¥æ–‡ä»¶åŒç›®å½• |
| `--disable-llm-repair` | ç¦ç”¨LLMä¿®å¤åŠŸèƒ½ | `False`ï¼ˆé»˜è®¤å¯ç”¨ä¿®å¤ï¼‰ |
| `--no-modify-file` | ä¸ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶ | `False`ï¼ˆé»˜è®¤ä¿®æ”¹åŸæ–‡ä»¶ï¼‰ |
| `--max-concurrent` | æœ€å¤§å¹¶å‘éªŒè¯æ•° | `5` |
| `--batch-size` | æ‰¹å¤„ç†å¤§å° | `10` |
| `--timeout` | å•ä¸ªéªŒè¯è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ | `30` |
| `--verbose` | å¯ç”¨è¯¦ç»†æ—¥å¿— | `False` |
| `--dry-run` | ä»…è§£ææ–‡ä»¶ä¸æ‰§è¡ŒéªŒè¯ | `False` |
| `--save-json` | ä¿å­˜è¯¦ç»†JSONæŠ¥å‘Š | `False` |

### 6.3 SQLéªŒè¯ä½¿ç”¨ç¤ºä¾‹

```bash
# åŸºæœ¬éªŒè¯ï¼ˆé»˜è®¤ï¼šå¯ç”¨LLMä¿®å¤å’Œæ–‡ä»¶ä¿®æ”¹ï¼‰
python -m data_pipeline.validators.sql_validate_cli \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --input-file ./data.json

# ä»…ç”ŸæˆæŠ¥å‘Šï¼Œä¸ä¿®æ”¹æ–‡ä»¶
python -m data_pipeline.validators.sql_validate_cli \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --input-file ./data.json \
  --no-modify-file

# å¯ç”¨æ–‡ä»¶ä¿®æ”¹ï¼Œä½†ç¦ç”¨LLMä¿®å¤ï¼ˆä»…åˆ é™¤æ— æ•ˆSQLï¼‰
python -m data_pipeline.validators.sql_validate_cli \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --input-file ./data.json \
  --disable-llm-repair

# æ€§èƒ½è°ƒä¼˜å‚æ•°
python -m data_pipeline.validators.sql_validate_cli \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --input-file ./data.json \
  --max-concurrent 10 \
  --batch-size 20 \
  --timeout 60 \
  --verbose
```

## 7. è®­ç»ƒæ•°æ®ç®¡ç†

### 7.1 è®­ç»ƒæ•°æ®åŠ è½½

```bash
# ä½¿ç”¨è®­ç»ƒæ•°æ®ç®¡é“
python -m data_pipeline.trainer.run_training \
  --data_path ./data_pipeline/training_data/
```

### 7.2 æ”¯æŒçš„æ–‡ä»¶æ ¼å¼

Data Pipeline è‡ªåŠ¨è¯†åˆ«ä»¥ä¸‹è®­ç»ƒæ•°æ®æ ¼å¼ï¼š

- **`.ddl`** æ–‡ä»¶ â†’ `train_ddl_statements()`
- **`.md/.markdown`** â†’ `train_documentation_blocks()`
- **`_pair.json/_pairs.json`** â†’ `train_json_question_sql_pairs()`
- **`_pair.sql/_pairs.sql`** â†’ `train_formatted_question_sql_pairs()`
- **`.sql`** (å…¶ä»–) â†’ `train_sql_examples()`

### 7.3 è®­ç»ƒæ•°æ®ç›®å½•ç»“æ„

```
data_pipeline/training_data/
â”œâ”€â”€ bss_service_area.ddl              # DDLæ–‡ä»¶
â”œâ”€â”€ bss_service_area_detail.md        # MDæ–‡æ¡£
â”œâ”€â”€ bss_company.ddl
â”œâ”€â”€ bss_company_detail.md
â”œâ”€â”€ qs_highway_db_20240123_143052_pair.json  # Q&Aè®­ç»ƒæ•°æ®
â”œâ”€â”€ filename_mapping.txt              # æ–‡ä»¶åæ˜ å°„
â””â”€â”€ logs/                            # æ—¥å¿—ç›®å½•
    â””â”€â”€ data_pipeline_20240123.log
```

## 8. é…ç½®è¯¦è§£

### 8.1 ä¸»è¦é…ç½®é¡¹

é…ç½®æ–‡ä»¶ä½äº `data_pipeline/config.py`ï¼š

```python
# DDL/MDç”Ÿæˆç›¸å…³é…ç½®
"output_directory": "./data_pipeline/training_data/",   # è¾“å‡ºç›®å½•
"create_subdirectories": False,                        # ä¸åˆ›å»ºå­ç›®å½•
"max_concurrent_tables": 1,                            # æœ€å¤§å¹¶å‘æ•°ï¼ˆé¿å…LLMå¹¶å‘é—®é¢˜ï¼‰
"sample_data_limit": 20,                              # æ•°æ®é‡‡æ ·é‡
"large_table_threshold": 1000000,                     # å¤§è¡¨é˜ˆå€¼ï¼ˆ100ä¸‡è¡Œï¼‰
"filter_system_tables": True,                          # è¿‡æ»¤ç³»ç»Ÿè¡¨
"continue_on_error": True,                             # é”™è¯¯åç»§ç»­

# Question-SQLç”Ÿæˆé…ç½®
"qs_generation": {
    "max_tables": 20,                                 # æœ€å¤§è¡¨æ•°é‡é™åˆ¶
    "theme_count": 5,                                 # ä¸»é¢˜æ•°é‡
    "questions_per_theme": 10,                        # æ¯ä¸»é¢˜é—®é¢˜æ•°
    "max_concurrent_themes": 1,                       # å¹¶è¡Œä¸»é¢˜æ•°ï¼ˆé¿å…LLMå¹¶å‘é—®é¢˜ï¼‰
    "continue_on_theme_error": True,                  # ä¸»é¢˜å¤±è´¥ç»§ç»­
    "save_intermediate": True,                        # ä¿å­˜ä¸­é—´ç»“æœ
}

# SQLéªŒè¯é…ç½®
"sql_validation": {
    "max_concurrent_validations": 5,                  # å¹¶å‘éªŒè¯æ•°
    "validation_timeout": 30,                         # å•ä¸ªéªŒè¯è¶…æ—¶(ç§’)
    "batch_size": 10,                                 # æ‰¹å¤„ç†å¤§å°
    "enable_sql_repair": False,                       # SQLä¿®å¤åŠŸèƒ½ï¼ˆå‘½ä»¤è¡Œè¦†ç›–ä¸ºTrueï¼‰
    "modify_original_file": False,                    # æ–‡ä»¶ä¿®æ”¹åŠŸèƒ½ï¼ˆå‘½ä»¤è¡Œè¦†ç›–ä¸ºTrueï¼‰
    "readonly_mode": True,                            # å¯ç”¨åªè¯»æ¨¡å¼
}
```

### 8.2 ä¿®æ”¹é…ç½®

å¯ä»¥é€šè¿‡ç¼–è¾‘ `data_pipeline/config.py` æ–‡ä»¶æ¥ä¿®æ”¹é»˜è®¤é…ç½®ã€‚

## 9. å¸¸è§é—®é¢˜

### 9.1 è¡¨æ•°é‡è¶…è¿‡20ä¸ªæ€ä¹ˆåŠï¼Ÿ

**é”™è¯¯ä¿¡æ¯**ï¼š
```
è¡¨æ•°é‡(25)è¶…è¿‡é™åˆ¶(20)ã€‚è¯·åˆ†æ‰¹å¤„ç†æˆ–è°ƒæ•´é…ç½®ä¸­çš„max_tableså‚æ•°ã€‚
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. åˆ†æ‰¹å¤„ç†ï¼šå°†è¡¨æ¸…å•åˆ†æˆå¤šä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªä¸è¶…è¿‡20ä¸ªè¡¨
2. ä¿®æ”¹é…ç½®ï¼šåœ¨ `config.py` ä¸­å¢åŠ  `max_tables` é™åˆ¶

### 9.2 DDLå’ŒMDæ–‡ä»¶æ•°é‡ä¸ä¸€è‡´

**é”™è¯¯ä¿¡æ¯**ï¼š
```
DDLæ–‡ä»¶æ•°é‡(5)ä¸è¡¨æ•°é‡(6)ä¸ä¸€è‡´
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥æ˜¯å¦æœ‰è¡¨å¤„ç†å¤±è´¥
2. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æ‰¾å‡ºå¤±è´¥çš„è¡¨
3. é‡æ–°è¿è¡ŒDDL/MDç”Ÿæˆ

### 9.3 LLMè°ƒç”¨å¤±è´¥

**å¯èƒ½åŸå› **ï¼š
- ç½‘ç»œè¿æ¥é—®é¢˜
- APIé…é¢é™åˆ¶
- Tokenè¶…é™

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æŸ¥çœ‹ä¸­é—´ç»“æœæ–‡ä»¶ï¼Œä»æ–­ç‚¹ç»§ç»­
3. å‡å°‘è¡¨æ•°é‡æˆ–åˆ†æ‰¹å¤„ç†

### 9.4 æƒé™ä¸è¶³

**é”™è¯¯ä¿¡æ¯**ï¼š
```
æ•°æ®åº“æŸ¥è¯¢æƒé™ä¸è¶³
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨ `--check-permissions-only` æ£€æŸ¥æƒé™
2. ç¡®ä¿æ•°æ®åº“ç”¨æˆ·æœ‰SELECTæƒé™
3. Data Pipelineæ”¯æŒåªè¯»æ•°æ®åº“

### 9.5 å·¥ä½œæµç¼–æ’å™¨ç›¸å…³é—®é¢˜

**Q: å·¥ä½œæµä¸­é€”å¤±è´¥ï¼Œå¦‚ä½•æ¢å¤ï¼Ÿ**
A: å·¥ä½œæµç¼–æ’å™¨ä¼šä¿ç•™å·²å®Œæˆæ­¥éª¤çš„è¾“å‡ºæ–‡ä»¶ï¼Œå¯ä»¥æ‰‹åŠ¨ä»å¤±è´¥æ­¥éª¤å¼€å§‹é‡æ–°æ‰§è¡Œã€‚

**Q: å¦‚ä½•åªæ‰§è¡Œéƒ¨åˆ†æ­¥éª¤ï¼Ÿ**
A: ä½¿ç”¨ `--skip-validation` è·³è¿‡SQLéªŒè¯ï¼Œæˆ–ä½¿ç”¨åˆ†æ­¥æ‰§è¡Œæ–¹å¼è°ƒç”¨å„ä¸ªæ¨¡å—ã€‚

**Q: å·¥ä½œæµæ‰§è¡Œæ—¶é—´è¿‡é•¿æ€ä¹ˆåŠï¼Ÿ**
A: å¯ä»¥é€šè¿‡å‡å°‘è¡¨æ•°é‡ã€è°ƒæ•´å¹¶å‘å‚æ•°ã€æˆ–åˆ†æ‰¹å¤„ç†æ¥ä¼˜åŒ–æ‰§è¡Œæ—¶é—´ã€‚

### 9.6 SQLéªŒè¯å™¨é»˜è®¤è¡Œä¸ºè¯´æ˜

**é‡è¦**ï¼šSQLéªŒè¯å™¨çš„å‘½ä»¤è¡Œæ¨¡å¼ä¸é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ä¸åŒï¼š

- **é…ç½®æ–‡ä»¶é»˜è®¤**ï¼š`enable_sql_repair=False`, `modify_original_file=False`
- **å‘½ä»¤è¡Œé»˜è®¤**ï¼šå¯ç”¨LLMä¿®å¤å’Œæ–‡ä»¶ä¿®æ”¹åŠŸèƒ½
- **åŸå› **ï¼šå‘½ä»¤è¡Œä½¿ç”¨æ—¶é€šå¸¸æœŸæœ›å®Œæ•´çš„ä¿®å¤åŠŸèƒ½ï¼Œè€Œé…ç½®æ–‡ä»¶æä¾›ä¿å®ˆçš„é»˜è®¤å€¼

å¦‚éœ€ç¦ç”¨ï¼Œè¯·æ˜ç¡®ä½¿ç”¨ `--disable-llm-repair` æˆ– `--no-modify-file` å‚æ•°ã€‚

## 10. æœ€ä½³å®è·µ

### 10.1 æ¨èå·¥ä½œæµç¨‹

**æ–¹å¼ä¸€ï¼šä¸€é”®æ‰§è¡Œï¼ˆæ¨èï¼‰**
```bash
# å®Œæ•´å·¥ä½œæµç¨‹ï¼Œä¸€ä¸ªå‘½ä»¤æå®š
python -m data_pipeline.schema_workflow \
  --db-connection "postgresql://user:pass@localhost:5432/highway_db" \
  --table-list tables.txt \
  --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ" \
  --output-dir ./data_pipeline/training_data/
```

**æ–¹å¼äºŒï¼šåˆ†æ­¥æ‰§è¡Œï¼ˆè°ƒè¯•æ—¶ä½¿ç”¨ï¼‰**
1. **ç¬¬ä¸€æ­¥**ï¼šç”ŸæˆDDLå’ŒMDæ–‡æ¡£
   ```bash
   python -m data_pipeline.ddl_generation.ddl_md_generator --db-connection "..." --table-list tables.txt --business-context "..." --output-dir ./data_pipeline/training_data/
   ```

2. **ç¬¬äºŒæ­¥**ï¼šäººå·¥æ£€æŸ¥
   - æ£€æŸ¥DDLæ–‡ä»¶çš„è¡¨ç»“æ„æ˜¯å¦æ­£ç¡®
   - ç¡®è®¤MDæ–‡æ¡£ä¸­çš„æ³¨é‡Šæ˜¯å¦å‡†ç¡®
   - æ ¹æ®éœ€è¦æ‰‹åŠ¨è°ƒæ•´

3. **ç¬¬ä¸‰æ­¥**ï¼šç”ŸæˆQuestion-SQL
   ```bash
   python -m data_pipeline.qa_generation.qs_generator --output-dir ./data_pipeline/training_data/ --table-list tables.txt --business-context "..."
   ```

4. **ç¬¬å››æ­¥**ï¼šéªŒè¯SQLï¼ˆå¯é€‰ï¼‰
   ```bash
   python -m data_pipeline.validators.sql_validate_cli --db-connection "..." --input-file ./qs_xxx.json
   ```

5. **ç¬¬äº”æ­¥**ï¼šè®­ç»ƒæ•°æ®åŠ è½½
   ```bash
   python -m data_pipeline.trainer.run_training --data_path ./data_pipeline/training_data/
   ```

### 10.2 è¡¨æ¸…å•ç»„ç»‡

- æŒ‰ä¸šåŠ¡æ¨¡å—åˆ†ç»„
- æ¯ç»„ä¸è¶…è¿‡15-20ä¸ªè¡¨
- ä½¿ç”¨æ³¨é‡Šè¯´æ˜æ¯ç»„çš„ç”¨é€”

### 10.3 ä¸šåŠ¡ä¸Šä¸‹æ–‡ä¼˜åŒ–

- æä¾›å‡†ç¡®çš„ä¸šåŠ¡èƒŒæ™¯æè¿°
- åŒ…å«è¡Œä¸šç‰¹å®šæœ¯è¯­
- è¯´æ˜ä¸»è¦ä¸šåŠ¡æµç¨‹

### 10.4 è¾“å‡ºæ–‡ä»¶ç®¡ç†

- å®šæœŸå¤‡ä»½ç”Ÿæˆçš„æ–‡ä»¶
- ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†DDLæ–‡ä»¶
- ä¿ç•™ä¸­é—´ç»“æœç”¨äºè°ƒè¯•
- ç»Ÿä¸€ä½¿ç”¨ `./data_pipeline/training_data/` ç›®å½•

### 10.5 å·¥ä½œæµç¼–æ’å™¨æœ€ä½³å®è·µ

- **é¦–æ¬¡ä½¿ç”¨**ï¼šå»ºè®®å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼ˆ`--verbose`ï¼‰è§‚å¯Ÿæ‰§è¡Œè¿‡ç¨‹
- **ç”Ÿäº§ç¯å¢ƒ**ï¼šä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œå¯ç”¨SQLéªŒè¯å’Œä¿®å¤
- **è°ƒè¯•é˜¶æ®µ**ï¼šå¯ä»¥ä½¿ç”¨ `--skip-validation` è·³è¿‡éªŒè¯æ­¥éª¤åŠ å¿«æ‰§è¡Œ
- **è´¨é‡è¦æ±‚é«˜**ï¼šä½¿ç”¨ `--no-modify-file` ä»…ç”ŸæˆæŠ¥å‘Šï¼Œæ‰‹åŠ¨å®¡æŸ¥åå†å†³å®šæ˜¯å¦ä¿®æ”¹

### 10.6 æ•°æ®ç®¡é“é›†æˆ

- **è®­ç»ƒæ•°æ®ç»Ÿä¸€ç®¡ç†**ï¼šæ‰€æœ‰ç”Ÿæˆçš„æ•°æ®éƒ½å­˜å‚¨åœ¨ `data_pipeline/training_data/` ç›®å½•
- **è‡ªåŠ¨åŒ–è®­ç»ƒ**ï¼šå¯ä»¥å®šæœŸè¿è¡Œå·¥ä½œæµç¼–æ’å™¨æ›´æ–°è®­ç»ƒæ•°æ®
- **ç‰ˆæœ¬æ§åˆ¶**ï¼šå»ºè®®å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œç‰ˆæœ¬ç®¡ç†
- **ç›‘æ§å’ŒæŠ¥å‘Š**ï¼šåˆ©ç”¨è¯¦ç»†çš„æ‰§è¡ŒæŠ¥å‘Šç›‘æ§æ•°æ®è´¨é‡

## æ€»ç»“

Data Pipeline æä¾›äº†å®Œæ•´çš„æ•°æ®åº“é€†å‘å·¥ç¨‹è§£å†³æ–¹æ¡ˆï¼Œä»åŸå§‹æ•°æ®åº“schemaåˆ°å¯ç”¨çš„è®­ç»ƒæ•°æ®ï¼Œæ•´ä¸ªæµç¨‹å®Œå…¨è‡ªåŠ¨åŒ–ã€‚é€šè¿‡å·¥ä½œæµç¼–æ’å™¨ï¼Œç”¨æˆ·å¯ä»¥ä¸€é”®å®Œæˆæ‰€æœ‰æ­¥éª¤ï¼Œä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦åˆ†æ­¥æ‰§è¡Œå’Œè°ƒè¯•ã€‚ç³»ç»Ÿè®¾è®¡è€ƒè™‘äº†å®¹é”™æ€§ã€å¯æ‰©å±•æ€§å’Œæ˜“ç”¨æ€§ï¼Œé€‚åˆå„ç§è§„æ¨¡çš„æ•°æ®å¤„ç†éœ€æ±‚ã€‚

-------
  ä¸€é”®æ‰§è¡Œï¼ˆæ¨èï¼‰ï¼š

  # å®Œæ•´çš„4æ­¥æµç¨‹
  python -m data_pipeline.schema_workflow \
    --db-connection "postgresql://user:pass@localhost:5432/highway_db" \
    --table-list tables.txt \
    --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ" \
    --output-dir ./data_pipeline/training_data/

  # å¦‚éœ€è·³è¿‡è®­ç»ƒæ•°æ®åŠ è½½
  python -m data_pipeline.schema_workflow \
    --db-connection "postgresql://user:pass@localhost:5432/test_db" \
    --table-list tables.txt \
    --business-context "æµ‹è¯•ç³»ç»Ÿ" \
    --skip-training-load

  åˆ†æ­¥æ‰§è¡Œï¼š

  # ç¬¬1æ­¥ï¼šDDL/MDç”Ÿæˆ
  python -m data_pipeline.ddl_generation.ddl_md_generator --db-connection "..." --table-list tables.txt --business-context "..."

  # ç¬¬2æ­¥ï¼šQ&Aç”Ÿæˆ
  python -m data_pipeline.qa_generation.qs_generator --output-dir ./data_pipeline/training_data/ --table-list tables.txt --business-context "..."

  # ç¬¬3æ­¥ï¼šSQLéªŒè¯
  python -m data_pipeline.validators.sql_validate_cli --db-connection "..." --input-file ./qs_xxx.json

  # ç¬¬4æ­¥ï¼šè®­ç»ƒæ•°æ®åŠ è½½
  python -m data_pipeline.trainer.run_training --data_path ./data_pipeline/training_data/
