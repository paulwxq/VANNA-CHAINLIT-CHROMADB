# Vectorè¡¨ç®¡ç†åŠŸèƒ½ç»Ÿä¸€åŒ–é‡æ„æ–¹æ¡ˆ

## æ¦‚è¿°

å½“å‰ç³»ç»Ÿä¸­Vectorè¡¨ç®¡ç†åŠŸèƒ½å­˜åœ¨ä¸¤å¥—ä¸åŒçš„å®ç°è·¯å¾„ï¼Œå¯¼è‡´è„šæœ¬æ¨¡å¼å’ŒAPIæ¨¡å¼çš„è¡Œä¸ºä¸ä¸€è‡´ã€‚æœ¬æ–‡æ¡£æå‡ºç»Ÿä¸€åŒ–é‡æ„æ–¹æ¡ˆï¼Œå°†Vectorè¡¨ç®¡ç†åŠŸèƒ½ç»Ÿä¸€æ”¶æ•›åˆ° `training_load` æ­¥éª¤ä¸­ï¼Œå®ç°è„šæœ¬æ¨¡å¼å’ŒAPIæ¨¡å¼çš„å®Œå…¨ä¸€è‡´ã€‚

## æœ€ç»ˆè®¾è®¡å†³å®š

åŸºäºç”¨æˆ·åé¦ˆï¼Œä»¥ä¸‹ä¸ºæœ€ç»ˆç¡®å®šçš„å‚æ•°è®¾è®¡ï¼š

### å‚æ•°å®šä¹‰
- `--backup-vector-tables`ï¼šå¤‡ä»½vectorè¡¨æ•°æ®ï¼ˆé»˜è®¤å€¼ï¼š`false`ï¼‰
- `--truncate-vector-tables`ï¼šæ¸…ç©ºvectorè¡¨æ•°æ®ï¼Œè‡ªåŠ¨å¯ç”¨å¤‡ä»½ï¼ˆé»˜è®¤å€¼ï¼š`false`ï¼‰
- `--skip-training`ï¼šè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†ï¼Œä»…æ‰§è¡ŒVectorè¡¨ç®¡ç†ï¼ˆé»˜è®¤å€¼ï¼š`false`ï¼‰

### å‚æ•°è¯­ä¹‰
- **å‚æ•°ä¾èµ–**ï¼š`--truncate-vector-tables=true` è‡ªåŠ¨è®¾ç½® `--backup-vector-tables=true`ï¼ˆå•å‘ä¾èµ–ï¼Œ`backup` ä¸ä¼šè§¦å‘ `truncate`ï¼‰
- **å†²çªå¤„ç†**ï¼šå½“ `--skip-training=true` ä½†æœªæŒ‡å®šä»»ä½•Vectoræ“ä½œæ—¶ï¼Œè®°å½•è­¦å‘Šå¹¶è·³è¿‡æ‰€æœ‰å¤„ç†ï¼ˆå®½æ¾æ¨¡å¼ï¼‰
- **å‚æ•°ç§»é™¤**ï¼šåˆ é™¤ç°æœ‰çš„ `--skip-training-load` å‚æ•°ï¼Œç»Ÿä¸€ä½¿ç”¨ `--skip-training`

### å‚æ•°ç»„åˆè¡Œä¸ºè¡¨

| backup_vector_tables | truncate_vector_tables | skip_training | å®é™…è¡Œä¸º | æ¨è |
|:-------------------:|:---------------------:|:------------:|:--------|:---:|
| false | false | false | æ­£å¸¸è®­ç»ƒæ–‡ä»¶å¤„ç†ï¼Œæ— Vectoræ“ä½œ | âœ… |
| true | false | false | å¤‡ä»½Vectorè¡¨ + è®­ç»ƒæ–‡ä»¶å¤„ç† | âœ… |
| false | true | false | å¤‡ä»½Vectorè¡¨ + æ¸…ç©ºVectorè¡¨ + è®­ç»ƒæ–‡ä»¶å¤„ç†Â¹ | âœ… |
| true | true | false | å¤‡ä»½Vectorè¡¨ + æ¸…ç©ºVectorè¡¨ + è®­ç»ƒæ–‡ä»¶å¤„ç†Â² | âš ï¸ |
| true | false | true | ä»…å¤‡ä»½Vectorè¡¨ï¼Œè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç† | âœ… |
| false | true | true | ä»…å¤‡ä»½+æ¸…ç©ºVectorè¡¨ï¼Œè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†Â¹ | âœ… |
| true | true | true | ä»…å¤‡ä»½+æ¸…ç©ºVectorè¡¨ï¼Œè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†Â² | âš ï¸ |
| false | false | true | âš ï¸ è­¦å‘Šï¼šæœªæŒ‡å®šVectoræ“ä½œï¼Œè·³è¿‡æ‰€æœ‰å¤„ç† | âŒ |

**æ³¨é‡Š**ï¼š
- Â¹ `truncate` è‡ªåŠ¨å¯ç”¨ `backup`ï¼Œè¿™æ˜¯é¢„æœŸè¡Œä¸º
- Â² åŒæ—¶æŒ‡å®šä¸¤ä¸ªå‚æ•°æ˜¯å†—ä½™çš„ï¼Œå»ºè®®åªä½¿ç”¨ `truncate_vector_tables`

### æ¨èç”¨æ³•

**ğŸ¯ æœ€ä½³å®è·µ**ï¼š
```bash
# âœ… ä»…å¤‡ä»½Vectorè¡¨æ•°æ®
--backup-vector-tables

# âœ… æ¸…ç©ºVectorè¡¨æ•°æ®ï¼ˆè‡ªåŠ¨åŒ…å«å¤‡ä»½ï¼‰
--truncate-vector-tables

# âŒ é¿å…å†—ä½™ï¼šä¸è¦åŒæ—¶ä½¿ç”¨
--backup-vector-tables --truncate-vector-tables  # å†—ä½™

# âŒ é¿å…æ— æ„ä¹‰çš„ç»„åˆ
--skip-training  # æ²¡æœ‰Vectoræ“ä½œï¼Œä»€ä¹ˆéƒ½ä¸åš
```

## å½“å‰ç°çŠ¶åˆ†æ

### 1. è„šæœ¬æ¨¡å¼ç°çŠ¶ âœ…ï¼ˆå·²å®Œæˆï¼‰

#### å®Œæ•´æ¨¡å¼
```bash
python -m data_pipeline.schema_workflow --backup-vector-tables --truncate-vector-tables
```

**å½“å‰è°ƒç”¨é“¾**ï¼š
```
schema_workflow.py::main()
â†“
SchemaWorkflowOrchestrator(backup_vector_tables=True, truncate_vector_tables=True)
â†“
execute_complete_workflow()
â”œâ”€ _execute_vector_table_management()  # ç‹¬ç«‹æ‰§è¡ŒVectorè¡¨ç®¡ç†
â””â”€ _execute_step_4_training_data_load()
   â””â”€ process_training_files(backup_vector_tables=False, truncate_vector_tables=False)  # ç¦ç”¨ä»¥é¿å…é‡å¤
```

#### å•æ­¥æ¨¡å¼
```bash
python -m data_pipeline.trainer.run_training --backup-vector-tables --truncate-vector-tables
```

**å½“å‰è°ƒç”¨é“¾**ï¼š
```
run_training.py::main()
â†“
process_training_files(backup_vector_tables=True, truncate_vector_tables=True)
â†“
VectorTableManager.execute_vector_management()  # åœ¨å‡½æ•°å†…éƒ¨æ‰§è¡Œ
```

### 2. APIæ¨¡å¼ç°çŠ¶ âš ï¸ï¼ˆéƒ¨åˆ†å®Œæˆï¼‰

#### å®Œæ•´æ¨¡å¼
```json
{
    "execution_mode": "complete",
    "backup_vector_tables": true,
    "truncate_vector_tables": true
}
```

**å½“å‰è°ƒç”¨é“¾**ï¼š
```
unified_api.py::execute_data_pipeline_task()
â†“
SimpleWorkflowExecutor(backup_vector_tables=True, truncate_vector_tables=True)
â†“
execute_complete_workflow()
â†“
SchemaWorkflowOrchestrator.execute_complete_workflow()
â”œâ”€ _execute_vector_table_management()  # ç‹¬ç«‹æ‰§è¡ŒVectorè¡¨ç®¡ç†
â””â”€ _execute_step_4_training_data_load()
   â””â”€ process_training_files(backup_vector_tables=False, truncate_vector_tables=False)  # ç¦ç”¨ä»¥é¿å…é‡å¤
```

#### å•æ­¥æ¨¡å¼ âŒï¼ˆæœ‰é—®é¢˜ï¼‰
```json
{
    "execution_mode": "step",
    "step_name": "training_load",
    "backup_vector_tables": true,
    "truncate_vector_tables": true
}
```

**å½“å‰è°ƒç”¨é“¾ï¼ˆæœ‰é—®é¢˜ï¼‰**ï¼š
```
unified_api.py::execute_data_pipeline_task()
â†“
SimpleWorkflowExecutor(backup_vector_tables=True, truncate_vector_tables=True)
â†“
execute_single_step("training_load")
â†“
SchemaWorkflowOrchestrator._execute_step_4_training_data_load()
â†“
process_training_files(backup_vector_tables=False, truncate_vector_tables=False)  # âŒ ç¡¬ç¼–ç False
```

**é—®é¢˜**ï¼šAPIå•æ­¥æ¨¡å¼ä¸­ï¼Œç”¨æˆ·ä¼ é€’çš„Vectorè¡¨ç®¡ç†å‚æ•°è¢«ç¡¬ç¼–ç çš„ `False` è¦†ç›–ï¼Œå¯¼è‡´åŠŸèƒ½å¤±æ•ˆã€‚

### 3. å½“å‰å®ç°çš„é—®é¢˜

1. **åŒé‡å®ç°è·¯å¾„**ï¼šå®Œæ•´æ¨¡å¼ä½¿ç”¨ç‹¬ç«‹çš„ `_execute_vector_table_management()`ï¼Œå•æ­¥æ¨¡å¼ä½¿ç”¨ `process_training_files()` å†…éƒ¨å®ç°
2. **è¡Œä¸ºä¸ä¸€è‡´**ï¼šè„šæœ¬æ¨¡å¼å’ŒAPIæ¨¡å¼çš„Vectorè¡¨ç®¡ç†æ‰§è¡Œæ—¶æœºä¸åŒ
3. **ä»£ç å¤æ‚**ï¼šéœ€è¦ç»´æŠ¤é¿å…é‡å¤æ‰§è¡Œçš„é€»è¾‘
4. **APIå•æ­¥æ¨¡å¼ç¼ºé™·**ï¼šç¡¬ç¼–ç å‚æ•°å¯¼è‡´åŠŸèƒ½å¤±æ•ˆ

## ç»Ÿä¸€åŒ–é‡æ„æ–¹æ¡ˆ

### è®¾è®¡åŸåˆ™

1. **ç»Ÿä¸€æ”¶æ•›**ï¼šå°†Vectorè¡¨ç®¡ç†åŠŸèƒ½ç»Ÿä¸€æ”¶æ•›åˆ° `training_load` æ­¥éª¤ä¸­
2. **é€»è¾‘ä¸€è‡´**ï¼šè„šæœ¬æ¨¡å¼å’ŒAPIæ¨¡å¼ä½¿ç”¨å®Œå…¨ç›¸åŒçš„è°ƒç”¨è·¯å¾„
3. **èŒè´£æ¸…æ™°**ï¼šVectorè¡¨æ“ä½œä½œä¸ºè®­ç»ƒå‡†å¤‡å·¥ä½œï¼Œå½’å±äºè®­ç»ƒæ­¥éª¤
4. **åˆç†çº¦æŸ**ï¼šè·³è¿‡è®­ç»ƒæ­¥éª¤æ—¶ä¸æ‰§è¡ŒVectorè¡¨ç®¡ç†ï¼ˆé€»è¾‘åˆç†ï¼‰

### æ ¸å¿ƒä¿®æ”¹

#### 1. åˆ é™¤ç‹¬ç«‹çš„Vectorè¡¨ç®¡ç†è°ƒç”¨

**ä¿®æ”¹æ–‡ä»¶**ï¼š`data_pipeline/schema_workflow.py`

**åˆ é™¤ä»£ç **ï¼š
```python
# åˆ é™¤è¿™æ®µç‹¬ç«‹çš„Vectorè¡¨ç®¡ç†è°ƒç”¨
if self.backup_vector_tables or self.truncate_vector_tables:
    await self._execute_vector_table_management()
```

#### 2. ä¿®æ”¹training_loadæ­¥éª¤å‚æ•°ä¼ é€’

**ä¿®æ”¹æ–‡ä»¶**ï¼š`data_pipeline/schema_workflow.py`

**å½“å‰ä»£ç **ï¼š
```python
# ç¦ç”¨vectorç®¡ç†å‚æ•°ä»¥é¿å…é‡å¤æ‰§è¡Œ
load_successful, _ = process_training_files(training_data_dir, self.task_id, 
                                           backup_vector_tables=False, 
                                           truncate_vector_tables=False)
```

**ä¿®æ”¹ä¸º**ï¼š
```python
# ä¼ é€’Vectorè¡¨ç®¡ç†å‚æ•°åˆ°trainingæ­¥éª¤
load_successful, vector_stats = process_training_files(training_data_dir, self.task_id, 
                                                       backup_vector_tables=self.backup_vector_tables, 
                                                       truncate_vector_tables=self.truncate_vector_tables)

# è®°å½•Vectorè¡¨ç®¡ç†ç»“æœåˆ°å·¥ä½œæµçŠ¶æ€
if vector_stats:
    self.workflow_state["artifacts"]["vector_management"] = vector_stats
```

#### 3. å¢å¼ºprocess_training_fileså‡½æ•°

**ä¿®æ”¹æ–‡ä»¶**ï¼š`data_pipeline/trainer/run_training.py`

**æ–°å¢å‚æ•°æ”¯æŒ**ï¼š
```python
def process_training_files(data_path, task_id=None, 
                          backup_vector_tables=False, 
                          truncate_vector_tables=False,
                          skip_training=False):  # æ–°å¢å‚æ•°
    """
    å¤„ç†æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰è®­ç»ƒæ–‡ä»¶
    
    Args:
        data_path (str): è®­ç»ƒæ•°æ®ç›®å½•è·¯å¾„
        task_id (str): ä»»åŠ¡IDï¼Œç”¨äºæ—¥å¿—è®°å½•
        backup_vector_tables (bool): æ˜¯å¦å¤‡ä»½vectorè¡¨æ•°æ®
        truncate_vector_tables (bool): æ˜¯å¦æ¸…ç©ºvectorè¡¨æ•°æ®
        skip_training (bool): æ˜¯å¦è·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†ï¼Œä»…æ‰§è¡ŒVectorè¡¨ç®¡ç†
    
    Returns:
        tuple: (å¤„ç†æˆåŠŸæ ‡å¿—, Vectorè¡¨ç®¡ç†ç»Ÿè®¡ä¿¡æ¯)
    """
    
    # Vectorè¡¨ç®¡ç†ï¼ˆå‰ç½®æ­¥éª¤ï¼‰
    vector_stats = None
    if backup_vector_tables or truncate_vector_tables:
        # æ‰§è¡ŒVectorè¡¨ç®¡ç†...
        vector_stats = asyncio.run(vector_manager.execute_vector_management(...))
        
        # å¦‚æœæ˜¯è·³è¿‡è®­ç»ƒæ¨¡å¼ï¼Œè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†
        if skip_training:
            log_message("âœ… Vectorè¡¨ç®¡ç†å®Œæˆï¼Œè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†ï¼ˆskip_training=Trueï¼‰")
            return True, vector_stats
    elif skip_training:
        # å¦‚æœè®¾ç½®äº†skip_trainingä½†æ²¡æœ‰Vectoræ“ä½œï¼Œè®°å½•è­¦å‘Šå¹¶è·³è¿‡
        log_message("âš ï¸ è®¾ç½®äº†skip_training=Trueä½†æœªæŒ‡å®šVectoræ“ä½œï¼Œè·³è¿‡æ‰€æœ‰å¤„ç†")
        return True, None
    
    # ç»§ç»­è®­ç»ƒæ–‡ä»¶å¤„ç†...
    return process_successful, vector_stats
```

### é‡æ„åçš„è°ƒç”¨é“¾æ¡

#### 1. è„šæœ¬å®Œæ•´æ¨¡å¼
```
schema_workflow.py::main()
â†“
SchemaWorkflowOrchestrator.execute_complete_workflow()
â†“ (åˆ é™¤ç‹¬ç«‹Vectorè¡¨ç®¡ç†è°ƒç”¨)
â†“
_execute_step_4_training_data_load()
â†“
process_training_files(backup_vector_tables=True, truncate_vector_tables=True)
â†“
VectorTableManager.execute_vector_management() + è®­ç»ƒæ–‡ä»¶å¤„ç†
```

#### 2. APIå®Œæ•´æ¨¡å¼
```
APIè¯·æ±‚
â†“
SimpleWorkflowExecutor.execute_complete_workflow()
â†“
SchemaWorkflowOrchestrator.execute_complete_workflow()
â†“ (åˆ é™¤ç‹¬ç«‹Vectorè¡¨ç®¡ç†è°ƒç”¨)
â†“
_execute_step_4_training_data_load()
â†“
process_training_files(backup_vector_tables=True, truncate_vector_tables=True)
â†“
VectorTableManager.execute_vector_management() + è®­ç»ƒæ–‡ä»¶å¤„ç†
```

#### 3. å•æ­¥æ¨¡å¼ï¼ˆè„šæœ¬/APIå®Œå…¨ä¸€è‡´ï¼‰
```
training_loadæ­¥éª¤
â†“
process_training_files(backup_vector_tables=True, truncate_vector_tables=True)
â†“
VectorTableManager.execute_vector_management() + è®­ç»ƒæ–‡ä»¶å¤„ç†
```

#### 4. å•ç‹¬å¤‡ä»½æ¨¡å¼ï¼ˆæ–°åŠŸèƒ½ï¼‰
```
training_loadæ­¥éª¤
â†“
process_training_files(backup_vector_tables=True, skip_training=True)
â†“
VectorTableManager.execute_vector_management()
â†“ (è·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†)
```

## è¯¦ç»†ä¿®æ”¹æ¸…å•

### æ–‡ä»¶1ï¼š`data_pipeline/schema_workflow.py`

#### ä¿®æ”¹1ï¼šåˆ é™¤ç‹¬ç«‹Vectorè¡¨ç®¡ç†è°ƒç”¨
**ä½ç½®**ï¼š`execute_complete_workflow()` æ–¹æ³•ï¼Œçº¦165-167è¡Œ

**åˆ é™¤**ï¼š
```python
# æ–°å¢ï¼šç‹¬ç«‹çš„Vectorè¡¨ç®¡ç†ï¼ˆåœ¨è®­ç»ƒåŠ è½½ä¹‹å‰æˆ–æ›¿ä»£è®­ç»ƒåŠ è½½ï¼‰
if self.backup_vector_tables or self.truncate_vector_tables:
    await self._execute_vector_table_management()
```

#### ä¿®æ”¹2ï¼šä¿®æ”¹training_loadæ­¥éª¤å‚æ•°ä¼ é€’
**ä½ç½®**ï¼š`_execute_step_4_training_data_load()` æ–¹æ³•ï¼Œçº¦454-456è¡Œ

**ä»**ï¼š
```python
# ç¦ç”¨vectorç®¡ç†å‚æ•°ä»¥é¿å…é‡å¤æ‰§è¡Œ
load_successful, _ = process_training_files(training_data_dir, self.task_id, 
                                           backup_vector_tables=False, 
                                           truncate_vector_tables=False)
```

**æ”¹ä¸º**ï¼š
```python
# ä¼ é€’Vectorè¡¨ç®¡ç†å‚æ•°åˆ°trainingæ­¥éª¤
load_successful, vector_stats = process_training_files(training_data_dir, self.task_id, 
                                                       backup_vector_tables=self.backup_vector_tables, 
                                                       truncate_vector_tables=self.truncate_vector_tables)

# è®°å½•Vectorè¡¨ç®¡ç†ç»“æœåˆ°å·¥ä½œæµçŠ¶æ€
if vector_stats:
    self.workflow_state["artifacts"]["vector_management"] = vector_stats
```

#### ä¿®æ”¹3ï¼šæ›´æ–°æ³¨é‡Šå’Œæ–‡æ¡£
æ›´æ–°ç›¸å…³æ–¹æ³•çš„æ³¨é‡Šï¼Œè¯´æ˜Vectorè¡¨ç®¡ç†ç°åœ¨ç»Ÿä¸€åœ¨trainingæ­¥éª¤ä¸­æ‰§è¡Œã€‚

### æ–‡ä»¶2ï¼š`data_pipeline/trainer/run_training.py`

#### ä¿®æ”¹1ï¼šå‡½æ•°ç­¾åæ‰©å±•
**ä½ç½®**ï¼š`process_training_files()` å‡½æ•°å®šä¹‰ï¼Œçº¦336è¡Œ

**ä»**ï¼š
```python
def process_training_files(data_path, task_id=None, backup_vector_tables=False, truncate_vector_tables=False):
```

**æ”¹ä¸º**ï¼š
```python
def process_training_files(data_path, task_id=None, backup_vector_tables=False, truncate_vector_tables=False, skip_training=False):
```

#### ä¿®æ”¹2ï¼šè¿”å›å€¼ä¿®æ”¹
**ä½ç½®**ï¼šå‡½æ•°ç»“å°¾ï¼Œçº¦463è¡Œ

**ä»**ï¼š
```python
return process_successful
```

**æ”¹ä¸º**ï¼š
```python
return process_successful, vector_stats
```

#### ä¿®æ”¹3ï¼šæ”¯æŒskip_trainingå‚æ•°
**ä½ç½®**ï¼šVectorè¡¨ç®¡ç†ä»£ç å—ä¹‹å

**æ·»åŠ **ï¼š
```python
# å¦‚æœæ˜¯è·³è¿‡è®­ç»ƒæ¨¡å¼ï¼Œè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†
if skip_training:
    log_message("âœ… Vectorè¡¨ç®¡ç†å®Œæˆï¼Œè·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†ï¼ˆskip_training=Trueï¼‰")
    return True, vector_stats
elif skip_training and not (backup_vector_tables or truncate_vector_tables):
    # å¦‚æœè®¾ç½®äº†skip_trainingä½†æ²¡æœ‰Vectoræ“ä½œï¼Œè®°å½•è­¦å‘Šå¹¶è·³è¿‡
    log_message("âš ï¸ è®¾ç½®äº†skip_training=Trueä½†æœªæŒ‡å®šVectoræ“ä½œï¼Œè·³è¿‡æ‰€æœ‰å¤„ç†")
    return True, None
```

#### ä¿®æ”¹4ï¼šæ›´æ–°mainå‡½æ•°è°ƒç”¨
**ä½ç½®**ï¼š`main()` å‡½æ•°ä¸­è°ƒç”¨process_training_filesçš„åœ°æ–¹

**ä»**ï¼š
```python
process_successful = process_training_files(data_path, args.task_id, 
                                           args.backup_vector_tables, 
                                           args.truncate_vector_tables)
```

**æ”¹ä¸º**ï¼š
```python
process_successful, vector_stats = process_training_files(data_path, args.task_id, 
                                                         args.backup_vector_tables, 
                                                         args.truncate_vector_tables)
```

### æ–‡ä»¶3ï¼š`data_pipeline/api/simple_workflow.py`

#### æ— éœ€ä¿®æ”¹
APIå±‚é¢ä¸éœ€è¦ä¿®æ”¹ï¼Œå› ä¸ºå‚æ•°ä¼ é€’å·²ç»æ­£ç¡®å®ç°ï¼Œä¿®æ”¹åº•å±‚çš„ `_execute_step_4_training_data_load()` å³å¯ã€‚

## æ–°å¢åŠŸèƒ½

### 1. skip_trainingå‚æ•°

**ç”¨é€”**ï¼šå…è®¸è·³è¿‡è®­ç»ƒæ–‡ä»¶å¤„ç†ï¼Œä»…æ‰§è¡ŒVectorè¡¨ç®¡ç†

**ä½¿ç”¨åœºæ™¯**ï¼š
- å•ç‹¬å¤‡ä»½Vectorè¡¨æ•°æ®
- å•ç‹¬æ¸…ç©ºVectorè¡¨æ•°æ®
- åœ¨ä¸éœ€è¦é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ç®¡ç†Vectorè¡¨

**APIä½¿ç”¨ç¤ºä¾‹**ï¼š
```json
// ä»…å¤‡ä»½Vectorè¡¨
{
    "execution_mode": "step",
    "step_name": "training_load", 
    "backup_vector_tables": true,
    "skip_training": true
}

// æ¸…ç©ºVectorè¡¨ï¼ˆè‡ªåŠ¨åŒ…å«å¤‡ä»½ï¼‰
{
    "execution_mode": "step",
    "step_name": "training_load", 
    "truncate_vector_tables": true,
    "skip_training": true
}
```

**è„šæœ¬ä½¿ç”¨ç¤ºä¾‹**ï¼š
```bash
# ä»…å¤‡ä»½Vectorè¡¨
python -m data_pipeline.trainer.run_training \
  --task-id manual_20250720_130541 \
  --backup-vector-tables \
  --skip-training

# æ¸…ç©ºVectorè¡¨ï¼ˆè‡ªåŠ¨åŒ…å«å¤‡ä»½ï¼‰
python -m data_pipeline.trainer.run_training \
  --task-id manual_20250720_130541 \
  --truncate-vector-tables \
  --skip-training
```

### 2. ç»Ÿä¸€çš„è¿”å›å€¼æ ¼å¼

é‡æ„åï¼Œæ‰€æœ‰è°ƒç”¨è·¯å¾„éƒ½è¿”å›ç›¸åŒæ ¼å¼çš„Vectorè¡¨ç®¡ç†ç»Ÿè®¡ä¿¡æ¯ï¼š

```python
{
    "backup_performed": true,
    "truncate_performed": true,
    "tables_backed_up": {
        "langchain_pg_collection": {
            "row_count": 1234,
            "file_size": "45.6 KB",
            "backup_file": "langchain_pg_collection_20250720_121007.csv"
        },
        "langchain_pg_embedding": {
            "row_count": 12345,
            "file_size": "2.1 MB",
            "backup_file": "langchain_pg_embedding_20250720_121007.csv"
        }
    },
    "truncate_results": {
        "langchain_pg_embedding": {
            "success": true,
            "rows_before": 12345,
            "rows_after": 0
        }
    },
    "duration": 12.5,
    "backup_directory": "/path/to/task/vector_bak"
}
```

## çº¦æŸå’Œé™åˆ¶

### 1. åˆç†çº¦æŸ

**è·³è¿‡training_loadæ­¥éª¤æ—¶æ— æ³•æ‰§è¡ŒVectorè¡¨ç®¡ç†**

è¿™ä¸ªçº¦æŸæ˜¯åˆç†çš„ï¼Œå› ä¸ºï¼š
- Vectorè¡¨æ“ä½œæœ¬è´¨ä¸Šæ˜¯è®­ç»ƒå‡†å¤‡å·¥ä½œ
- ä¸è®­ç»ƒå°±ä¸éœ€è¦å¤‡ä»½å’Œæ¸…ç©ºVectorè¡¨
- ä¿æŒåŠŸèƒ½çš„é€»è¾‘ä¸€è‡´æ€§

**ç¤ºä¾‹**ï¼š
```bash
# è¿™ç§æƒ…å†µä¸‹ä¸ä¼šæ‰§è¡ŒVectorè¡¨ç®¡ç†ï¼ˆåˆç†ï¼Œå› ä¸ºåˆ é™¤äº†--skip-training-loadå‚æ•°ï¼‰
python -m data_pipeline.schema_workflow \
  --db-connection "..." \
  --table-list tables.txt \
  --business-context "ç³»ç»Ÿ" \
  --backup-vector-tables  # ä¼šåœ¨training_loadæ­¥éª¤ä¸­æ‰§è¡Œ
```

### 2. å…¼å®¹æ€§å˜åŒ–

**âš ï¸ ç ´åæ€§å˜åŒ–**ï¼š
- **åˆ é™¤** `--skip-training-load` å‚æ•°ï¼Œæ”¹ä¸º `--skip-training`
- åŸæœ‰ä½¿ç”¨ `--skip-training-load` çš„è„šæœ¬éœ€è¦æ›´æ–°

**å‘åå…¼å®¹**ï¼š
- ç°æœ‰çš„APIè°ƒç”¨ä¸å—å½±å“ï¼ˆé™¤äº†æ–°å¢å‚æ•°æ”¯æŒï¼‰
- æ–°å¢çš„ `skip_training` å‚æ•°é»˜è®¤ä¸º `False`

**è¡Œä¸ºå˜åŒ–**ï¼š
- å®Œæ•´æ¨¡å¼ä¸­Vectorè¡¨ç®¡ç†çš„æ‰§è¡Œæ—¶æœºå˜åŒ–ï¼ˆä»ç‹¬ç«‹æ‰§è¡Œæ”¹ä¸ºåœ¨trainingæ­¥éª¤ä¸­æ‰§è¡Œï¼‰
- å¯¹ç”¨æˆ·æ¥è¯´åŠŸèƒ½å’Œç»“æœå®Œå…¨ä¸€è‡´

## æµ‹è¯•éªŒè¯

### 1. åŠŸèƒ½æµ‹è¯•

#### è„šæœ¬æ¨¡å¼æµ‹è¯•
```bash
# å®Œæ•´æ¨¡å¼ + Vectorè¡¨ç®¡ç†
python -m data_pipeline.schema_workflow \
  --db-connection "postgresql://..." \
  --table-list tables.txt \
  --business-context "æµ‹è¯•ç³»ç»Ÿ" \
  --backup-vector-tables \
  --truncate-vector-tables

# å•æ­¥æ¨¡å¼ + Vectorè¡¨ç®¡ç†
python -m data_pipeline.trainer.run_training \
  --task-id task_20250721_113010 \
  --backup-vector-tables

# ä»…å¤‡ä»½Vectorè¡¨ï¼ˆä¸æ¸…ç©ºæ•°æ®ï¼‰
python -m data_pipeline.trainer.run_training \
  --task-id task_20250721_113010 \
  --backup-vector-tables \
  --skip-training

# æ¸…ç©ºVectorè¡¨ï¼ˆè‡ªåŠ¨åŒ…å«å¤‡ä»½ï¼‰
python -m data_pipeline.trainer.run_training \
  --task-id task_20250721_113010 \
  --truncate-vector-tables \
  --skip-training

# âŒ é”™è¯¯ç¤ºä¾‹ï¼šä¸è¦åŒæ—¶æŒ‡å®šä¸¤ä¸ªå‚æ•°
# python -m data_pipeline.trainer.run_training \
#   --task-id task_20250721_113010 \
#   --backup-vector-tables \
#   --truncate-vector-tables \
#   --skip-training
```

#### APIæ¨¡å¼æµ‹è¯•
```bash
# å®Œæ•´æ¨¡å¼ + æ¸…ç©ºVectorè¡¨ï¼ˆåŒ…å«è‡ªåŠ¨å¤‡ä»½ï¼‰
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "complete",
    "truncate_vector_tables": true
  }'

# å•æ­¥æ¨¡å¼ + ä»…å¤‡ä»½Vectorè¡¨
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "step",
    "step_name": "training_load",
    "backup_vector_tables": true
  }'

# ä»…å¤‡ä»½Vectorè¡¨ï¼Œè·³è¿‡è®­ç»ƒ
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "step",
    "step_name": "training_load",
    "backup_vector_tables": true,
    "skip_training": true
  }'

# æ¸…ç©ºVectorè¡¨ï¼Œè·³è¿‡è®­ç»ƒï¼ˆè‡ªåŠ¨åŒ…å«å¤‡ä»½ï¼‰
curl -X POST http://localhost:8084/api/v0/data_pipeline/tasks/task_20250721_113010/execute \
  -H "Content-Type: application/json" \
  -d '{
    "execution_mode": "step",
    "step_name": "training_load",
    "truncate_vector_tables": true,
    "skip_training": true
  }'
```

### 2. å›å½’æµ‹è¯•

**éªŒè¯ç‚¹**ï¼š
- ç°æœ‰åŠŸèƒ½ä¸å—å½±å“
- Vectorè¡¨ç®¡ç†åŠŸèƒ½æ­£å¸¸å·¥ä½œ
- å¤‡ä»½æ–‡ä»¶ä½ç½®å’Œæ ¼å¼æ­£ç¡®
- æ—¥å¿—è®°å½•å®Œæ•´
- é”™è¯¯å¤„ç†æ­£å¸¸

## å®æ–½è®¡åˆ’

### é˜¶æ®µ1ï¼šæ ¸å¿ƒé‡æ„
1. ä¿®æ”¹ `data_pipeline/schema_workflow.py`
2. ä¿®æ”¹ `data_pipeline/trainer/run_training.py`
3. åŸºç¡€åŠŸèƒ½æµ‹è¯•

### é˜¶æ®µ2ï¼šåŠŸèƒ½å¢å¼º
1. æ·»åŠ  `skip_training` å‚æ•°æ”¯æŒ
2. åˆ é™¤ `--skip-training-load` å‚æ•°
3. å®Œå–„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
4. æ›´æ–°ç›¸å…³æ–‡æ¡£

### é˜¶æ®µ3ï¼šå…¨é¢æµ‹è¯•
1. è„šæœ¬æ¨¡å¼æµ‹è¯•
2. APIæ¨¡å¼æµ‹è¯•
3. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
4. å›å½’æµ‹è¯•

### é˜¶æ®µ4ï¼šæ–‡æ¡£æ›´æ–°
1. æ›´æ–°ç”¨æˆ·æ–‡æ¡£
2. æ›´æ–°APIæ–‡æ¡£
3. æ›´æ–°å¼€å‘æ–‡æ¡£

## é¢„æœŸæ•ˆæœ

### 1. ä»£ç è´¨é‡æå‡
- æ¶ˆé™¤é‡å¤å®ç°
- ç®€åŒ–è°ƒç”¨é€»è¾‘
- æé«˜ä»£ç å¯ç»´æŠ¤æ€§

### 2. ç”¨æˆ·ä½“éªŒæ”¹å–„
- è„šæœ¬æ¨¡å¼å’ŒAPIæ¨¡å¼è¡Œä¸ºä¸€è‡´
- åŠŸèƒ½é€»è¾‘æ›´åŠ æ¸…æ™°
- æ”¯æŒæ›´çµæ´»çš„ä½¿ç”¨åœºæ™¯

### 3. ç³»ç»Ÿæ¶æ„ä¼˜åŒ–
- èŒè´£åˆ†ç¦»æ›´æ¸…æ™°
- æ¨¡å—é—´è€¦åˆåº¦é™ä½
- æ‰©å±•æ€§æ›´å¥½

## é£é™©è¯„ä¼°

### 1. ä½é£é™©
- ä¸»è¦æ˜¯å†…éƒ¨å®ç°è°ƒæ•´
- å¯¹å¤–æ¥å£ä¿æŒå…¼å®¹
- æ ¸å¿ƒåŠŸèƒ½é€»è¾‘ä¸å˜

### 2. é£é™©æ§åˆ¶
- åˆ†é˜¶æ®µå®æ–½
- å……åˆ†æµ‹è¯•éªŒè¯
- ä¿ç•™å›æ»šæœºåˆ¶

### 3. åº”æ€¥é¢„æ¡ˆ
- ä¿ç•™åŸæœ‰ä»£ç å¤‡ä»½
- å‡†å¤‡å¿«é€Ÿå›æ»šæ–¹æ¡ˆ
- ç›‘æ§é‡è¦æŒ‡æ ‡

## æ€»ç»“

æœ¬æ¬¡é‡æ„å°†å®ç°Vectorè¡¨ç®¡ç†åŠŸèƒ½çš„ç»Ÿä¸€åŒ–ï¼Œè§£å†³å½“å‰è„šæœ¬æ¨¡å¼å’ŒAPIæ¨¡å¼è¡Œä¸ºä¸ä¸€è‡´çš„é—®é¢˜ï¼ŒåŒæ—¶ç®€åŒ–ä»£ç ç»“æ„ï¼Œæé«˜ç³»ç»Ÿçš„å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ã€‚é‡æ„åçš„ç³»ç»Ÿå°†å…·æœ‰æ›´æ¸…æ™°çš„èŒè´£åˆ†ç¦»å’Œæ›´ä¸€è‡´çš„ç”¨æˆ·ä½“éªŒã€‚ 