#!/usr/bin/env python3
"""
ç‹¬ç«‹æµ‹è¯•Vectorè¡¨å¤‡ä»½åŠŸèƒ½
åªå¤‡ä»½langchain_pg_collectionå’Œlangchain_pg_embeddingè¡¨
"""

import asyncio
import os
from pathlib import Path
from datetime import datetime


async def test_vector_backup():
    """æµ‹è¯•vectorè¡¨å¤‡ä»½åŠŸèƒ½"""
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•Vectorè¡¨å¤‡ä»½åŠŸèƒ½...")
    print("=" * 50)
    
    # 1. è®¾ç½®æµ‹è¯•è¾“å‡ºç›®å½•
    test_dir = Path("./test_vector_backup_output")
    test_dir.mkdir(exist_ok=True)
    
    print(f"ğŸ“ æµ‹è¯•è¾“å‡ºç›®å½•: {test_dir.resolve()}")
    
    try:
        # 2. å¯¼å…¥VectorTableManager
        from data_pipeline.trainer.vector_table_manager import VectorTableManager
        
        # 3. åˆ›å»ºç®¡ç†å™¨å®ä¾‹
        task_id = f"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        vector_manager = VectorTableManager(
            task_output_dir=str(test_dir), 
            task_id=task_id
        )
        
        print(f"ğŸ†” ä»»åŠ¡ID: {task_id}")
        print("ğŸ”§ VectorTableManager åˆ›å»ºæˆåŠŸ")
        
        # 4. æ‰§è¡Œå¤‡ä»½ï¼ˆåªå¤‡ä»½ï¼Œä¸æ¸…ç©ºï¼‰
        print("\nğŸ—‚ï¸ å¼€å§‹æ‰§è¡Œå¤‡ä»½...")
        result = await vector_manager.execute_vector_management(
            backup=True,    # æ‰§è¡Œå¤‡ä»½
            truncate=False  # ä¸æ¸…ç©ºè¡¨
        )
        
        # 5. æ˜¾ç¤ºç»“æœ
        print("\nğŸ“Š å¤‡ä»½ç»“æœ:")
        print("=" * 30)
        
        if result.get("backup_performed", False):
            print("âœ… å¤‡ä»½çŠ¶æ€: å·²æ‰§è¡Œ")
            
            tables_info = result.get("tables_backed_up", {})
            for table_name, info in tables_info.items():
                if info.get("success", False):
                    print(f"  âœ… {table_name}: {info['row_count']}è¡Œ -> {info['backup_file']} ({info['file_size']})")
                else:
                    print(f"  âŒ {table_name}: å¤±è´¥ - {info.get('error', 'æœªçŸ¥é”™è¯¯')}")
        else:
            print("âŒ å¤‡ä»½çŠ¶æ€: æœªæ‰§è¡Œ")
        
        duration = result.get("duration", 0)
        print(f"â±ï¸  æ€»è€—æ—¶: {duration:.2f}ç§’")
        
        errors = result.get("errors", [])
        if errors:
            print(f"âš ï¸  é”™è¯¯ä¿¡æ¯: {'; '.join(errors)}")
        
        # 6. æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        backup_dir = test_dir / "vector_bak"
        if backup_dir.exists():
            print(f"\nğŸ“‚ å¤‡ä»½æ–‡ä»¶ç›®å½•: {backup_dir.resolve()}")
            backup_files = list(backup_dir.glob("*.csv"))
            if backup_files:
                print("ğŸ“„ ç”Ÿæˆçš„å¤‡ä»½æ–‡ä»¶:")
                for file in backup_files:
                    file_size = file.stat().st_size
                    print(f"  ğŸ“„ {file.name} ({file_size} bytes)")
            else:
                print("âš ï¸  æœªæ‰¾åˆ°CSVå¤‡ä»½æ–‡ä»¶")
                
            log_files = list(backup_dir.glob("*.txt"))
            if log_files:
                print("ğŸ“‹ æ—¥å¿—æ–‡ä»¶:")
                for file in log_files:
                    print(f"  ğŸ“‹ {file.name}")
        else:
            print("âŒ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨")
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("Vectorè¡¨å¤‡ä»½åŠŸèƒ½ç‹¬ç«‹æµ‹è¯•")
    print("æµ‹è¯•ç›®æ ‡: langchain_pg_collection, langchain_pg_embedding")
    print("æ•°æ®åº“: ä» data_pipeline.config è‡ªåŠ¨è·å–è¿æ¥é…ç½®")
    print()
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    success = asyncio.run(test_vector_backup())
    
    if success:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        exit(0)
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥!")
        exit(1)


if __name__ == "__main__":
    main() 