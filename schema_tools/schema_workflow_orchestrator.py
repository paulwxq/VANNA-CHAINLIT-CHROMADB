"""
Schemaå·¥ä½œæµç¼–æ’å™¨
ç»Ÿä¸€ç®¡ç†å®Œæ•´çš„æ•°æ®åº“Schemaå¤„ç†æµç¨‹
"""

import asyncio
import time
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path
from datetime import datetime

from schema_tools.training_data_agent import SchemaTrainingDataAgent
from schema_tools.qs_agent import QuestionSQLGenerationAgent
from schema_tools.sql_validation_agent import SQLValidationAgent
from schema_tools.config import SCHEMA_TOOLS_CONFIG
from schema_tools.utils.logger import setup_logging


class SchemaWorkflowOrchestrator:
    """ç«¯åˆ°ç«¯çš„Schemaå¤„ç†ç¼–æ’å™¨ - å®Œæ•´å·¥ä½œæµç¨‹"""
    
    def __init__(self, 
                 db_connection: str,
                 table_list_file: str,
                 business_context: str,
                 db_name: str,
                 output_dir: str = None,
                 enable_sql_validation: bool = True,
                 enable_llm_repair: bool = True,
                 modify_original_file: bool = True):
        """
        åˆå§‹åŒ–Schemaå·¥ä½œæµç¼–æ’å™¨
        
        Args:
            db_connection: æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
            table_list_file: è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„
            business_context: ä¸šåŠ¡ä¸Šä¸‹æ–‡æè¿°
            db_name: æ•°æ®åº“åç§°ï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰
            output_dir: è¾“å‡ºç›®å½•
            enable_sql_validation: æ˜¯å¦å¯ç”¨SQLéªŒè¯
            enable_llm_repair: æ˜¯å¦å¯ç”¨LLMä¿®å¤åŠŸèƒ½
            modify_original_file: æ˜¯å¦ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶
        """
        self.db_connection = db_connection
        self.table_list_file = table_list_file
        self.business_context = business_context
        self.db_name = db_name
        self.output_dir = Path(output_dir) if output_dir else Path("./output")
        self.enable_sql_validation = enable_sql_validation
        self.enable_llm_repair = enable_llm_repair
        self.modify_original_file = modify_original_file
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = logging.getLogger("schema_tools.SchemaWorkflowOrchestrator")
        
        # å·¥ä½œæµç¨‹çŠ¶æ€
        self.workflow_state = {
            "start_time": None,
            "end_time": None,
            "current_step": None,
            "completed_steps": [],
            "failed_steps": [],
            "artifacts": {},  # å­˜å‚¨å„æ­¥éª¤äº§ç”Ÿçš„æ–‡ä»¶
            "statistics": {}
        }
    
    async def execute_complete_workflow(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„Schemaå¤„ç†å·¥ä½œæµç¨‹
        
        Returns:
            å®Œæ•´çš„å·¥ä½œæµç¨‹æŠ¥å‘Š
        """
        self.workflow_state["start_time"] = time.time()
        self.logger.info("ğŸš€ å¼€å§‹æ‰§è¡ŒSchemaå·¥ä½œæµç¼–æ’")
        self.logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        self.logger.info(f"ğŸ¢ ä¸šåŠ¡èƒŒæ™¯: {self.business_context}")
        self.logger.info(f"ğŸ’¾ æ•°æ®åº“: {self.db_name}")
        
        try:
            # æ­¥éª¤1: ç”ŸæˆDDLå’ŒMDæ–‡ä»¶
            await self._execute_step_1_ddl_md_generation()
            
            # æ­¥éª¤2: ç”ŸæˆQuestion-SQLå¯¹
            await self._execute_step_2_question_sql_generation()
            
            # æ­¥éª¤3: éªŒè¯å’Œä¿®æ­£SQLï¼ˆå¯é€‰ï¼‰
            if self.enable_sql_validation:
                await self._execute_step_3_sql_validation()
            else:
                self.logger.info("â­ï¸ è·³è¿‡SQLéªŒè¯æ­¥éª¤")
            
            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            final_report = await self._generate_final_report()
            
            self.workflow_state["end_time"] = time.time()
            self.logger.info("âœ… Schemaå·¥ä½œæµç¼–æ’å®Œæˆ")
            
            return final_report
            
        except Exception as e:
            self.workflow_state["end_time"] = time.time()
            self.logger.exception(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
            
            error_report = await self._generate_error_report(e)
            return error_report
    
    async def _execute_step_1_ddl_md_generation(self):
        """æ­¥éª¤1: ç”ŸæˆDDLå’ŒMDæ–‡ä»¶"""
        self.workflow_state["current_step"] = "ddl_md_generation"
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“ æ­¥éª¤1: å¼€å§‹ç”ŸæˆDDLå’ŒMDæ–‡ä»¶")
        self.logger.info("=" * 60)
        
        step_start_time = time.time()
        
        try:
            # åˆ›å»ºDDL/MDç”ŸæˆAgent
            ddl_md_agent = SchemaTrainingDataAgent(
                db_connection=self.db_connection,
                table_list_file=self.table_list_file,
                business_context=self.business_context,
                output_dir=str(self.output_dir),
                pipeline="full"
            )
            
            # æ‰§è¡ŒDDL/MDç”Ÿæˆ
            ddl_md_result = await ddl_md_agent.generate_training_data()
            
            step_duration = time.time() - step_start_time
            
            # è®°å½•ç»“æœ
            self.workflow_state["completed_steps"].append("ddl_md_generation")
            self.workflow_state["artifacts"]["ddl_md_generation"] = {
                "total_tables": ddl_md_result.get("summary", {}).get("total_tables", 0),
                "processed_successfully": ddl_md_result.get("summary", {}).get("processed_successfully", 0),
                "failed": ddl_md_result.get("summary", {}).get("failed", 0),
                "files_generated": ddl_md_result.get("statistics", {}).get("files_generated", 0),
                "duration": step_duration
            }
            self.workflow_state["statistics"]["step1_duration"] = step_duration
            
            processed_tables = ddl_md_result.get("summary", {}).get("processed_successfully", 0)
            self.logger.info(f"âœ… æ­¥éª¤1å®Œæˆ: æˆåŠŸå¤„ç† {processed_tables} ä¸ªè¡¨ï¼Œè€—æ—¶ {step_duration:.2f}ç§’")
            
        except Exception as e:
            self.workflow_state["failed_steps"].append("ddl_md_generation")
            self.logger.error(f"âŒ æ­¥éª¤1å¤±è´¥: {str(e)}")
            raise
    
    async def _execute_step_2_question_sql_generation(self):
        """æ­¥éª¤2: ç”ŸæˆQuestion-SQLå¯¹"""
        self.workflow_state["current_step"] = "question_sql_generation"
        self.logger.info("=" * 60)
        self.logger.info("ğŸ¤– æ­¥éª¤2: å¼€å§‹ç”ŸæˆQuestion-SQLå¯¹")
        self.logger.info("=" * 60)
        
        step_start_time = time.time()
        
        try:
            # åˆ›å»ºQuestion-SQLç”ŸæˆAgent
            qs_agent = QuestionSQLGenerationAgent(
                output_dir=str(self.output_dir),
                table_list_file=self.table_list_file,
                business_context=self.business_context,
                db_name=self.db_name
            )
            
            # æ‰§è¡ŒQuestion-SQLç”Ÿæˆ
            qs_result = await qs_agent.generate()
            
            step_duration = time.time() - step_start_time
            
            # è®°å½•ç»“æœ
            self.workflow_state["completed_steps"].append("question_sql_generation")
            self.workflow_state["artifacts"]["question_sql_generation"] = {
                "output_file": str(qs_result.get("output_file", "")),
                "total_questions": qs_result.get("total_questions", 0),
                "total_themes": qs_result.get("total_themes", 0),
                "successful_themes": qs_result.get("successful_themes", 0),
                "failed_themes": qs_result.get("failed_themes", []),
                "duration": step_duration
            }
            self.workflow_state["statistics"]["step2_duration"] = step_duration
            
            total_questions = qs_result.get("total_questions", 0)
            self.logger.info(f"âœ… æ­¥éª¤2å®Œæˆ: ç”Ÿæˆäº† {total_questions} ä¸ªé—®ç­”å¯¹ï¼Œè€—æ—¶ {step_duration:.2f}ç§’")
            
        except Exception as e:
            self.workflow_state["failed_steps"].append("question_sql_generation")
            self.logger.error(f"âŒ æ­¥éª¤2å¤±è´¥: {str(e)}")
            raise
    
    async def _execute_step_3_sql_validation(self):
        """æ­¥éª¤3: éªŒè¯å’Œä¿®æ­£SQL"""
        self.workflow_state["current_step"] = "sql_validation"
        self.logger.info("=" * 60)
        self.logger.info("ğŸ” æ­¥éª¤3: å¼€å§‹éªŒè¯å’Œä¿®æ­£SQL")
        self.logger.info("=" * 60)
        
        step_start_time = time.time()
        
        try:
            # è·å–æ­¥éª¤2ç”Ÿæˆçš„æ–‡ä»¶
            qs_artifacts = self.workflow_state["artifacts"].get("question_sql_generation", {})
            qs_file = qs_artifacts.get("output_file")
            
            if not qs_file or not Path(qs_file).exists():
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°Question-SQLæ–‡ä»¶: {qs_file}")
            
            self.logger.info(f"ğŸ“„ éªŒè¯æ–‡ä»¶: {qs_file}")
            
            # åŠ¨æ€è®¾ç½®éªŒè¯é…ç½®
            SCHEMA_TOOLS_CONFIG['sql_validation']['enable_sql_repair'] = self.enable_llm_repair
            SCHEMA_TOOLS_CONFIG['sql_validation']['modify_original_file'] = self.modify_original_file
            
            # åˆ›å»ºSQLéªŒè¯Agent
            sql_validator = SQLValidationAgent(
                db_connection=self.db_connection,
                input_file=str(qs_file),
                output_dir=str(self.output_dir)
            )
            
            # æ‰§è¡ŒSQLéªŒè¯å’Œä¿®æ­£
            validation_result = await sql_validator.validate()
            
            step_duration = time.time() - step_start_time
            
            # è®°å½•ç»“æœ
            self.workflow_state["completed_steps"].append("sql_validation")
            
            summary = validation_result.get("summary", {})
            self.workflow_state["artifacts"]["sql_validation"] = {
                "original_sql_count": summary.get("total_questions", 0),
                "valid_sql_count": summary.get("valid_sqls", 0),
                "invalid_sql_count": summary.get("invalid_sqls", 0),
                "success_rate": summary.get("success_rate", 0),
                "repair_stats": summary.get("repair_stats", {}),
                "file_modification_stats": summary.get("file_modification_stats", {}),
                "average_execution_time": summary.get("average_execution_time", 0),
                "total_retries": summary.get("total_retries", 0),
                "duration": step_duration
            }
            self.workflow_state["statistics"]["step3_duration"] = step_duration
            
            success_rate = summary.get("success_rate", 0)
            valid_count = summary.get("valid_sqls", 0)
            total_count = summary.get("total_questions", 0)
            
            self.logger.info(f"âœ… æ­¥éª¤3å®Œæˆ: SQLéªŒè¯æˆåŠŸç‡ {success_rate:.1%} ({valid_count}/{total_count})ï¼Œè€—æ—¶ {step_duration:.2f}ç§’")
            
            # æ˜¾ç¤ºä¿®å¤ç»Ÿè®¡
            repair_stats = summary.get("repair_stats", {})
            if repair_stats.get("attempted", 0) > 0:
                self.logger.info(f"ğŸ”§ ä¿®å¤ç»Ÿè®¡: å°è¯• {repair_stats['attempted']}ï¼ŒæˆåŠŸ {repair_stats['successful']}ï¼Œå¤±è´¥ {repair_stats['failed']}")
            
            # æ˜¾ç¤ºæ–‡ä»¶ä¿®æ”¹ç»Ÿè®¡
            file_stats = summary.get("file_modification_stats", {})
            if file_stats.get("modified", 0) > 0 or file_stats.get("deleted", 0) > 0:
                self.logger.info(f"ğŸ“ æ–‡ä»¶ä¿®æ”¹: æ›´æ–° {file_stats.get('modified', 0)} ä¸ªSQLï¼Œåˆ é™¤ {file_stats.get('deleted', 0)} ä¸ªæ— æ•ˆé¡¹")
            
        except Exception as e:
            self.workflow_state["failed_steps"].append("sql_validation")
            self.logger.error(f"âŒ æ­¥éª¤3å¤±è´¥: {str(e)}")
            raise
    
    async def _generate_final_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆå·¥ä½œæµç¨‹æŠ¥å‘Š"""
        total_duration = self.workflow_state["end_time"] - self.workflow_state["start_time"]
        
        # è®¡ç®—æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
        qs_artifacts = self.workflow_state["artifacts"].get("question_sql_generation", {})
        final_output_file = qs_artifacts.get("output_file", "")
        
        # è®¡ç®—æœ€ç»ˆé—®é¢˜æ•°é‡
        if "sql_validation" in self.workflow_state["artifacts"]:
            # å¦‚æœæœ‰éªŒè¯æ­¥éª¤ï¼Œä½¿ç”¨éªŒè¯åçš„æ•°é‡
            validation_artifacts = self.workflow_state["artifacts"]["sql_validation"]
            final_question_count = validation_artifacts.get("valid_sql_count", 0)
        else:
            # å¦åˆ™ä½¿ç”¨ç”Ÿæˆçš„æ•°é‡
            final_question_count = qs_artifacts.get("total_questions", 0)
        
        report = {
            "success": True,
            "workflow_summary": {
                "total_duration": round(total_duration, 2),
                "completed_steps": self.workflow_state["completed_steps"],
                "failed_steps": self.workflow_state["failed_steps"],
                "total_steps": len(self.workflow_state["completed_steps"]),
                "workflow_started": datetime.fromtimestamp(self.workflow_state["start_time"]).isoformat(),
                "workflow_completed": datetime.fromtimestamp(self.workflow_state["end_time"]).isoformat()
            },
            "input_parameters": {
                "db_connection": self._mask_connection_string(self.db_connection),
                "table_list_file": self.table_list_file,
                "business_context": self.business_context,
                "db_name": self.db_name,
                "output_directory": str(self.output_dir),
                "enable_sql_validation": self.enable_sql_validation,
                "enable_llm_repair": self.enable_llm_repair,
                "modify_original_file": self.modify_original_file
            },
            "processing_results": {
                "ddl_md_generation": self.workflow_state["artifacts"].get("ddl_md_generation", {}),
                "question_sql_generation": self.workflow_state["artifacts"].get("question_sql_generation", {}),
                "sql_validation": self.workflow_state["artifacts"].get("sql_validation", {})
            },
            "final_outputs": {
                "primary_output_file": final_output_file,
                "output_directory": str(self.output_dir),
                "final_question_count": final_question_count,
                "backup_files_created": self.modify_original_file
            },
            "performance_metrics": {
                "step1_duration": round(self.workflow_state["statistics"].get("step1_duration", 0), 2),
                "step2_duration": round(self.workflow_state["statistics"].get("step2_duration", 0), 2),
                "step3_duration": round(self.workflow_state["statistics"].get("step3_duration", 0), 2),
                "total_duration": round(total_duration, 2)
            }
        }
        
        return report
    
    async def _generate_error_report(self, error: Exception) -> Dict[str, Any]:
        """ç”Ÿæˆé”™è¯¯æŠ¥å‘Š"""
        total_duration = self.workflow_state["end_time"] - self.workflow_state["start_time"]
        
        return {
            "success": False,
            "error": {
                "message": str(error),
                "type": type(error).__name__,
                "failed_step": self.workflow_state["current_step"]
            },
            "workflow_summary": {
                "total_duration": round(total_duration, 2),
                "completed_steps": self.workflow_state["completed_steps"],
                "failed_steps": self.workflow_state["failed_steps"],
                "workflow_started": datetime.fromtimestamp(self.workflow_state["start_time"]).isoformat() if self.workflow_state["start_time"] else None,
                "workflow_failed": datetime.fromtimestamp(self.workflow_state["end_time"]).isoformat() if self.workflow_state["end_time"] else None
            },
            "partial_results": self.workflow_state["artifacts"],
            "input_parameters": {
                "db_connection": self._mask_connection_string(self.db_connection),
                "table_list_file": self.table_list_file,
                "business_context": self.business_context,
                "db_name": self.db_name,
                "output_directory": str(self.output_dir)
            }
        }
    
    def _mask_connection_string(self, conn_str: str) -> str:
        """éšè—è¿æ¥å­—ç¬¦ä¸²ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
        import re
        return re.sub(r':[^:@]+@', ':***@', conn_str)
    
    def print_final_summary(self, report: Dict[str, Any]):
        """æ‰“å°æœ€ç»ˆæ‘˜è¦"""
        self.logger.info("=" * 80)
        self.logger.info("ğŸ“Š å·¥ä½œæµç¨‹æ‰§è¡Œæ‘˜è¦")
        self.logger.info("=" * 80)
        
        if report["success"]:
            summary = report["workflow_summary"]
            results = report["processing_results"]
            outputs = report["final_outputs"]
            metrics = report["performance_metrics"]
            
            self.logger.info(f"âœ… å·¥ä½œæµç¨‹æ‰§è¡ŒæˆåŠŸ")
            self.logger.info(f"â±ï¸  æ€»è€—æ—¶: {summary['total_duration']} ç§’")
            self.logger.info(f"ğŸ“ å®Œæˆæ­¥éª¤: {len(summary['completed_steps'])}/{summary['total_steps']}")
            
            # DDL/MDç”Ÿæˆç»“æœ
            if "ddl_md_generation" in results:
                ddl_md = results["ddl_md_generation"]
                self.logger.info(f"ğŸ“‹ DDL/MDç”Ÿæˆ: {ddl_md.get('processed_successfully', 0)} ä¸ªè¡¨æˆåŠŸå¤„ç†")
            
            # Question-SQLç”Ÿæˆç»“æœ
            if "question_sql_generation" in results:
                qs = results["question_sql_generation"]
                self.logger.info(f"ğŸ¤– Question-SQLç”Ÿæˆ: {qs.get('total_questions', 0)} ä¸ªé—®ç­”å¯¹")
            
            # SQLéªŒè¯ç»“æœ
            if "sql_validation" in results:
                validation = results["sql_validation"]
                success_rate = validation.get('success_rate', 0)
                self.logger.info(f"ğŸ” SQLéªŒè¯: {success_rate:.1%} æˆåŠŸç‡ ({validation.get('valid_sql_count', 0)}/{validation.get('original_sql_count', 0)})")
            
            self.logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {outputs['output_directory']}")
            self.logger.info(f"ğŸ“„ ä¸»è¦è¾“å‡ºæ–‡ä»¶: {outputs['primary_output_file']}")
            self.logger.info(f"â“ æœ€ç»ˆé—®é¢˜æ•°é‡: {outputs['final_question_count']}")
            
        else:
            error = report["error"]
            summary = report["workflow_summary"]
            
            self.logger.error(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥")
            self.logger.error(f"ğŸ’¥ å¤±è´¥åŸå› : {error['message']}")
            self.logger.error(f"ğŸ’¥ å¤±è´¥æ­¥éª¤: {error['failed_step']}")
            self.logger.error(f"â±ï¸  æ‰§è¡Œè€—æ—¶: {summary['total_duration']} ç§’")
            self.logger.error(f"âœ… å·²å®Œæˆæ­¥éª¤: {', '.join(summary['completed_steps']) if summary['completed_steps'] else 'æ— '}")
        
        self.logger.info("=" * 80)


# ä¾¿æ·çš„å‘½ä»¤è¡Œæ¥å£
def setup_argument_parser():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Schemaå·¥ä½œæµç¼–æ’å™¨ - ç«¯åˆ°ç«¯çš„Schemaå¤„ç†æµç¨‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # å®Œæ•´å·¥ä½œæµç¨‹
  python -m schema_tools.schema_workflow_orchestrator \\
    --db-connection "postgresql://user:pass@localhost:5432/dbname" \\
    --table-list tables.txt \\
    --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ" \\
    --db-name highway_db \\
    --output-dir ./output
  
  # è·³è¿‡SQLéªŒè¯
  python -m schema_tools.schema_workflow_orchestrator \\
    --db-connection "postgresql://user:pass@localhost:5432/dbname" \\
    --table-list tables.txt \\
    --business-context "ç”µå•†ç³»ç»Ÿ" \\
    --db-name ecommerce_db \\
    --skip-validation
  
  # ç¦ç”¨LLMä¿®å¤
  python -m schema_tools.schema_workflow_orchestrator \\
    --db-connection "postgresql://user:pass@localhost:5432/dbname" \\
    --table-list tables.txt \\
    --business-context "ç®¡ç†ç³»ç»Ÿ" \\
    --db-name management_db \\
    --disable-llm-repair
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        "--db-connection",
        required=True,
        help="æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸² (postgresql://user:pass@host:port/dbname)"
    )
    
    parser.add_argument(
        "--table-list",
        required=True,
        help="è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "--business-context",
        required=True,
        help="ä¸šåŠ¡ä¸Šä¸‹æ–‡æè¿°"
    )
    
    parser.add_argument(
        "--db-name",
        required=True,
        help="æ•°æ®åº“åç§°ï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰"
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        "--output-dir",
        default="./output",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š./outputï¼‰"
    )
    
    parser.add_argument(
        "--skip-validation",
        action="store_true",
        help="è·³è¿‡SQLéªŒè¯æ­¥éª¤"
    )
    
    parser.add_argument(
        "--disable-llm-repair",
        action="store_true",
        help="ç¦ç”¨LLMä¿®å¤åŠŸèƒ½"
    )
    
    parser.add_argument(
        "--no-modify-file",
        action="store_true",
        help="ä¸ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶ï¼ˆä»…ç”ŸæˆæŠ¥å‘Šï¼‰"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º"
    )
    
    parser.add_argument(
        "--log-file",
        help="æ—¥å¿—æ–‡ä»¶è·¯å¾„"
    )
    
    return parser


async def main():
    """å‘½ä»¤è¡Œå…¥å£ç‚¹"""
    import sys
    import os
    
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(
        verbose=args.verbose,
        log_file=args.log_file,
        log_dir=os.path.join(args.output_dir, 'logs') if args.output_dir else None
    )
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.table_list):
        print(f"é”™è¯¯: è¡¨æ¸…å•æ–‡ä»¶ä¸å­˜åœ¨: {args.table_list}")
        sys.exit(1)
    
    try:
        # åˆ›å»ºå¹¶æ‰§è¡Œå·¥ä½œæµç¼–æ’å™¨
        orchestrator = SchemaWorkflowOrchestrator(
            db_connection=args.db_connection,
            table_list_file=args.table_list,
            business_context=args.business_context,
            db_name=args.db_name,
            output_dir=args.output_dir,
            enable_sql_validation=not args.skip_validation,
            enable_llm_repair=not args.disable_llm_repair,
            modify_original_file=not args.no_modify_file
        )
        
        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        print(f"ğŸš€ å¼€å§‹æ‰§è¡ŒSchemaå·¥ä½œæµç¼–æ’...")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"ğŸ“‹ è¡¨æ¸…å•: {args.table_list}")
        print(f"ğŸ¢ ä¸šåŠ¡èƒŒæ™¯: {args.business_context}")
        print(f"ğŸ’¾ æ•°æ®åº“: {args.db_name}")
        print(f"ğŸ” SQLéªŒè¯: {'å¯ç”¨' if not args.skip_validation else 'ç¦ç”¨'}")
        print(f"ğŸ”§ LLMä¿®å¤: {'å¯ç”¨' if not args.disable_llm_repair else 'ç¦ç”¨'}")
        
        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
        report = await orchestrator.execute_complete_workflow()
        
        # æ‰“å°è¯¦ç»†æ‘˜è¦
        orchestrator.print_final_summary(report)
        
        # è¾“å‡ºç»“æœå¹¶è®¾ç½®é€€å‡ºç 
        if report["success"]:
            if report["processing_results"].get("sql_validation", {}).get("success_rate", 1.0) >= 0.8:
                print(f"\nğŸ‰ å·¥ä½œæµç¨‹æ‰§è¡ŒæˆåŠŸ!")
                exit_code = 0  # å®Œå…¨æˆåŠŸ
            else:
                print(f"\nâš ï¸  å·¥ä½œæµç¨‹æ‰§è¡Œå®Œæˆï¼Œä½†SQLéªŒè¯æˆåŠŸç‡è¾ƒä½")
                exit_code = 1  # éƒ¨åˆ†æˆåŠŸ
        else:
            print(f"\nâŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥")
            exit_code = 2  # å¤±è´¥
        
        print(f"ğŸ“„ ä¸»è¦è¾“å‡ºæ–‡ä»¶: {report['final_outputs']['primary_output_file']}")
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main()) 