import asyncio
import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from schema_tools.config import SCHEMA_TOOLS_CONFIG
from schema_tools.validators import SQLValidator, SQLValidationResult, ValidationStats
from schema_tools.utils.logger import setup_logging


class SQLValidationAgent:
    """SQLéªŒè¯Agent - ç®¡ç†SQLéªŒè¯çš„å®Œæ•´æµç¨‹"""
    
    def __init__(self, 
                 db_connection: str,
                 input_file: str,
                 output_dir: str = None):
        """
        åˆå§‹åŒ–SQLéªŒè¯Agent
        
        Args:
            db_connection: æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
            input_file: è¾“å…¥çš„JSONæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«Question-SQLå¯¹ï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸ºè¾“å…¥æ–‡ä»¶åŒç›®å½•ï¼‰
        """
        self.db_connection = db_connection
        self.input_file = Path(input_file)
        self.output_dir = Path(output_dir) if output_dir else self.input_file.parent
        
        self.config = SCHEMA_TOOLS_CONFIG['sql_validation']
        self.logger = logging.getLogger("schema_tools.SQLValidationAgent")
        
        # åˆå§‹åŒ–éªŒè¯å™¨
        self.validator = SQLValidator(db_connection)
        
        # åˆå§‹åŒ–LLMå®ä¾‹ï¼ˆç”¨äºSQLä¿®å¤ï¼‰
        self.vn = None
        if self.config.get('enable_sql_repair', True):
            self._initialize_llm()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_questions = 0
        self.validation_start_time = None
        
    async def validate(self) -> Dict[str, Any]:
        """
        æ‰§è¡ŒSQLéªŒè¯æµç¨‹
        
        Returns:
            éªŒè¯ç»“æœæŠ¥å‘Š
        """
        try:
            self.validation_start_time = time.time()
            self.logger.info("ğŸš€ å¼€å§‹SQLéªŒè¯æµç¨‹")
            
            # 1. è¯»å–è¾“å…¥æ–‡ä»¶
            self.logger.info(f"ğŸ“– è¯»å–è¾“å…¥æ–‡ä»¶: {self.input_file}")
            questions_sqls = await self._load_questions_sqls()
            self.total_questions = len(questions_sqls)
            
            if not questions_sqls:
                raise ValueError("è¾“å…¥æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Question-SQLå¯¹")
            
            self.logger.info(f"âœ… æˆåŠŸè¯»å– {self.total_questions} ä¸ªQuestion-SQLå¯¹")
            
            # 2. æå–SQLè¯­å¥
            sqls = [item['sql'] for item in questions_sqls]
            
            # 3. æ‰§è¡ŒéªŒè¯
            self.logger.info("ğŸ” å¼€å§‹SQLéªŒè¯...")
            validation_results = await self._validate_sqls_with_batching(sqls)
            
            # 4. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            stats = self.validator.calculate_stats(validation_results)
            
            # 5. å°è¯•ä¿®å¤å¤±è´¥çš„SQLï¼ˆå¦‚æœå¯ç”¨LLMä¿®å¤ï¼‰
            file_modification_stats = {'modified': 0, 'deleted': 0, 'failed_modifications': 0}
            if self.config.get('enable_sql_repair', False) and self.vn:
                self.logger.info("ğŸ”§ å¯ç”¨LLMä¿®å¤åŠŸèƒ½ï¼Œå¼€å§‹ä¿®å¤å¤±è´¥çš„SQL...")
                validation_results = await self._attempt_sql_repair(questions_sqls, validation_results)
                # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«ä¿®å¤ç»“æœï¼‰
                stats = self.validator.calculate_stats(validation_results)
            
            # 6. ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨æ–‡ä»¶ä¿®æ”¹ï¼‰
            if self.config.get('modify_original_file', False):
                self.logger.info("ğŸ“ å¯ç”¨æ–‡ä»¶ä¿®æ”¹åŠŸèƒ½ï¼Œå¼€å§‹ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶...")
                file_modification_stats = await self._modify_original_json_file(questions_sqls, validation_results)
            else:
                self.logger.info("ğŸ“‹ ä¸ä¿®æ”¹åŸå§‹æ–‡ä»¶")
            
            # 7. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            report = await self._generate_report(questions_sqls, validation_results, stats, file_modification_stats)
            
            # 8. ä¿å­˜éªŒè¯æŠ¥å‘Š
            if self.config['save_validation_report']:
                await self._save_validation_report(report)
            
            # 9. è¾“å‡ºç»“æœæ‘˜è¦
            self._print_summary(stats, validation_results, file_modification_stats)
            
            return report
            
        except Exception as e:
            self.logger.exception("âŒ SQLéªŒè¯æµç¨‹å¤±è´¥")
            raise
    
    async def _load_questions_sqls(self) -> List[Dict[str, str]]:
        """è¯»å–Question-SQLå¯¹"""
        try:
            with open(self.input_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # éªŒè¯æ•°æ®æ ¼å¼
            if not isinstance(data, list):
                raise ValueError("è¾“å…¥æ–‡ä»¶åº”åŒ…å«Question-SQLå¯¹çš„æ•°ç»„")
            
            questions_sqls = []
            for i, item in enumerate(data):
                if not isinstance(item, dict):
                    self.logger.warning(f"è·³è¿‡ç¬¬ {i+1} é¡¹ï¼šæ ¼å¼ä¸æ­£ç¡®")
                    continue
                
                if 'question' not in item or 'sql' not in item:
                    self.logger.warning(f"è·³è¿‡ç¬¬ {i+1} é¡¹ï¼šç¼ºå°‘questionæˆ–sqlå­—æ®µ")
                    continue
                
                questions_sqls.append({
                    'index': i,
                    'question': item['question'],
                    'sql': item['sql'].strip()
                })
            
            return questions_sqls
            
        except json.JSONDecodeError as e:
            raise ValueError(f"è¾“å…¥æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {e}")
        except Exception as e:
            raise ValueError(f"è¯»å–è¾“å…¥æ–‡ä»¶å¤±è´¥: {e}")
    
    async def _validate_sqls_with_batching(self, sqls: List[str]) -> List[SQLValidationResult]:
        """ä½¿ç”¨æ‰¹å¤„ç†æ–¹å¼éªŒè¯SQL"""
        batch_size = self.config['batch_size']
        all_results = []
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(sqls), batch_size):
            batch = sqls[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(sqls) + batch_size - 1) // batch_size
            
            self.logger.info(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} ä¸ªSQL)")
            
            batch_results = await self.validator.validate_sqls_batch(batch)
            all_results.extend(batch_results)
            
            # æ˜¾ç¤ºæ‰¹æ¬¡è¿›åº¦
            valid_count = sum(1 for r in batch_results if r.valid)
            self.logger.info(f"âœ… æ‰¹æ¬¡ {batch_num} å®Œæˆ: {valid_count}/{len(batch)} æœ‰æ•ˆ")
        
        return all_results
    
    async def _generate_report(self, 
                              questions_sqls: List[Dict], 
                              validation_results: List[SQLValidationResult],
                              stats: ValidationStats,
                              file_modification_stats: Dict[str, int] = None) -> Dict[str, Any]:
        """ç”Ÿæˆè¯¦ç»†éªŒè¯æŠ¥å‘Š"""
        
        validation_time = time.time() - self.validation_start_time
        
        # åˆå¹¶é—®é¢˜å’ŒéªŒè¯ç»“æœ
        detailed_results = []
        for i, (qs, result) in enumerate(zip(questions_sqls, validation_results)):
            detailed_results.append({
                'index': i + 1,
                'question': qs['question'],
                'sql': qs['sql'],
                'valid': result.valid,
                'error_message': result.error_message,
                'execution_time': result.execution_time,
                'retry_count': result.retry_count,
                
                # æ·»åŠ ä¿®å¤ä¿¡æ¯
                'repair_attempted': result.repair_attempted,
                'repair_successful': result.repair_successful,
                'repaired_sql': result.repaired_sql,
                'repair_error': result.repair_error
            })
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'metadata': {
                'input_file': str(self.input_file),
                'validation_time': datetime.now().isoformat(),
                'total_validation_time': validation_time,
                'database_connection': self._mask_connection_string(self.db_connection),
                'config': self.config.copy()
            },
            'summary': {
                'total_questions': stats.total_sqls,
                'valid_sqls': stats.valid_sqls,
                'invalid_sqls': stats.invalid_sqls,
                'success_rate': stats.valid_sqls / stats.total_sqls if stats.total_sqls > 0 else 0.0,
                'average_execution_time': stats.avg_time_per_sql,
                'total_retries': stats.retry_count,
                
                # æ·»åŠ ä¿®å¤ç»Ÿè®¡
                'repair_stats': {
                    'attempted': stats.repair_attempted,
                    'successful': stats.repair_successful,
                    'failed': stats.repair_failed
                },
                
                # æ·»åŠ æ–‡ä»¶ä¿®æ”¹ç»Ÿè®¡
                'file_modification_stats': file_modification_stats or {
                    'modified': 0, 'deleted': 0, 'failed_modifications': 0
                }
            },
            'detailed_results': detailed_results
        }
        
        return report
    
    async def _save_validation_report(self, report: Dict[str, Any]):
        """ä¿å­˜éªŒè¯æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # åªä¿å­˜æ–‡æœ¬æ ¼å¼æ‘˜è¦ï¼ˆä¾¿äºæŸ¥çœ‹ï¼‰
        txt_file = self.output_dir / f"{self.config['report_file_prefix']}_{timestamp}_summary.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"SQLéªŒè¯æŠ¥å‘Š\n")
            f.write(f"=" * 50 + "\n\n")
            f.write(f"è¾“å…¥æ–‡ä»¶: {self.input_file}\n")
            f.write(f"éªŒè¯æ—¶é—´: {report['metadata']['validation_time']}\n")
            f.write(f"éªŒè¯è€—æ—¶: {report['metadata']['total_validation_time']:.2f}ç§’\n\n")
            
            f.write(f"éªŒè¯ç»“æœæ‘˜è¦:\n")
            f.write(f"  æ€»SQLæ•°é‡: {report['summary']['total_questions']}\n")
            f.write(f"  æœ‰æ•ˆSQL: {report['summary']['valid_sqls']}\n")
            f.write(f"  æ— æ•ˆSQL: {report['summary']['invalid_sqls']}\n")
            f.write(f"  æˆåŠŸç‡: {report['summary']['success_rate']:.2%}\n")
            f.write(f"  å¹³å‡è€—æ—¶: {report['summary']['average_execution_time']:.3f}ç§’\n")
            f.write(f"  é‡è¯•æ¬¡æ•°: {report['summary']['total_retries']}\n\n")
            
            # æ·»åŠ ä¿®å¤ç»Ÿè®¡
            if 'repair_stats' in report['summary']:
                repair_stats = report['summary']['repair_stats']
                f.write(f"SQLä¿®å¤ç»Ÿè®¡:\n")
                f.write(f"  å°è¯•ä¿®å¤: {repair_stats['attempted']}\n")
                f.write(f"  ä¿®å¤æˆåŠŸ: {repair_stats['successful']}\n")
                f.write(f"  ä¿®å¤å¤±è´¥: {repair_stats['failed']}\n")
                if repair_stats['attempted'] > 0:
                    f.write(f"  ä¿®å¤æˆåŠŸç‡: {repair_stats['successful'] / repair_stats['attempted']:.2%}\n")
                f.write(f"\n")
            
            # æ·»åŠ æ–‡ä»¶ä¿®æ”¹ç»Ÿè®¡
            if 'file_modification_stats' in report['summary']:
                file_stats = report['summary']['file_modification_stats']
                f.write(f"åŸå§‹æ–‡ä»¶ä¿®æ”¹ç»Ÿè®¡:\n")
                f.write(f"  ä¿®æ”¹çš„SQL: {file_stats['modified']}\n")
                f.write(f"  åˆ é™¤çš„æ— æ•ˆé¡¹: {file_stats['deleted']}\n")
                f.write(f"  ä¿®æ”¹å¤±è´¥: {file_stats['failed_modifications']}\n")
                f.write(f"\n")
            
            # æå–é”™è¯¯è¯¦æƒ…ï¼ˆæ˜¾ç¤ºå®Œæ•´SQLï¼‰
            error_results = [r for r in report['detailed_results'] if not r['valid'] and not r.get('repair_successful', False)]
            if error_results:
                f.write(f"é”™è¯¯è¯¦æƒ…ï¼ˆå…±{len(error_results)}ä¸ªï¼‰:\n")
                f.write(f"=" * 50 + "\n")
                for i, error_result in enumerate(error_results, 1):
                    f.write(f"\n{i}. é—®é¢˜: {error_result['question']}\n")
                    f.write(f"   é”™è¯¯: {error_result['error_message']}\n")
                    if error_result['retry_count'] > 0:
                        f.write(f"   é‡è¯•: {error_result['retry_count']}æ¬¡\n")
                    
                    # æ˜¾ç¤ºä¿®å¤å°è¯•ä¿¡æ¯
                    if error_result.get('repair_attempted', False):
                        if error_result.get('repair_successful', False):
                            f.write(f"   LLMä¿®å¤å°è¯•: æˆåŠŸ\n")
                            f.write(f"   ä¿®å¤åSQL:\n")
                            f.write(f"   {error_result.get('repaired_sql', '')}\n")
                        else:
                            f.write(f"   LLMä¿®å¤å°è¯•: å¤±è´¥\n")
                            repair_error = error_result.get('repair_error', 'æœªçŸ¥é”™è¯¯')
                            f.write(f"   ä¿®å¤å¤±è´¥åŸå› : {repair_error}\n")
                    else:
                        f.write(f"   LLMä¿®å¤å°è¯•: æœªå°è¯•\n")
                    
                    f.write(f"   å®Œæ•´SQL:\n")
                    f.write(f"   {error_result['sql']}\n")
                    f.write(f"   {'-' * 40}\n")
            
            # æ˜¾ç¤ºæˆåŠŸä¿®å¤çš„SQL
            repaired_results = [r for r in report['detailed_results'] if r.get('repair_successful', False)]
            if repaired_results:
                f.write(f"\næˆåŠŸä¿®å¤çš„SQLï¼ˆå…±{len(repaired_results)}ä¸ªï¼‰:\n")
                f.write(f"=" * 50 + "\n")
                for i, repaired_result in enumerate(repaired_results, 1):
                    f.write(f"\n{i}. é—®é¢˜: {repaired_result['question']}\n")
                    f.write(f"   åŸå§‹é”™è¯¯: {repaired_result['error_message']}\n")
                    f.write(f"   ä¿®å¤åSQL:\n")
                    f.write(f"   {repaired_result.get('repaired_sql', '')}\n")
                    f.write(f"   {'-' * 40}\n")
        
        self.logger.info(f"ğŸ“Š éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {txt_file}")
        
        # å¦‚æœé…ç½®å…è®¸ï¼Œä¹Ÿå¯ä»¥ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Šï¼ˆå¯é€‰ï¼‰
        if self.config.get('save_detailed_json_report', False):
            json_file = self.output_dir / f"{self.config['report_file_prefix']}_{timestamp}_report.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            self.logger.info(f"ğŸ“Š è¯¦ç»†JSONæŠ¥å‘Šå·²ä¿å­˜: {json_file}")
    
    def _mask_connection_string(self, conn_str: str) -> str:
        """éšè—è¿æ¥å­—ç¬¦ä¸²ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
        import re
        # éšè—å¯†ç 
        return re.sub(r':[^:@]+@', ':***@', conn_str)
    
    def _print_summary(self, stats: ValidationStats, validation_results: List[SQLValidationResult] = None, file_modification_stats: Dict[str, int] = None):
        """æ‰“å°éªŒè¯ç»“æœæ‘˜è¦"""
        validation_time = time.time() - self.validation_start_time
        
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š SQLéªŒè¯ç»“æœæ‘˜è¦")
        self.logger.info(f"  ğŸ“ æ€»SQLæ•°é‡: {stats.total_sqls}")
        self.logger.info(f"  âœ… æœ‰æ•ˆSQL: {stats.valid_sqls}")
        self.logger.info(f"  âŒ æ— æ•ˆSQL: {stats.invalid_sqls}")
        self.logger.info(f"  ğŸ“ˆ æˆåŠŸç‡: {stats.valid_sqls / stats.total_sqls:.2%}")
        self.logger.info(f"  â±ï¸  å¹³å‡è€—æ—¶: {stats.avg_time_per_sql:.3f}ç§’/SQL")
        self.logger.info(f"  ğŸ”„ é‡è¯•æ¬¡æ•°: {stats.retry_count}")
        self.logger.info(f"  â° æ€»è€—æ—¶: {validation_time:.2f}ç§’")
        
        # æ·»åŠ ä¿®å¤ç»Ÿè®¡
        if stats.repair_attempted > 0:
            self.logger.info(f"  ğŸ”§ ä¿®å¤å°è¯•: {stats.repair_attempted}")
            self.logger.info(f"  âœ… ä¿®å¤æˆåŠŸ: {stats.repair_successful}")
            self.logger.info(f"  âŒ ä¿®å¤å¤±è´¥: {stats.repair_failed}")
            repair_rate = stats.repair_successful / stats.repair_attempted if stats.repair_attempted > 0 else 0.0
            self.logger.info(f"  ğŸ“ˆ ä¿®å¤æˆåŠŸç‡: {repair_rate:.2%}")
        
        # æ·»åŠ æ–‡ä»¶ä¿®æ”¹ç»Ÿè®¡
        if file_modification_stats:
            self.logger.info(f"  ğŸ“ æ–‡ä»¶ä¿®æ”¹: {file_modification_stats['modified']} ä¸ªSQL")
            self.logger.info(f"  ğŸ—‘ï¸  åˆ é™¤æ— æ•ˆé¡¹: {file_modification_stats['deleted']} ä¸ª")
            if file_modification_stats['failed_modifications'] > 0:
                self.logger.info(f"  âš ï¸  ä¿®æ”¹å¤±è´¥: {file_modification_stats['failed_modifications']} ä¸ª")
        
        self.logger.info("=" * 60)
        
        # æ˜¾ç¤ºéƒ¨åˆ†é”™è¯¯ä¿¡æ¯
        if validation_results:
            error_results = [r for r in validation_results if not r.valid]
            if error_results:
                self.logger.info(f"âš ï¸  å‰5ä¸ªé”™è¯¯ç¤ºä¾‹:")
                for i, error_result in enumerate(error_results[:5], 1):
                    self.logger.info(f"  {i}. {error_result.error_message}")
                    # æ˜¾ç¤ºSQLçš„å‰80ä¸ªå­—ç¬¦
                    sql_preview = error_result.sql[:80] + '...' if len(error_result.sql) > 80 else error_result.sql
                    self.logger.info(f"     SQL: {sql_preview}")
    
    def _initialize_llm(self):
        """åˆå§‹åŒ–LLMå®ä¾‹"""
        try:
            from core.vanna_llm_factory import create_vanna_instance
            self.vn = create_vanna_instance()
            self.logger.info("âœ… LLMå®ä¾‹åˆå§‹åŒ–æˆåŠŸï¼ŒSQLä¿®å¤åŠŸèƒ½å·²å¯ç”¨")
        except Exception as e:
            self.logger.warning(f"âš ï¸  LLMåˆå§‹åŒ–å¤±è´¥ï¼ŒSQLä¿®å¤åŠŸèƒ½å°†è¢«ç¦ç”¨: {e}")
            self.vn = None 
    
    async def _attempt_sql_repair(self, questions_sqls: List[Dict], validation_results: List[SQLValidationResult]) -> List[SQLValidationResult]:
        """
        å°è¯•ä¿®å¤å¤±è´¥çš„SQL
        
        Args:
            questions_sqls: é—®é¢˜SQLå¯¹åˆ—è¡¨
            validation_results: éªŒè¯ç»“æœåˆ—è¡¨
            
        Returns:
            æ›´æ–°åçš„éªŒè¯ç»“æœåˆ—è¡¨
        """
        # æ‰¾å‡ºéœ€è¦ä¿®å¤çš„SQL
        failed_indices = []
        for i, result in enumerate(validation_results):
            if not result.valid:
                failed_indices.append(i)
        
        if not failed_indices:
            self.logger.info("ğŸ‰ æ‰€æœ‰SQLéƒ½æœ‰æ•ˆï¼Œæ— éœ€ä¿®å¤")
            return validation_results
        
        self.logger.info(f"ğŸ”§ å¼€å§‹ä¿®å¤ {len(failed_indices)} ä¸ªå¤±è´¥çš„SQL...")
        
        # æ‰¹é‡ä¿®å¤
        batch_size = self.config.get('repair_batch_size', 5)
        updated_results = validation_results.copy()
        
        for i in range(0, len(failed_indices), batch_size):
            batch_indices = failed_indices[i:i + batch_size]
            self.logger.info(f"ğŸ“¦ ä¿®å¤æ‰¹æ¬¡ {i//batch_size + 1}/{(len(failed_indices) + batch_size - 1)//batch_size} ({len(batch_indices)} ä¸ªSQL)")
            
            # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
            batch_data = []
            for idx in batch_indices:
                batch_data.append({
                    'index': idx,
                    'question': questions_sqls[idx]['question'],
                    'sql': validation_results[idx].sql,
                    'error': validation_results[idx].error_message
                })
            
            # è°ƒç”¨LLMä¿®å¤
            repaired_sqls = await self._repair_sqls_with_llm(batch_data)
            
            # éªŒè¯ä¿®å¤åçš„SQL
            for j, idx in enumerate(batch_indices):
                original_result = updated_results[idx]
                original_result.repair_attempted = True
                
                if j < len(repaired_sqls) and repaired_sqls[j]:
                    repaired_sql = repaired_sqls[j]
                    
                    # éªŒè¯ä¿®å¤åçš„SQL
                    repair_result = await self.validator.validate_sql(repaired_sql)
                    
                    if repair_result.valid:
                        # ä¿®å¤æˆåŠŸ
                        original_result.repair_successful = True
                        original_result.repaired_sql = repaired_sql
                        original_result.valid = True  # æ›´æ–°ä¸ºæœ‰æ•ˆ
                        self.logger.info(f"âœ… SQLä¿®å¤æˆåŠŸ (ç´¢å¼• {idx})")
                    else:
                        # ä¿®å¤å¤±è´¥
                        original_result.repair_successful = False
                        original_result.repair_error = repair_result.error_message
                        self.logger.warning(f"âŒ SQLä¿®å¤å¤±è´¥ (ç´¢å¼• {idx}): {repair_result.error_message}")
                else:
                    # LLMä¿®å¤å¤±è´¥
                    original_result.repair_successful = False
                    original_result.repair_error = "LLMä¿®å¤å¤±è´¥æˆ–è¿”å›ç©ºç»“æœ"
                    self.logger.warning(f"âŒ LLMä¿®å¤å¤±è´¥ (ç´¢å¼• {idx})")
        
        # ç»Ÿè®¡ä¿®å¤ç»“æœ
        repair_attempted = sum(1 for r in updated_results if r.repair_attempted)
        repair_successful = sum(1 for r in updated_results if r.repair_successful)
        
        self.logger.info(f"ğŸ”§ ä¿®å¤å®Œæˆ: {repair_successful}/{repair_attempted} æˆåŠŸ")
        
        return updated_results 
    
    async def _modify_original_json_file(self, questions_sqls: List[Dict], validation_results: List[SQLValidationResult]) -> Dict[str, int]:
        """
        ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶ï¼š
        1. å¯¹äºä¿®å¤æˆåŠŸçš„SQLï¼Œæ›´æ–°åŸå§‹æ–‡ä»¶ä¸­çš„SQLå†…å®¹
        2. å¯¹äºæ— æ³•ä¿®å¤çš„SQLï¼Œä»åŸå§‹æ–‡ä»¶ä¸­åˆ é™¤å¯¹åº”çš„é”®å€¼å¯¹
        
        Returns:
            ä¿®æ”¹ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {'modified': 0, 'deleted': 0, 'failed_modifications': 0}
        
        try:
            # è¯»å–åŸå§‹JSONæ–‡ä»¶
            with open(self.input_file, 'r', encoding='utf-8') as f:
                original_data = json.load(f)
            
            if not isinstance(original_data, list):
                self.logger.error("åŸå§‹JSONæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•ä¿®æ”¹")
                stats['failed_modifications'] = 1
                return stats
            
            # åˆ›å»ºå¤‡ä»½æ–‡ä»¶
            backup_file = Path(str(self.input_file) + '.backup')
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(original_data, f, ensure_ascii=False, indent=2)
            self.logger.info(f"å·²åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_file}")
            
            # æ„å»ºä¿®æ”¹è®¡åˆ’
            modifications = []
            deletions = []
            
            for i, (qs, result) in enumerate(zip(questions_sqls, validation_results)):
                if result.repair_successful and result.repaired_sql:
                    # ä¿®å¤æˆåŠŸçš„SQL
                    modifications.append({
                        'index': i,
                        'original_sql': result.sql,
                        'repaired_sql': result.repaired_sql,
                        'question': qs['question']
                    })
                elif not result.valid and not result.repair_successful:
                    # æ— æ³•ä¿®å¤çš„SQLï¼Œæ ‡è®°åˆ é™¤
                    deletions.append({
                        'index': i,
                        'question': qs['question'],
                        'sql': result.sql,
                        'error': result.error_message
                    })
            
            # æ‰§è¡Œä¿®æ”¹ï¼ˆä»åå¾€å‰ï¼Œé¿å…ç´¢å¼•å˜åŒ–ï¼‰
            new_data = original_data.copy()
            
            # å…ˆåˆ é™¤æ— æ•ˆé¡¹ï¼ˆä»åå¾€å‰åˆ é™¤ï¼‰
            for deletion in sorted(deletions, key=lambda x: x['index'], reverse=True):
                if deletion['index'] < len(new_data):
                    removed_item = new_data.pop(deletion['index'])
                    stats['deleted'] += 1
                    self.logger.info(f"åˆ é™¤æ— æ•ˆé¡¹ {deletion['index']}: {deletion['question'][:50]}...")
            
            # å†ä¿®æ”¹SQLï¼ˆéœ€è¦é‡æ–°è®¡ç®—ç´¢å¼•ï¼‰
            index_offset = 0
            for modification in sorted(modifications, key=lambda x: x['index']):
                # è®¡ç®—åˆ é™¤åçš„æ–°ç´¢å¼•
                new_index = modification['index']
                for deletion in deletions:
                    if deletion['index'] < modification['index']:
                        new_index -= 1
                
                if new_index < len(new_data):
                    new_data[new_index]['sql'] = modification['repaired_sql']
                    stats['modified'] += 1
                    self.logger.info(f"ä¿®æ”¹SQL {new_index}: {modification['question'][:50]}...")
            
            # å†™å…¥ä¿®æ”¹åçš„æ–‡ä»¶
            with open(self.input_file, 'w', encoding='utf-8') as f:
                json.dump(new_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"âœ… åŸå§‹æ–‡ä»¶ä¿®æ”¹å®Œæˆ: ä¿®æ”¹{stats['modified']}ä¸ªSQLï¼Œåˆ é™¤{stats['deleted']}ä¸ªæ— æ•ˆé¡¹")
            
            # è®°å½•è¯¦ç»†ä¿®æ”¹ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶
            await self._write_modification_log(modifications, deletions)
            
        except Exception as e:
            self.logger.error(f"ä¿®æ”¹åŸå§‹JSONæ–‡ä»¶å¤±è´¥: {e}")
            stats['failed_modifications'] = 1
        
        return stats
    
    async def _write_modification_log(self, modifications: List[Dict], deletions: List[Dict]):
        """å†™å…¥è¯¦ç»†çš„ä¿®æ”¹æ—¥å¿—"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            log_file = self.output_dir / f"file_modifications_{timestamp}.log"
            
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write(f"åŸå§‹JSONæ–‡ä»¶ä¿®æ”¹æ—¥å¿—\n")
                f.write(f"=" * 50 + "\n")
                f.write(f"ä¿®æ”¹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"åŸå§‹æ–‡ä»¶: {self.input_file}\n")
                f.write(f"å¤‡ä»½æ–‡ä»¶: {str(self.input_file)}.backup\n")
                f.write(f"\n")
                
                if modifications:
                    f.write(f"ä¿®æ”¹çš„SQL ({len(modifications)}ä¸ª):\n")
                    f.write(f"-" * 40 + "\n")
                    for i, mod in enumerate(modifications, 1):
                        f.write(f"{i}. ç´¢å¼•: {mod['index']}\n")
                        f.write(f"   é—®é¢˜: {mod['question']}\n")
                        f.write(f"   åŸSQL: {mod['original_sql']}\n")
                        f.write(f"   æ–°SQL: {mod['repaired_sql']}\n\n")
                
                if deletions:
                    f.write(f"åˆ é™¤çš„æ— æ•ˆé¡¹ ({len(deletions)}ä¸ª):\n")
                    f.write(f"-" * 40 + "\n")
                    for i, del_item in enumerate(deletions, 1):
                        f.write(f"{i}. ç´¢å¼•: {del_item['index']}\n")
                        f.write(f"   é—®é¢˜: {del_item['question']}\n")
                        f.write(f"   SQL: {del_item['sql']}\n")
                        f.write(f"   é”™è¯¯: {del_item['error']}\n\n")
            
            self.logger.info(f"è¯¦ç»†ä¿®æ”¹æ—¥å¿—å·²ä¿å­˜: {log_file}")
            
        except Exception as e:
            self.logger.warning(f"å†™å…¥ä¿®æ”¹æ—¥å¿—å¤±è´¥: {e}")
    
    async def _repair_sqls_with_llm(self, batch_data: List[Dict]) -> List[str]:
        """
        ä½¿ç”¨LLMä¿®å¤SQLæ‰¹æ¬¡
        
        Args:
            batch_data: æ‰¹æ¬¡æ•°æ®ï¼ŒåŒ…å«question, sql, error
            
        Returns:
            ä¿®å¤åçš„SQLåˆ—è¡¨
        """
        try:
            # æ„å»ºä¿®å¤æç¤ºè¯
            prompt = self._build_repair_prompt(batch_data)
            
            # è°ƒç”¨LLM
            response = await self._call_llm_for_repair(prompt)
            
            # è§£æå“åº”
            repaired_sqls = self._parse_repair_response(response, len(batch_data))
            
            return repaired_sqls
            
        except Exception as e:
            self.logger.error(f"LLMä¿®å¤æ‰¹æ¬¡å¤±è´¥: {e}")
            return [""] * len(batch_data)  # è¿”å›ç©ºå­—ç¬¦ä¸²åˆ—è¡¨ 
    
    def _build_repair_prompt(self, batch_data: List[Dict]) -> str:
        """æ„å»ºSQLä¿®å¤æç¤ºè¯"""
        
        # æå–æ•°æ®åº“ç±»å‹
        db_type = "PostgreSQL"  # ä»è¿æ¥å­—ç¬¦ä¸²å¯ä»¥ç¡®å®šæ˜¯PostgreSQL
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ï¼Œä¸“é—¨ä¿®å¤PostgreSQLæ•°æ®åº“çš„SQLè¯­å¥é”™è¯¯ã€‚

æ•°æ®åº“ç±»å‹: {db_type}

è¯·ä¿®å¤ä»¥ä¸‹SQLè¯­å¥ä¸­çš„é”™è¯¯ã€‚å¯¹äºæ¯ä¸ªSQLï¼Œæˆ‘ä¼šæä¾›é—®é¢˜æè¿°ã€é”™è¯¯ä¿¡æ¯å’Œå®Œæ•´çš„SQLè¯­å¥ã€‚

ä¿®å¤è¦æ±‚ï¼š
1. åªä¿®å¤è¯­æ³•é”™è¯¯å’Œè¡¨ç»“æ„é”™è¯¯
2. ä¿æŒSQLçš„åŸå§‹ä¸šåŠ¡é€»è¾‘ä¸å˜
3. ä½¿ç”¨PostgreSQLæ ‡å‡†è¯­æ³•
4. ç¡®ä¿ä¿®å¤åçš„SQLè¯­æ³•æ­£ç¡®

éœ€è¦ä¿®å¤çš„SQLï¼š

"""
        
        # æ·»åŠ æ¯ä¸ªSQLçš„è¯¦ç»†ä¿¡æ¯
        for i, data in enumerate(batch_data, 1):
            prompt += f"""
{i}. é—®é¢˜: {data['question']}
   é”™è¯¯: {data['error']}
   å®Œæ•´SQL:
   {data['sql']}

"""
        
        prompt += f"""
è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºä¿®å¤åçš„SQLï¼š
```json
{{
  "repaired_sqls": [
    "ä¿®å¤åçš„SQL1",
    "ä¿®å¤åçš„SQL2",
    "ä¿®å¤åçš„SQL3"
  ]
}}
```

æ³¨æ„ï¼š
- å¿…é¡»è¾“å‡º {len(batch_data)} ä¸ªä¿®å¤åçš„SQL
- å¦‚æœæŸä¸ªSQLæ— æ³•ä¿®å¤ï¼Œè¯·è¾“å‡ºåŸå§‹SQL
- SQLè¯­å¥å¿…é¡»ä»¥åˆ†å·ç»“æŸ
- ä¿æŒåŸå§‹çš„ä¸­æ–‡åˆ«åå’Œä¸šåŠ¡é€»è¾‘"""
        
        return prompt 
    
    async def _call_llm_for_repair(self, prompt: str) -> str:
        """è°ƒç”¨LLMè¿›è¡Œä¿®å¤"""
        import asyncio
        
        try:
            timeout = self.config.get('llm_repair_timeout', 60)
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    self.vn.chat_with_llm,
                    question=prompt,
                    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„PostgreSQL SQLä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£ä¿®å¤SQLè¯­å¥ä¸­çš„è¯­æ³•é”™è¯¯å’Œè¡¨ç»“æ„é”™è¯¯ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºä¿®å¤ç»“æœã€‚"
                ),
                timeout=timeout
            )
            
            if not response or not response.strip():
                raise ValueError("LLMè¿”å›ç©ºå“åº”")
            
            return response.strip()
            
        except asyncio.TimeoutError:
            raise Exception(f"LLMè°ƒç”¨è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
        except Exception as e:
            raise Exception(f"LLMè°ƒç”¨å¤±è´¥: {e}") 
    
    def _parse_repair_response(self, response: str, expected_count: int) -> List[str]:
        """è§£æLLMä¿®å¤å“åº”"""
        import json
        import re
        
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ç›´æ¥è§£æ
                json_str = response
            
            # è§£æJSON
            parsed_data = json.loads(json_str)
            repaired_sqls = parsed_data.get('repaired_sqls', [])
            
            # éªŒè¯æ•°é‡
            if len(repaired_sqls) != expected_count:
                self.logger.warning(f"LLMè¿”å›çš„SQLæ•°é‡ä¸åŒ¹é…ï¼šæœŸæœ›{expected_count}ï¼Œå®é™…{len(repaired_sqls)}")
                # è¡¥é½æˆ–æˆªæ–­
                while len(repaired_sqls) < expected_count:
                    repaired_sqls.append("")
                repaired_sqls = repaired_sqls[:expected_count]
            
            # æ¸…ç†SQLè¯­å¥
            cleaned_sqls = []
            for sql in repaired_sqls:
                if sql and isinstance(sql, str):
                    cleaned_sql = sql.strip()
                    # ç¡®ä¿ä»¥åˆ†å·ç»“æŸ
                    if cleaned_sql and not cleaned_sql.endswith(';'):
                        cleaned_sql += ';'
                    cleaned_sqls.append(cleaned_sql)
                else:
                    cleaned_sqls.append("")
            
            return cleaned_sqls
            
        except json.JSONDecodeError as e:
            self.logger.error(f"è§£æLLMä¿®å¤å“åº”å¤±è´¥: {e}")
            self.logger.debug(f"åŸå§‹å“åº”: {response}")
            return [""] * expected_count
        except Exception as e:
            self.logger.error(f"å¤„ç†ä¿®å¤å“åº”å¤±è´¥: {e}")
            return [""] * expected_count 