import asyncio
import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

from schema_tools.config import SCHEMA_TOOLS_CONFIG
from schema_tools.validators import FileCountValidator
from schema_tools.analyzers import MDFileAnalyzer, ThemeExtractor
from schema_tools.utils.logger import setup_logging
from core.vanna_llm_factory import create_vanna_instance


class QuestionSQLGenerationAgent:
    """Question-SQLç”ŸæˆAgent"""
    
    def __init__(self, 
                 output_dir: str,
                 table_list_file: str,
                 business_context: str,
                 db_name: str = None):
        """
        åˆå§‹åŒ–Agent
        
        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼ˆåŒ…å«DDLå’ŒMDæ–‡ä»¶ï¼‰
            table_list_file: è¡¨æ¸…å•æ–‡ä»¶è·¯å¾„
            business_context: ä¸šåŠ¡ä¸Šä¸‹æ–‡
            db_name: æ•°æ®åº“åç§°ï¼ˆç”¨äºè¾“å‡ºæ–‡ä»¶å‘½åï¼‰
        """
        self.output_dir = Path(output_dir)
        self.table_list_file = table_list_file
        self.business_context = business_context
        self.db_name = db_name or "db"
        
        self.config = SCHEMA_TOOLS_CONFIG
        self.logger = logging.getLogger("schema_tools.QSAgent")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.validator = FileCountValidator()
        self.md_analyzer = MDFileAnalyzer(output_dir)
        
        # vannaå®ä¾‹å’Œä¸»é¢˜æå–å™¨å°†åœ¨éœ€è¦æ—¶åˆå§‹åŒ–
        self.vn = None
        self.theme_extractor = None
        
        # ä¸­é—´ç»“æœå­˜å‚¨
        self.intermediate_results = []
        self.intermediate_file = None
        
    async def generate(self) -> Dict[str, Any]:
        """
        ç”ŸæˆQuestion-SQLå¯¹
        
        Returns:
            ç”Ÿæˆç»“æœæŠ¥å‘Š
        """
        start_time = time.time()
        
        try:
            self.logger.info("ğŸš€ å¼€å§‹ç”ŸæˆQuestion-SQLè®­ç»ƒæ•°æ®")
            
            # 1. éªŒè¯æ–‡ä»¶æ•°é‡
            self.logger.info("ğŸ“‹ éªŒè¯æ–‡ä»¶æ•°é‡...")
            validation_result = self.validator.validate(self.table_list_file, str(self.output_dir))
            
            if not validation_result.is_valid:
                self.logger.error(f"âŒ æ–‡ä»¶éªŒè¯å¤±è´¥: {validation_result.error}")
                if validation_result.missing_ddl:
                    self.logger.error(f"ç¼ºå¤±DDLæ–‡ä»¶: {validation_result.missing_ddl}")
                if validation_result.missing_md:
                    self.logger.error(f"ç¼ºå¤±MDæ–‡ä»¶: {validation_result.missing_md}")
                raise ValueError(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {validation_result.error}")
            
            self.logger.info(f"âœ… æ–‡ä»¶éªŒè¯é€šè¿‡: {validation_result.table_count}ä¸ªè¡¨")
            
            # 2. è¯»å–æ‰€æœ‰MDæ–‡ä»¶å†…å®¹
            self.logger.info("ğŸ“– è¯»å–MDæ–‡ä»¶...")
            md_contents = await self.md_analyzer.read_all_md_files()
            
            # 3. åˆå§‹åŒ–LLMç›¸å…³ç»„ä»¶
            self._initialize_llm_components()
            
            # 4. æå–åˆ†æä¸»é¢˜
            self.logger.info("ğŸ¯ æå–åˆ†æä¸»é¢˜...")
            themes = await self.theme_extractor.extract_themes(md_contents)
            self.logger.info(f"âœ… æˆåŠŸæå– {len(themes)} ä¸ªåˆ†æä¸»é¢˜")
            
            for i, theme in enumerate(themes):
                topic_name = theme.get('topic_name', theme.get('name', ''))
                description = theme.get('description', '')
                self.logger.info(f"  {i+1}. {topic_name}: {description}")
            
            # 5. åˆå§‹åŒ–ä¸­é—´ç»“æœæ–‡ä»¶
            self._init_intermediate_file()
            
            # 6. å¤„ç†æ¯ä¸ªä¸»é¢˜
            all_qs_pairs = []
            failed_themes = []
            
            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¹¶è¡Œè¿˜æ˜¯ä¸²è¡Œå¤„ç†
            max_concurrent = self.config['qs_generation'].get('max_concurrent_themes', 1)
            if max_concurrent > 1:
                results = await self._process_themes_parallel(themes, md_contents, max_concurrent)
            else:
                results = await self._process_themes_serial(themes, md_contents)
            
            # 7. æ•´ç†ç»“æœ
            for result in results:
                if result['success']:
                    all_qs_pairs.extend(result['qs_pairs'])
                else:
                    failed_themes.append(result['theme_name'])
            
            # 8. ä¿å­˜æœ€ç»ˆç»“æœ
            output_file = await self._save_final_results(all_qs_pairs)
            
            # 8.5 ç”Ÿæˆmetadata.txtæ–‡ä»¶
            await self._generate_metadata_file(themes)
            
            # 9. æ¸…ç†ä¸­é—´æ–‡ä»¶
            if not failed_themes:  # åªæœ‰å…¨éƒ¨æˆåŠŸæ‰æ¸…ç†
                self._cleanup_intermediate_file()
            
            # 10. ç”ŸæˆæŠ¥å‘Š
            end_time = time.time()
            report = {
                'success': True,
                'total_themes': len(themes),
                'successful_themes': len(themes) - len(failed_themes),
                'failed_themes': failed_themes,
                'total_questions': len(all_qs_pairs),
                'output_file': str(output_file),
                'execution_time': end_time - start_time
            }
            
            self._print_summary(report)
            
            return report
            
        except Exception as e:
            self.logger.exception("âŒ Question-SQLç”Ÿæˆå¤±è´¥")
            
            # ä¿å­˜å½“å‰å·²ç”Ÿæˆçš„ç»“æœ
            if self.intermediate_results:
                recovery_file = self._save_intermediate_results()
                self.logger.warning(f"âš ï¸  ä¸­é—´ç»“æœå·²ä¿å­˜åˆ°: {recovery_file}")
            
            raise
    
    def _initialize_llm_components(self):
        """åˆå§‹åŒ–LLMç›¸å…³ç»„ä»¶"""
        if not self.vn:
            self.logger.info("åˆå§‹åŒ–LLMç»„ä»¶...")
            self.vn = create_vanna_instance()
            self.theme_extractor = ThemeExtractor(self.vn, self.business_context)
    
    async def _process_themes_serial(self, themes: List[Dict], md_contents: str) -> List[Dict]:
        """ä¸²è¡Œå¤„ç†ä¸»é¢˜"""
        results = []
        
        for i, theme in enumerate(themes):
            self.logger.info(f"å¤„ç†ä¸»é¢˜ {i+1}/{len(themes)}: {theme.get('topic_name', theme.get('name', ''))}")
            result = await self._process_single_theme(theme, md_contents)
            results.append(result)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­
            if not result['success'] and not self.config['qs_generation']['continue_on_theme_error']:
                self.logger.error(f"ä¸»é¢˜å¤„ç†å¤±è´¥ï¼Œåœæ­¢å¤„ç†")
                break
        
        return results
    
    async def _process_themes_parallel(self, themes: List[Dict], md_contents: str, max_concurrent: int) -> List[Dict]:
        """å¹¶è¡Œå¤„ç†ä¸»é¢˜"""
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_with_semaphore(theme):
            async with semaphore:
                return await self._process_single_theme(theme, md_contents)
        
        tasks = [process_with_semaphore(theme) for theme in themes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                theme_name = themes[i].get('topic_name', themes[i].get('name', ''))
                self.logger.error(f"ä¸»é¢˜ '{theme_name}' å¤„ç†å¼‚å¸¸: {result}")
                processed_results.append({
                    'success': False,
                    'theme_name': theme_name,
                    'error': str(result)
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _process_single_theme(self, theme: Dict, md_contents: str) -> Dict:
        """å¤„ç†å•ä¸ªä¸»é¢˜"""
        theme_name = theme.get('topic_name', theme.get('name', ''))
        
        try:
            self.logger.info(f"ğŸ” å¼€å§‹å¤„ç†ä¸»é¢˜: {theme_name}")
            
            # æ„å»ºprompt
            prompt = self._build_qs_generation_prompt(theme, md_contents)
            
            # è°ƒç”¨LLMç”Ÿæˆ
            response = await self._call_llm(prompt)
            
            # è§£æå“åº”
            qs_pairs = self._parse_qs_response(response)
            
            # éªŒè¯å’Œæ¸…ç†
            validated_pairs = self._validate_qs_pairs(qs_pairs, theme_name)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            await self._save_theme_results(theme_name, validated_pairs)
            
            self.logger.info(f"âœ… ä¸»é¢˜ '{theme_name}' å¤„ç†æˆåŠŸï¼Œç”Ÿæˆ {len(validated_pairs)} ä¸ªé—®é¢˜")
            
            return {
                'success': True,
                'theme_name': theme_name,
                'qs_pairs': validated_pairs
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†ä¸»é¢˜ '{theme_name}' å¤±è´¥: {e}")
            return {
                'success': False,
                'theme_name': theme_name,
                'error': str(e),
                'qs_pairs': []
            }
    
    def _build_qs_generation_prompt(self, theme: Dict, md_contents: str) -> str:
        """æ„å»ºQuestion-SQLç”Ÿæˆçš„prompt"""
        questions_count = self.config['qs_generation']['questions_per_theme']
        
        # å…¼å®¹æ–°æ—§æ ¼å¼
        topic_name = theme.get('topic_name', theme.get('name', ''))
        description = theme.get('description', '')
        focus_areas = theme.get('focus_areas', theme.get('keywords', []))
        related_tables = theme.get('related_tables', [])
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸šåŠ¡æ•°æ®åˆ†æå¸ˆï¼Œæ­£åœ¨ä¸º{self.business_context}è®¾è®¡æ•°æ®æŸ¥è¯¢ã€‚

å½“å‰åˆ†æä¸»é¢˜ï¼š{topic_name}
ä¸»é¢˜æè¿°ï¼š{description}
å…³æ³¨é¢†åŸŸï¼š{', '.join(focus_areas)}
ç›¸å…³è¡¨ï¼š{', '.join(related_tables)}

æ•°æ®åº“è¡¨ç»“æ„ä¿¡æ¯ï¼š
{md_contents}

è¯·ä¸ºè¿™ä¸ªä¸»é¢˜ç”Ÿæˆ {questions_count} ä¸ªä¸šåŠ¡é—®é¢˜å’Œå¯¹åº”çš„SQLæŸ¥è¯¢ã€‚

è¦æ±‚ï¼š
1. é—®é¢˜åº”è¯¥ä»ä¸šåŠ¡è§’åº¦å‡ºå‘ï¼Œè´´åˆä¸»é¢˜è¦æ±‚ï¼Œå…·æœ‰å®é™…åˆ†æä»·å€¼
2. SQLå¿…é¡»ä½¿ç”¨PostgreSQLè¯­æ³•
3. è€ƒè™‘å®é™…ä¸šåŠ¡é€»è¾‘ï¼ˆå¦‚è½¯åˆ é™¤ä½¿ç”¨ delete_ts IS NULL æ¡ä»¶ï¼‰
4. ä½¿ç”¨ä¸­æ–‡åˆ«åæé«˜å¯è¯»æ€§ï¼ˆä½¿ç”¨ AS æŒ‡å®šåˆ—åˆ«åï¼‰
5. é—®é¢˜åº”è¯¥å¤šæ ·åŒ–ï¼Œè¦†ç›–ä¸åŒçš„åˆ†æè§’åº¦
6. åŒ…å«æ—¶é—´ç­›é€‰ã€åˆ†ç»„ç»Ÿè®¡ã€æ’åºã€é™åˆ¶ç­‰ä¸åŒç±»å‹çš„æŸ¥è¯¢
7. SQLè¯­å¥æœ«å°¾å¿…é¡»ä»¥åˆ†å·ç»“æŸ
8. **é‡è¦ï¼šé—®é¢˜å’ŒSQLéƒ½å¿…é¡»æ˜¯å•è¡Œæ–‡æœ¬ï¼Œä¸èƒ½åŒ…å«æ¢è¡Œç¬¦**

è¾“å‡ºJSONæ ¼å¼ï¼ˆæ³¨æ„SQLä¸­çš„åŒå¼•å·éœ€è¦è½¬ä¹‰ï¼‰ï¼š
```json
[
  {{
    "question": "å…·ä½“çš„ä¸šåŠ¡é—®é¢˜ï¼Ÿ",
    "sql": "SELECT column AS ä¸­æ–‡å FROM table WHERE condition;"
  }}
]
```

ç”Ÿæˆçš„é—®é¢˜åº”è¯¥åŒ…æ‹¬ä½†ä¸é™äºï¼š
- è¶‹åŠ¿åˆ†æï¼ˆæŒ‰æ—¶é—´ç»´åº¦ï¼‰
- å¯¹æ¯”åˆ†æï¼ˆä¸åŒç»´åº¦å¯¹æ¯”ï¼‰
- æ’åç»Ÿè®¡ï¼ˆTOP Nï¼‰
- æ±‡æ€»ç»Ÿè®¡ï¼ˆæ€»é‡ã€å¹³å‡å€¼ç­‰ï¼‰
- æ˜ç»†æŸ¥è¯¢ï¼ˆç‰¹å®šæ¡ä»¶çš„è¯¦ç»†æ•°æ®ï¼‰"""
        
        return prompt
    
    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLM"""
        try:
            response = await asyncio.to_thread(
                self.vn.chat_with_llm,
                question=prompt,
                system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œç²¾é€šPostgreSQLè¯­æ³•ï¼Œæ“…é•¿è®¾è®¡æœ‰ä¸šåŠ¡ä»·å€¼çš„æ•°æ®æŸ¥è¯¢ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºã€‚ç‰¹åˆ«æ³¨æ„ï¼šç”Ÿæˆçš„é—®é¢˜å’ŒSQLéƒ½å¿…é¡»æ˜¯å•è¡Œæ–‡æœ¬ï¼Œä¸èƒ½åŒ…å«æ¢è¡Œç¬¦ã€‚"
            )
            
            if not response or not response.strip():
                raise ValueError("LLMè¿”å›ç©ºå“åº”")
            
            return response.strip()
            
        except Exception as e:
            self.logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _parse_qs_response(self, response: str) -> List[Dict[str, str]]:
        """è§£æQuestion-SQLå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = response
            
            # è§£æJSON
            qs_pairs = json.loads(json_str)
            
            if not isinstance(qs_pairs, list):
                raise ValueError("å“åº”ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
            
            return qs_pairs
            
        except json.JSONDecodeError as e:
            self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
            self.logger.debug(f"åŸå§‹å“åº”: {response}")
            raise ValueError(f"æ— æ³•è§£æLLMå“åº”ä¸ºJSONæ ¼å¼: {e}")
    
    def _validate_qs_pairs(self, qs_pairs: List[Dict], theme_name: str) -> List[Dict[str, str]]:
        """éªŒè¯å’Œæ¸…ç†Question-SQLå¯¹"""
        validated = []
        
        for i, pair in enumerate(qs_pairs):
            if not isinstance(pair, dict):
                self.logger.warning(f"è·³è¿‡æ— æ•ˆæ ¼å¼çš„é¡¹ {i+1}")
                continue
            
            question = pair.get('question', '').strip()
            sql = pair.get('sql', '').strip()
            
            if not question or not sql:
                self.logger.warning(f"è·³è¿‡ç©ºé—®é¢˜æˆ–SQLçš„é¡¹ {i+1}")
                continue
            
            # æ¸…ç†questionä¸­çš„æ¢è¡Œç¬¦ï¼Œæ›¿æ¢ä¸ºç©ºæ ¼
            question = ' '.join(question.split())
            
            # æ¸…ç†SQLä¸­çš„æ¢è¡Œç¬¦å’Œå¤šä½™ç©ºæ ¼ï¼Œå‹ç¼©ä¸ºå•è¡Œ
            sql = ' '.join(sql.split())
            
            # ç¡®ä¿SQLä»¥åˆ†å·ç»“æŸ
            if not sql.endswith(';'):
                sql += ';'
            
            validated.append({
                'question': question,
                'sql': sql
            })
        
        self.logger.info(f"ä¸»é¢˜ '{theme_name}': éªŒè¯é€šè¿‡ {len(validated)}/{len(qs_pairs)} ä¸ªé—®é¢˜")
        
        return validated
    
    def _init_intermediate_file(self):
        """åˆå§‹åŒ–ä¸­é—´ç»“æœæ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.intermediate_file = self.output_dir / f"qs_intermediate_{timestamp}.json"
        self.intermediate_results = []
        self.logger.info(f"ä¸­é—´ç»“æœæ–‡ä»¶: {self.intermediate_file}")
    
    async def _save_theme_results(self, theme_name: str, qs_pairs: List[Dict]):
        """ä¿å­˜å•ä¸ªä¸»é¢˜çš„ç»“æœ"""
        theme_result = {
            "theme": theme_name,
            "timestamp": datetime.now().isoformat(),
            "questions_count": len(qs_pairs),
            "questions": qs_pairs
        }
        
        self.intermediate_results.append(theme_result)
        
        # ç«‹å³ä¿å­˜åˆ°ä¸­é—´æ–‡ä»¶
        if self.config['qs_generation']['save_intermediate']:
            try:
                with open(self.intermediate_file, 'w', encoding='utf-8') as f:
                    json.dump(self.intermediate_results, f, ensure_ascii=False, indent=2)
                self.logger.debug(f"ä¸­é—´ç»“æœå·²æ›´æ–°: {self.intermediate_file}")
            except Exception as e:
                self.logger.warning(f"ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {e}")
    
    def _save_intermediate_results(self) -> Path:
        """å¼‚å¸¸æ—¶ä¿å­˜ä¸­é—´ç»“æœ"""
        if not self.intermediate_results:
            return None
        
        recovery_file = self.output_dir / f"qs_recovery_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(recovery_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "status": "interrupted",
                    "timestamp": datetime.now().isoformat(),
                    "completed_themes": len(self.intermediate_results),
                    "results": self.intermediate_results
                }, f, ensure_ascii=False, indent=2)
            
            return recovery_file
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ¢å¤æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    async def _save_final_results(self, all_qs_pairs: List[Dict]) -> Path:
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = self.output_dir / f"{self.config['qs_generation']['output_file_prefix']}_{self.db_name}_{timestamp}_pair.json"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(all_qs_pairs, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"âœ… æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            return output_file
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æœ€ç»ˆç»“æœå¤±è´¥: {e}")
            raise
    
    def _cleanup_intermediate_file(self):
        """æ¸…ç†ä¸­é—´æ–‡ä»¶"""
        if self.intermediate_file and self.intermediate_file.exists():
            try:
                self.intermediate_file.unlink()
                self.logger.info("å·²æ¸…ç†ä¸­é—´æ–‡ä»¶")
            except Exception as e:
                self.logger.warning(f"æ¸…ç†ä¸­é—´æ–‡ä»¶å¤±è´¥: {e}")
    
    def _print_summary(self, report: Dict):
        """æ‰“å°æ€»ç»“ä¿¡æ¯"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“Š ç”Ÿæˆæ€»ç»“")
        self.logger.info(f"  âœ… æ€»ä¸»é¢˜æ•°: {report['total_themes']}")
        self.logger.info(f"  âœ… æˆåŠŸä¸»é¢˜: {report['successful_themes']}")
        
        if report['failed_themes']:
            self.logger.info(f"  âŒ å¤±è´¥ä¸»é¢˜: {len(report['failed_themes'])}")
            for theme in report['failed_themes']:
                self.logger.info(f"     - {theme}")
        
        self.logger.info(f"  ğŸ“ æ€»é—®é¢˜æ•°: {report['total_questions']}")
        self.logger.info(f"  ğŸ“ è¾“å‡ºæ–‡ä»¶: {report['output_file']}")
        self.logger.info(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {report['execution_time']:.2f}ç§’")
        self.logger.info("=" * 60)

    async def _generate_metadata_file(self, themes: List[Dict]):
        """ç”Ÿæˆmetadata.txtæ–‡ä»¶ï¼ŒåŒ…å«INSERTè¯­å¥"""
        metadata_file = self.output_dir / "metadata.txt"
        
        try:
            with open(metadata_file, 'w', encoding='utf-8') as f:
                f.write("-- Schema Toolsç”Ÿæˆçš„ä¸»é¢˜å…ƒæ•°æ®\n")
                f.write(f"-- ä¸šåŠ¡èƒŒæ™¯: {self.business_context}\n")
                f.write(f"-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"-- æ•°æ®åº“: {self.db_name}\n\n")
                
                f.write("-- åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n")
                f.write("CREATE TABLE IF NOT EXISTS metadata (\n")
                f.write("    id SERIAL PRIMARY KEY,\n")
                f.write("    topic_name VARCHAR(100) NOT NULL,\n")
                f.write("    description TEXT,\n")
                f.write("    related_tables TEXT[],\n")
                f.write("    keywords TEXT[],\n")
                f.write("    focus_areas TEXT[],\n")
                f.write("    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n")
                f.write(");\n\n")
                
                f.write("-- æ’å…¥ä¸»é¢˜æ•°æ®\n")
                for theme in themes:
                    # è·å–å­—æ®µå€¼ï¼Œä½¿ç”¨æ–°æ ¼å¼
                    topic_name = theme.get('topic_name', theme.get('name', ''))
                    description = theme.get('description', '')
                    
                    # å¤„ç†related_tables
                    related_tables = theme.get('related_tables', [])
                    if isinstance(related_tables, list):
                        tables_str = '{' + ','.join(related_tables) + '}'
                    else:
                        tables_str = '{}'
                    
                    # å¤„ç†keywords
                    keywords = theme.get('keywords', [])
                    if isinstance(keywords, list):
                        keywords_str = '{' + ','.join(keywords) + '}'
                    else:
                        keywords_str = '{}'
                    
                    # å¤„ç†focus_areas
                    focus_areas = theme.get('focus_areas', [])
                    if isinstance(focus_areas, list):
                        focus_areas_str = '{' + ','.join(focus_areas) + '}'
                    else:
                        focus_areas_str = '{}'
                    
                    # ç”ŸæˆINSERTè¯­å¥
                    f.write("INSERT INTO metadata(topic_name, description, related_tables, keywords, focus_areas) VALUES\n")
                    f.write("(\n")
                    f.write(f"  '{self._escape_sql_string(topic_name)}',\n")
                    f.write(f"  '{self._escape_sql_string(description)}',\n")
                    f.write(f"  '{tables_str}',\n")
                    f.write(f"  '{keywords_str}',\n")
                    f.write(f"  '{focus_areas_str}'\n")
                    f.write(");\n\n")
            
            self.logger.info(f"âœ… metadata.txtæ–‡ä»¶å·²ç”Ÿæˆ: {metadata_file}")
            return metadata_file
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆmetadata.txtæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _escape_sql_string(self, value: str) -> str:
        """è½¬ä¹‰SQLå­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        if not value:
            return ""
        # è½¬ä¹‰å•å¼•å·
        return value.replace("'", "''") 