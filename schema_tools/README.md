# Schema Tools

è‡ªåŠ¨åŒ–æ•°æ®åº“é€†å‘å·¥ç¨‹å·¥å…·ï¼Œç”¨äºä»PostgreSQLæ•°æ®åº“ç”Ÿæˆvanna.aiæ ¼å¼çš„è®­ç»ƒæ•°æ®ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ è‡ªåŠ¨è¿æ¥PostgreSQLæ•°æ®åº“
- ğŸ“‹ æ‰¹é‡å¤„ç†è¡¨æ¸…å•
- ğŸ¤– LLMæ™ºèƒ½ç”Ÿæˆä¸­æ–‡æ³¨é‡Š
- ğŸ” è‡ªåŠ¨æ£€æµ‹æšä¸¾å­—æ®µ
- âš¡ å¹¶å‘å¤„ç†æé«˜æ•ˆç‡
- ğŸ“ ç”Ÿæˆæ ‡å‡†åŒ–çš„DDLå’ŒMDæ–‡æ¡£
- ğŸ›¡ï¸ å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

## å®‰è£…ä¾èµ–

```bash
pip install asyncpg asyncio
```

## ä½¿ç”¨æ–¹æ³•

### 1. å‘½ä»¤è¡Œæ–¹å¼

#### åŸºæœ¬ä½¿ç”¨
```bash
python -m schema_tools \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --table-list tables.txt \
  --business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ"
```

#### æŒ‡å®šè¾“å‡ºç›®å½•å’Œå¤„ç†é“¾
```bash
python -m schema_tools \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --table-list tables.txt \
  --business-context "ç”µå•†ç³»ç»Ÿ" \
  --output-dir ./output \
  --pipeline full
```

#### ä»…æ£€æŸ¥æ•°æ®åº“æƒé™
```bash
python -m schema_tools \
  --db-connection "postgresql://user:pass@localhost:5432/dbname" \
  --check-permissions-only
```

### 2. ç¼–ç¨‹æ–¹å¼

```python
import asyncio
from schema_tools import SchemaTrainingDataAgent

async def generate_training_data():
    agent = SchemaTrainingDataAgent(
        db_connection="postgresql://user:pass@localhost:5432/dbname",
        table_list_file="tables.txt",
        business_context="é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ",
        output_dir="./output",
        pipeline="full"
    )
    
    report = await agent.generate_training_data()
    print(f"å¤„ç†å®Œæˆ: {report['summary']}")

asyncio.run(generate_training_data())
```

### 3. è¡¨æ¸…å•æ–‡ä»¶æ ¼å¼

åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼ˆå¦‚ `tables.txt`ï¼‰ï¼Œæ¯è¡Œä¸€ä¸ªè¡¨åï¼š

```text
# è¿™æ˜¯æ³¨é‡Šè¡Œ
public.users
public.orders
hr.employees
sales.products
```

## è¾“å‡ºæ–‡ä»¶ç»“æ„

```
output/
â”œâ”€â”€ ddl/                          # DDLæ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ users.ddl
â”‚   â”œâ”€â”€ orders.ddl
â”‚   â””â”€â”€ hr__employees.ddl
â”œâ”€â”€ docs/                         # MDæ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ users_detail.md
â”‚   â”œâ”€â”€ orders_detail.md
â”‚   â””â”€â”€ hr__employees_detail.md
â”œâ”€â”€ logs/                         # æ—¥å¿—ç›®å½•
â”‚   â””â”€â”€ schema_tools_20240101_120000.log
â””â”€â”€ filename_mapping.txt          # æ–‡ä»¶åæ˜ å°„æŠ¥å‘Š
```

## é…ç½®é€‰é¡¹

ä¸»è¦é…ç½®åœ¨ `schema_tools/config.py` ä¸­ï¼š

```python
SCHEMA_TOOLS_CONFIG = {
    # æ ¸å¿ƒé…ç½®
    "output_directory": "training/generated_data",
    "default_pipeline": "full",
    
    # æ•°æ®å¤„ç†é…ç½®
    "sample_data_limit": 20,              # é‡‡æ ·æ•°æ®é‡
    "max_concurrent_tables": 3,           # æœ€å¤§å¹¶å‘æ•°
    
    # LLMé…ç½®
    "max_llm_retries": 3,                # LLMé‡è¯•æ¬¡æ•°
    "comment_generation_timeout": 30,     # è¶…æ—¶æ—¶é—´
    
    # ç³»ç»Ÿè¡¨è¿‡æ»¤
    "filter_system_tables": True,         # è¿‡æ»¤ç³»ç»Ÿè¡¨
    
    # é”™è¯¯å¤„ç†
    "continue_on_error": True,            # é”™è¯¯åç»§ç»­
}
```

## å¤„ç†é“¾ç±»å‹

- **full**: å®Œæ•´å¤„ç†é“¾ï¼ˆé»˜è®¤ï¼‰
  - æ•°æ®åº“æ£€æŸ¥ â†’ æ•°æ®é‡‡æ · â†’ æ³¨é‡Šç”Ÿæˆ â†’ DDLç”Ÿæˆ â†’ MDæ–‡æ¡£ç”Ÿæˆ

- **ddl_only**: ä»…ç”ŸæˆDDL
  - æ•°æ®åº“æ£€æŸ¥ â†’ æ•°æ®é‡‡æ · â†’ æ³¨é‡Šç”Ÿæˆ â†’ DDLç”Ÿæˆ

- **analysis_only**: ä»…åˆ†æä¸ç”Ÿæˆæ–‡ä»¶
  - æ•°æ®åº“æ£€æŸ¥ â†’ æ•°æ®é‡‡æ · â†’ æ³¨é‡Šç”Ÿæˆ

## ä¸šåŠ¡ä¸Šä¸‹æ–‡

ä¸šåŠ¡ä¸Šä¸‹æ–‡å¸®åŠ©LLMæ›´å¥½åœ°ç†è§£è¡¨å’Œå­—æ®µçš„å«ä¹‰ï¼š

### æ–¹å¼1ï¼šå‘½ä»¤è¡Œå‚æ•°
```bash
--business-context "é«˜é€Ÿå…¬è·¯æœåŠ¡åŒºç®¡ç†ç³»ç»Ÿ"
```

### æ–¹å¼2ï¼šæ–‡ä»¶æ–¹å¼
```bash
--business-context-file business_context.txt
```

### æ–¹å¼3ï¼šä¸šåŠ¡è¯å…¸
ç¼–è¾‘ `schema_tools/prompts/business_dictionary.txt`ï¼š
```text
BSS - Business Support Systemï¼Œä¸šåŠ¡æ”¯æ’‘ç³»ç»Ÿ
SA - Service Areaï¼ŒæœåŠ¡åŒº
POS - Point of Saleï¼Œé”€å”®ç‚¹
```

## é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰ç³»ç»Ÿè¡¨è¿‡æ»¤

```python
from schema_tools.utils.system_filter import SystemTableFilter

filter = SystemTableFilter()
filter.add_custom_prefix("tmp_")      # æ·»åŠ è‡ªå®šä¹‰å‰ç¼€
filter.add_custom_schema("temp")      # æ·»åŠ è‡ªå®šä¹‰schema
```

### 2. å¤§è¡¨æ™ºèƒ½é‡‡æ ·

å¯¹äºè¶…è¿‡100ä¸‡è¡Œçš„å¤§è¡¨ï¼Œè‡ªåŠ¨ä½¿ç”¨åˆ†å±‚é‡‡æ ·ç­–ç•¥ï¼š
- å‰Nè¡Œ
- éšæœºä¸­é—´è¡Œ
- åNè¡Œ

### 3. æšä¸¾å­—æ®µæ£€æµ‹

è‡ªåŠ¨æ£€æµ‹å¹¶éªŒè¯æšä¸¾å­—æ®µï¼š
- VARCHARç±»å‹
- æ ·ä¾‹å€¼é‡å¤åº¦é«˜
- å­—æ®µååŒ…å«ç±»å‹å…³é”®è¯ï¼ˆçŠ¶æ€ã€ç±»å‹ã€çº§åˆ«ç­‰ï¼‰

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•å¤„ç†åªè¯»æ•°æ®åº“ï¼Ÿ
A: å·¥å…·è‡ªåŠ¨æ£€æµ‹å¹¶é€‚é…åªè¯»æ•°æ®åº“ï¼Œä¸ä¼šå°è¯•å†™æ“ä½œã€‚

### Q: å¦‚ä½•å¤„ç†é‡åè¡¨ï¼Ÿ
A: è‡ªåŠ¨ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼Œå¦‚ `hr__users.ddl` å’Œ `sales__users.ddl`ã€‚

### Q: å¦‚ä½•è·³è¿‡æŸäº›è¡¨ï¼Ÿ
A: åœ¨è¡¨æ¸…å•æ–‡ä»¶ä¸­æ³¨é‡Šæ‰ï¼ˆä½¿ç”¨ # å¼€å¤´ï¼‰æˆ–åˆ é™¤ç›¸åº”è¡Œã€‚

### Q: LLMè°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
A: è‡ªåŠ¨é‡è¯•3æ¬¡ï¼Œå¤±è´¥åä½¿ç”¨åŸå§‹æ³¨é‡Šæˆ–é»˜è®¤å€¼ã€‚

## æ³¨æ„äº‹é¡¹

1. **æ•°æ®åº“æƒé™**ï¼šè‡³å°‘éœ€è¦SELECTæƒé™
2. **LLMé…ç½®**ï¼šå¤ç”¨é¡¹ç›®çš„vannaå®ä¾‹é…ç½®
3. **å¹¶å‘æ§åˆ¶**ï¼šé»˜è®¤æœ€å¤§3ä¸ªè¡¨å¹¶å‘ï¼Œå¯è°ƒæ•´
4. **å†…å­˜ä½¿ç”¨**ï¼šå¤§è¡¨é‡‡æ ·ä¼šé™åˆ¶æ•°æ®é‡

## å¼€å‘ä¸æ‰©å±•

### æ·»åŠ æ–°å·¥å…·

1. åˆ›å»ºå·¥å…·ç±»ï¼š
```python
from schema_tools.tools.base import BaseTool, ToolRegistry

@ToolRegistry.register("my_tool")
class MyTool(BaseTool):
    needs_llm = False
    tool_name = "æˆ‘çš„å·¥å…·"
    
    async def execute(self, context):
        # å®ç°å·¥å…·é€»è¾‘
        return ProcessingResult(success=True)
```

2. æ·»åŠ åˆ°å¤„ç†é“¾ï¼š
```python
"my_pipeline": [
    "database_inspector",
    "my_tool",
    "ddl_generator"
]
```

## è®¸å¯è¯

æœ¬å·¥å…·ä½œä¸ºVANNA-CHAINLIT-CHROMADBé¡¹ç›®çš„ä¸€éƒ¨åˆ†ï¼Œéµå¾ªé¡¹ç›®è®¸å¯è¯ã€‚